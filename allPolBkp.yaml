apiVersion: v1
items:
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/add-default-securitycontext-container
      controls.cfasec.com/id: na
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/add-default-securitycontext-container","controls.cfasec.com/id":"na","policies.kyverno.io/category":"Sample","policies.kyverno.io/description":"A Container securityContext entry defines fields such as the user and group which should be used to run the Container. Sometimes choosing default values for users rather than blocking is a better alternative to not impede such Container definitions. This policy will mutate a Container to set `runAsNonRoot`, runAsUser`, `runAsGroup`, and `fsGroup` fields within the Container securityContext if they are not already set.","policies.kyverno.io/subject":"Pod","policies.kyverno.io/title":"Add Default securityContext"},"creationTimestamp":"2024-02-23T15:54:14Z","generation":1,"name":"add-default-securitycontext-container","resourceVersion":"727809648","uid":"cc47db40-7b7a-49c6-9d75-a74006f200eb"},"spec":{"background":true,"rules":[{"match":{"resources":{"kinds":["Pod"],"namespaceSelector":{"matchExpressions":[{"key":"feature/autoPodSecurityContext","operator":"In","values":["true"]}]}}},"mutate":{"foreach":[{"list":"request.object.spec.containers","patchStrategicMerge":{"spec":{"containers":[{"name":"{{ element.name }}","securityContext":{"+(allowPrivilegeEscalation)":false,"+(readOnlyRootFilesystem)":true,"+(runAsGroup)":3000,"+(runAsNonRoot)":true,"+(runAsUser)":1000,"capabilities":{"+(drop)":["ALL"]}}}]}}}]},"name":"add-default-securitycontext"}],"validationFailureAction":"Audit"},"status":{"autogen":{"rules":[{"exclude":{"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"],"namespaceSelector":{"matchExpressions":[{"key":"feature/autoPodSecurityContext","operator":"In","values":["true"]}]}}},"mutate":{"foreach":[{"list":"request.object.spec.template.spec.containers","patchStrategicMerge":{"spec":{"template":{"spec":{"containers":[{"name":"{{ element.name }}","securityContext":{"+(allowPrivilegeEscalation)":false,"+(readOnlyRootFilesystem)":true,"+(runAsGroup)":3000,"+(runAsNonRoot)":true,"+(runAsUser)":1000,"capabilities":{"+(drop)":["ALL"]}}}]}}}}}]},"name":"autogen-add-default-securitycontext","validate":{}},{"exclude":{"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"resources":{"kinds":["CronJob"],"namespaceSelector":{"matchExpressions":[{"key":"feature/autoPodSecurityContext","operator":"In","values":["true"]}]}}},"mutate":{"foreach":[{"list":"request.object.spec.jobTemplate.spec.template.spec.containers","patchStrategicMerge":{"spec":{"jobTemplate":{"spec":{"template":{"spec":{"containers":[{"name":"{{ element.name }}","securityContext":{"+(allowPrivilegeEscalation)":false,"+(readOnlyRootFilesystem)":true,"+(runAsGroup)":3000,"+(runAsNonRoot)":true,"+(runAsUser)":1000,"capabilities":{"+(drop)":["ALL"]}}}]}}}}}}}]},"name":"autogen-cronjob-add-default-securitycontext","validate":{}}]},"conditions":[{"lastTransitionTime":"2024-02-23T15:54:19Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":1,"validate":0,"verifyimages":0}}}
      policies.kyverno.io/category: Sample
      policies.kyverno.io/description: A Container securityContext entry defines fields
        such as the user and group which should be used to run the Container. Sometimes
        choosing default values for users rather than blocking is a better alternative
        to not impede such Container definitions. This policy will mutate a Container
        to set `runAsNonRoot`, runAsUser`, `runAsGroup`, and `fsGroup` fields within
        the Container securityContext if they are not already set.
      policies.kyverno.io/subject: Pod
      policies.kyverno.io/title: Add Default securityContext
    creationTimestamp: "2024-04-16T06:35:18Z"
    generation: 1
    name: add-default-securitycontext-container
    resourceVersion: "27604"
    uid: 882e2bdd-3d15-4dd5-a2c6-70c702012589
  spec:
    background: true
    rules:
    - match:
        resources:
          kinds:
          - Pod
          namespaceSelector:
            matchExpressions:
            - key: feature/autoPodSecurityContext
              operator: In
              values:
              - "true"
      mutate:
        foreach:
        - list: request.object.spec.containers
          patchStrategicMerge:
            spec:
              containers:
              - name: '{{ element.name }}'
                securityContext:
                  +(allowPrivilegeEscalation): false
                  +(readOnlyRootFilesystem): true
                  +(runAsGroup): 3000
                  +(runAsNonRoot): true
                  +(runAsUser): 1000
                  capabilities:
                    +(drop):
                    - ALL
      name: add-default-securitycontext
    validationFailureAction: Audit
  status:
    autogen:
      rules:
      - exclude:
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          resources:
            kinds:
            - DaemonSet
            - Deployment
            - Job
            - StatefulSet
            - ReplicaSet
            - ReplicationController
            namespaceSelector:
              matchExpressions:
              - key: feature/autoPodSecurityContext
                operator: In
                values:
                - "true"
        mutate:
          foreach:
          - list: request.object.spec.template.spec.containers
            patchStrategicMerge:
              spec:
                template:
                  spec:
                    containers:
                    - name: '{{ element.name }}'
                      securityContext:
                        +(allowPrivilegeEscalation): false
                        +(readOnlyRootFilesystem): true
                        +(runAsGroup): 3000
                        +(runAsNonRoot): true
                        +(runAsUser): 1000
                        capabilities:
                          +(drop):
                          - ALL
        name: autogen-add-default-securitycontext
        validate: {}
      - exclude:
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          resources:
            kinds:
            - CronJob
            namespaceSelector:
              matchExpressions:
              - key: feature/autoPodSecurityContext
                operator: In
                values:
                - "true"
        mutate:
          foreach:
          - list: request.object.spec.jobTemplate.spec.template.spec.containers
            patchStrategicMerge:
              spec:
                jobTemplate:
                  spec:
                    template:
                      spec:
                        containers:
                        - name: '{{ element.name }}'
                          securityContext:
                            +(allowPrivilegeEscalation): false
                            +(readOnlyRootFilesystem): true
                            +(runAsGroup): 3000
                            +(runAsNonRoot): true
                            +(runAsUser): 1000
                            capabilities:
                              +(drop):
                              - ALL
        name: autogen-cronjob-add-default-securitycontext
        validate: {}
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:18Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 1
      validate: 0
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/add-ns-compute-quota
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/add-ns-compute-quota","policies.kyverno.io/category":"Multi-Tenancy, EKS Best Practices","policies.kyverno.io/description":"Applies Compute ResourceQuotas to Namespaces with app-team label. 'To better control the number of resources that can be created in a given Namespace and provide default resource consumption for Pods, ResourceQuota resources are recommended.'","policies.kyverno.io/minversion":"1.6.0","policies.kyverno.io/subject":"ResourceQuota","policies.kyverno.io/title":"Add Compute Quota"},"creationTimestamp":"2024-02-23T16:11:27Z","generation":1,"name":"add-ns-compute-quota","resourceVersion":"727837210","uid":"362fcbc5-843a-4654-8b68-2de77d7a7f5e"},"spec":{"background":true,"generateExistingOnPolicyUpdate":true,"rules":[{"generate":{"apiVersion":"v1","data":{"spec":{"hard":{"requests.cpu":"106","requests.memory":"400Gi"}}},"kind":"ResourceQuota","name":"appcompute-resourcequota","namespace":"{{request.object.metadata.name}}"},"match":{"any":[{"resources":{"kinds":["Namespace"],"selector":{"matchLabels":{"app-team":"true"}}}}]},"name":"generate-compute-resourcequota"}],"validationFailureAction":"Audit"},"status":{"autogen":{},"conditions":[{"lastTransitionTime":"2024-02-23T16:11:28Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":1,"mutate":0,"validate":0,"verifyimages":0}}}
      policies.kyverno.io/category: Multi-Tenancy, EKS Best Practices
      policies.kyverno.io/description: Applies Compute ResourceQuotas to Namespaces
        with app-team label. 'To better control the number of resources that can be
        created in a given Namespace and provide default resource consumption for
        Pods, ResourceQuota resources are recommended.'
      policies.kyverno.io/minversion: 1.6.0
      policies.kyverno.io/subject: ResourceQuota
      policies.kyverno.io/title: Add Compute Quota
    creationTimestamp: "2024-04-16T06:35:18Z"
    generation: 1
    name: add-ns-compute-quota
    resourceVersion: "27633"
    uid: 100481cb-deba-465c-ae2d-6602d7eb77b0
  spec:
    background: true
    generateExistingOnPolicyUpdate: true
    rules:
    - generate:
        apiVersion: v1
        data:
          spec:
            hard:
              requests.cpu: "106"
              requests.memory: 400Gi
        kind: ResourceQuota
        name: appcompute-resourcequota
        namespace: '{{request.object.metadata.name}}'
      match:
        any:
        - resources:
            kinds:
            - Namespace
            selector:
              matchLabels:
                app-team: "true"
      name: generate-compute-resourcequota
    validationFailureAction: Audit
  status:
    autogen: {}
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:19Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 1
      mutate: 0
      validate: 0
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/add-ns-storage-quota
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/add-ns-storage-quota","policies.kyverno.io/category":"Multi-Tenancy, EKS Best Practices","policies.kyverno.io/description":"Applies Storage ResourceQuota to Namespaces with app-team label. 'To better control the number of resources that can be created in a given Namespace and provide default resource consumption for Pods, ResourceQuota resources are recommended.'","policies.kyverno.io/minversion":"1.6.0","policies.kyverno.io/subject":"ResourceQuota","policies.kyverno.io/title":"Add Storage Quota"},"creationTimestamp":"2024-02-23T15:54:02Z","generation":1,"name":"add-ns-storage-quota","resourceVersion":"727809473","uid":"7854486a-66ac-4645-87f8-1b38f206f907"},"spec":{"background":true,"generateExistingOnPolicyUpdate":true,"rules":[{"generate":{"apiVersion":"v1","data":{"spec":{"hard":{"persistentvolumeclaims":"3","requests.storage":"10Gi"}}},"kind":"ResourceQuota","name":"appstorage-resourcequota","namespace":"{{request.object.metadata.name}}"},"match":{"any":[{"resources":{"kinds":["Namespace"],"selector":{"matchLabels":{"app-team":"true"}}}}]},"name":"generate-storage-resourcequota"}],"validationFailureAction":"Audit"},"status":{"autogen":{},"conditions":[{"lastTransitionTime":"2024-02-23T15:54:13Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":1,"mutate":0,"validate":0,"verifyimages":0}}}
      policies.kyverno.io/category: Multi-Tenancy, EKS Best Practices
      policies.kyverno.io/description: Applies Storage ResourceQuota to Namespaces
        with app-team label. 'To better control the number of resources that can be
        created in a given Namespace and provide default resource consumption for
        Pods, ResourceQuota resources are recommended.'
      policies.kyverno.io/minversion: 1.6.0
      policies.kyverno.io/subject: ResourceQuota
      policies.kyverno.io/title: Add Storage Quota
    creationTimestamp: "2024-04-16T06:35:19Z"
    generation: 1
    name: add-ns-storage-quota
    resourceVersion: "27685"
    uid: f0ba8b00-6d0f-4a92-b958-32e760d24697
  spec:
    background: true
    generateExistingOnPolicyUpdate: true
    rules:
    - generate:
        apiVersion: v1
        data:
          spec:
            hard:
              persistentvolumeclaims: "3"
              requests.storage: 10Gi
        kind: ResourceQuota
        name: appstorage-resourcequota
        namespace: '{{request.object.metadata.name}}'
      match:
        any:
        - resources:
            kinds:
            - Namespace
            selector:
              matchLabels:
                app-team: "true"
      name: generate-storage-resourcequota
    validationFailureAction: Audit
  status:
    autogen: {}
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:19Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 1
      mutate: 0
      validate: 0
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/apply-pss-restricted-profile
      controls.cfasec.com/id: na
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/apply-pss-restricted-profile","controls.cfasec.com/id":"na","kyverno.io/kubernetes-version":"1.23","kyverno.io/kyverno-version":"1.6.2","policies.kyverno.io/category":"Other","policies.kyverno.io/description":"Pod Security Standards define the fields and their options which are allowable for Pods to achieve certain security best practices. While these are typically validation policies, workloads will either be accepted or rejected based upon what has already been defined. It is also possible to mutate incoming Pods to achieve the desired PSS level rather than reject. This policy sets all the fields necessary to pass the PSS Restricted profile.","policies.kyverno.io/subject":"Pod","policies.kyverno.io/title":"Apply PSS Restricted Profile"},"creationTimestamp":"2024-02-23T15:58:16Z","generation":1,"name":"apply-pss-restricted-profile","resourceVersion":"727837238","uid":"12988b70-7777-408c-9ba7-78a570d7657b"},"spec":{"background":true,"rules":[{"match":{"resources":{"kinds":["Pod"],"namespaceSelector":{"matchExpressions":[{"key":"feature/autoApplyPSSRestrictedProfile","operator":"In","values":["true"]}]}}},"mutate":{"patchStrategicMerge":{"spec":{"containers":[{"(name)":"?*","securityContext":{"allowPrivilegeEscalation":false,"capabilities":{"drop":["ALL"]},"privileged":false}}],"securityContext":{"fsGroup":2000,"runAsGroup":3000,"runAsNonRoot":true,"runAsUser":1000,"seccompProfile":{"type":"RuntimeDefault"}}}}},"name":"add-pss-fields"}],"validationFailureAction":"Audit"},"status":{"autogen":{"rules":[{"exclude":{"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"],"namespaceSelector":{"matchExpressions":[{"key":"feature/autoApplyPSSRestrictedProfile","operator":"In","values":["true"]}]}}},"mutate":{"patchStrategicMerge":{"spec":{"template":{"spec":{"containers":[{"(name)":"?*","securityContext":{"allowPrivilegeEscalation":false,"capabilities":{"drop":["ALL"]},"privileged":false}}],"securityContext":{"fsGroup":2000,"runAsGroup":3000,"runAsNonRoot":true,"runAsUser":1000,"seccompProfile":{"type":"RuntimeDefault"}}}}}}},"name":"autogen-add-pss-fields","validate":{}},{"exclude":{"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"resources":{"kinds":["CronJob"],"namespaceSelector":{"matchExpressions":[{"key":"feature/autoApplyPSSRestrictedProfile","operator":"In","values":["true"]}]}}},"mutate":{"patchStrategicMerge":{"spec":{"jobTemplate":{"spec":{"template":{"spec":{"containers":[{"(name)":"?*","securityContext":{"allowPrivilegeEscalation":false,"capabilities":{"drop":["ALL"]},"privileged":false}}],"securityContext":{"fsGroup":2000,"runAsGroup":3000,"runAsNonRoot":true,"runAsUser":1000,"seccompProfile":{"type":"RuntimeDefault"}}}}}}}}},"name":"autogen-cronjob-add-pss-fields","validate":{}}]},"conditions":[{"lastTransitionTime":"2024-02-23T15:58:18Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":1,"validate":0,"verifyimages":0}}}
      kyverno.io/kubernetes-version: "1.23"
      kyverno.io/kyverno-version: 1.6.2
      policies.kyverno.io/category: Other
      policies.kyverno.io/description: Pod Security Standards define the fields and
        their options which are allowable for Pods to achieve certain security best
        practices. While these are typically validation policies, workloads will either
        be accepted or rejected based upon what has already been defined. It is also
        possible to mutate incoming Pods to achieve the desired PSS level rather than
        reject. This policy sets all the fields necessary to pass the PSS Restricted
        profile.
      policies.kyverno.io/subject: Pod
      policies.kyverno.io/title: Apply PSS Restricted Profile
    creationTimestamp: "2024-04-16T06:35:19Z"
    generation: 1
    name: apply-pss-restricted-profile
    resourceVersion: "27727"
    uid: 4269677b-eee3-4381-915a-1261db400581
  spec:
    background: true
    rules:
    - match:
        resources:
          kinds:
          - Pod
          namespaceSelector:
            matchExpressions:
            - key: feature/autoApplyPSSRestrictedProfile
              operator: In
              values:
              - "true"
      mutate:
        patchStrategicMerge:
          spec:
            containers:
            - (name): ?*
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                  - ALL
                privileged: false
            securityContext:
              fsGroup: 2000
              runAsGroup: 3000
              runAsNonRoot: true
              runAsUser: 1000
              seccompProfile:
                type: RuntimeDefault
      name: add-pss-fields
    validationFailureAction: Audit
  status:
    autogen:
      rules:
      - exclude:
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          resources:
            kinds:
            - DaemonSet
            - Deployment
            - Job
            - StatefulSet
            - ReplicaSet
            - ReplicationController
            namespaceSelector:
              matchExpressions:
              - key: feature/autoApplyPSSRestrictedProfile
                operator: In
                values:
                - "true"
        mutate:
          patchStrategicMerge:
            spec:
              template:
                spec:
                  containers:
                  - (name): ?*
                    securityContext:
                      allowPrivilegeEscalation: false
                      capabilities:
                        drop:
                        - ALL
                      privileged: false
                  securityContext:
                    fsGroup: 2000
                    runAsGroup: 3000
                    runAsNonRoot: true
                    runAsUser: 1000
                    seccompProfile:
                      type: RuntimeDefault
        name: autogen-add-pss-fields
        validate: {}
      - exclude:
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          resources:
            kinds:
            - CronJob
            namespaceSelector:
              matchExpressions:
              - key: feature/autoApplyPSSRestrictedProfile
                operator: In
                values:
                - "true"
        mutate:
          patchStrategicMerge:
            spec:
              jobTemplate:
                spec:
                  template:
                    spec:
                      containers:
                      - (name): ?*
                        securityContext:
                          allowPrivilegeEscalation: false
                          capabilities:
                            drop:
                            - ALL
                          privileged: false
                      securityContext:
                        fsGroup: 2000
                        runAsGroup: 3000
                        runAsNonRoot: true
                        runAsUser: 1000
                        seccompProfile:
                          type: RuntimeDefault
        name: autogen-cronjob-add-pss-fields
        validate: {}
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:20Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 1
      validate: 0
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/apply-sc-node-group
      controls.cfasec.com/id: na
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/apply-sc-node-group","controls.cfasec.com/id":"na","kyverno.io/kubernetes-version":"1.23","kyverno.io/kyverno-version":"1.6.2","policies.kyverno.io/category":"Kuberneering","policies.kyverno.io/description":"This policy allows resources to be scheduled on the supply chain nodes.","policies.kyverno.io/subject":"Namespace","policies.kyverno.io/title":"Apply SC node group"},"creationTimestamp":"2024-02-23T16:11:27Z","generation":1,"name":"apply-sc-node-group","resourceVersion":"727837320","uid":"1636fe31-6e32-4826-8dc1-fc1fd87f007b"},"spec":{"background":true,"rules":[{"match":{"resources":{"kinds":["Pod"],"namespaceSelector":{"matchExpressions":[{"key":"feature/sc-AutoNodeSchedule","operator":"In","values":["true"]}]}}},"mutate":{"foreach":[{"list":"request.object.spec.containers","patchStrategicMerge":{"spec":{"containers":[{"name":"{{ element.name }}"}],"nodeSelector":{"supplychain-xl":"true"},"tolerations":[{"effect":"NoSchedule","key":"supplychain-xl","operator":"Exists"}]}}}]},"name":"add-sc-node-group"}],"validationFailureAction":"Audit"},"status":{"autogen":{"rules":[{"exclude":{"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"],"namespaceSelector":{"matchExpressions":[{"key":"feature/sc-AutoNodeSchedule","operator":"In","values":["true"]}]}}},"mutate":{"foreach":[{"list":"request.object.spec.template.spec.containers","patchStrategicMerge":{"spec":{"template":{"spec":{"containers":[{"name":"{{ element.name }}"}],"nodeSelector":{"supplychain-xl":"true"},"tolerations":[{"effect":"NoSchedule","key":"supplychain-xl","operator":"Exists"}]}}}}}]},"name":"autogen-add-sc-node-group","validate":{}},{"exclude":{"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"resources":{"kinds":["CronJob"],"namespaceSelector":{"matchExpressions":[{"key":"feature/sc-AutoNodeSchedule","operator":"In","values":["true"]}]}}},"mutate":{"foreach":[{"list":"request.object.spec.jobTemplate.spec.template.spec.containers","patchStrategicMerge":{"spec":{"jobTemplate":{"spec":{"template":{"spec":{"containers":[{"name":"{{ element.name }}"}],"nodeSelector":{"supplychain-xl":"true"},"tolerations":[{"effect":"NoSchedule","key":"supplychain-xl","operator":"Exists"}]}}}}}}}]},"name":"autogen-cronjob-add-sc-node-group","validate":{}}]},"conditions":[{"lastTransitionTime":"2024-02-23T16:11:32Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":1,"validate":0,"verifyimages":0}}}
      kyverno.io/kubernetes-version: "1.23"
      kyverno.io/kyverno-version: 1.6.2
      policies.kyverno.io/category: Kuberneering
      policies.kyverno.io/description: This policy allows resources to be scheduled
        on the supply chain nodes.
      policies.kyverno.io/subject: Namespace
      policies.kyverno.io/title: Apply SC node group
    creationTimestamp: "2024-04-16T06:35:20Z"
    generation: 1
    name: apply-sc-node-group
    resourceVersion: "27759"
    uid: 572e32e8-a675-4596-9cf3-40a1416212b0
  spec:
    background: true
    rules:
    - match:
        resources:
          kinds:
          - Pod
          namespaceSelector:
            matchExpressions:
            - key: feature/sc-AutoNodeSchedule
              operator: In
              values:
              - "true"
      mutate:
        foreach:
        - list: request.object.spec.containers
          patchStrategicMerge:
            spec:
              containers:
              - name: '{{ element.name }}'
              nodeSelector:
                supplychain-xl: "true"
              tolerations:
              - effect: NoSchedule
                key: supplychain-xl
                operator: Exists
      name: add-sc-node-group
    validationFailureAction: Audit
  status:
    autogen:
      rules:
      - exclude:
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          resources:
            kinds:
            - DaemonSet
            - Deployment
            - Job
            - StatefulSet
            - ReplicaSet
            - ReplicationController
            namespaceSelector:
              matchExpressions:
              - key: feature/sc-AutoNodeSchedule
                operator: In
                values:
                - "true"
        mutate:
          foreach:
          - list: request.object.spec.template.spec.containers
            patchStrategicMerge:
              spec:
                template:
                  spec:
                    containers:
                    - name: '{{ element.name }}'
                    nodeSelector:
                      supplychain-xl: "true"
                    tolerations:
                    - effect: NoSchedule
                      key: supplychain-xl
                      operator: Exists
        name: autogen-add-sc-node-group
        validate: {}
      - exclude:
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          resources:
            kinds:
            - CronJob
            namespaceSelector:
              matchExpressions:
              - key: feature/sc-AutoNodeSchedule
                operator: In
                values:
                - "true"
        mutate:
          foreach:
          - list: request.object.spec.jobTemplate.spec.template.spec.containers
            patchStrategicMerge:
              spec:
                jobTemplate:
                  spec:
                    template:
                      spec:
                        containers:
                        - name: '{{ element.name }}'
                        nodeSelector:
                          supplychain-xl: "true"
                        tolerations:
                        - effect: NoSchedule
                          key: supplychain-xl
                          operator: Exists
        name: autogen-cronjob-add-sc-node-group
        validate: {}
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:20Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 1
      validate: 0
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/block-ephemeral-containers
      controls.cfasec.com/id: pod1
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/block-ephemeral-containers","controls.cfasec.com/id":"pod1","kyverno.io/kubernetes-version":"1.23","kyverno.io/kyverno-version":"1.6.0","policies.kyverno.io/category":"Other","policies.kyverno.io/description":"Ephemeral containers, enabled by default in Kubernetes 1.23, allow users to use the `kubectl debug` functionality and attach a temporary container to an existing Pod. This may potentially be used to gain access to unauthorized information executing inside one or more containers in that Pod. This policy blocks the use of ephemeral containers.","policies.kyverno.io/minversion":"1.6.0","policies.kyverno.io/severity":"medium","policies.kyverno.io/subject":"Pod","policies.kyverno.io/title":"Block Ephemeral Containers"},"creationTimestamp":"2024-02-23T15:54:02Z","generation":1,"name":"block-ephemeral-containers","resourceVersion":"727809475","uid":"673d829e-1f36-4967-9798-92f576a689ab"},"spec":{"background":true,"rules":[{"match":{"any":[{"resources":{"kinds":["Pod"]}}]},"name":"block-ephemeral-containers","validate":{"message":"Ephemeral (debug) containers are not permitted.","pattern":{"spec":{"X(ephemeralContainers)":"null"}}}}],"validationFailureAction":"audit"},"status":{"autogen":{"rules":[{"exclude":{"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"]}}],"resources":{}},"mutate":{},"name":"autogen-block-ephemeral-containers","validate":{"message":"Ephemeral (debug) containers are not permitted.","pattern":{"spec":{"template":{"spec":{"X(ephemeralContainers)":"null"}}}}}},{"exclude":{"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["CronJob"]}}],"resources":{}},"mutate":{},"name":"autogen-cronjob-block-ephemeral-containers","validate":{"message":"Ephemeral (debug) containers are not permitted.","pattern":{"spec":{"jobTemplate":{"spec":{"template":{"spec":{"X(ephemeralContainers)":"null"}}}}}}}}]},"conditions":[{"lastTransitionTime":"2024-02-23T15:54:13Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":1,"verifyimages":0}}}
      kyverno.io/kubernetes-version: "1.23"
      kyverno.io/kyverno-version: 1.6.0
      policies.kyverno.io/category: Other
      policies.kyverno.io/description: Ephemeral containers, enabled by default in
        Kubernetes 1.23, allow users to use the `kubectl debug` functionality and
        attach a temporary container to an existing Pod. This may potentially be used
        to gain access to unauthorized information executing inside one or more containers
        in that Pod. This policy blocks the use of ephemeral containers.
      policies.kyverno.io/minversion: 1.6.0
      policies.kyverno.io/severity: medium
      policies.kyverno.io/subject: Pod
      policies.kyverno.io/title: Block Ephemeral Containers
    creationTimestamp: "2024-04-16T06:35:20Z"
    generation: 1
    name: block-ephemeral-containers
    resourceVersion: "27790"
    uid: 59525b9b-90a2-456c-b260-8c5125b4363f
  spec:
    background: true
    rules:
    - match:
        any:
        - resources:
            kinds:
            - Pod
      name: block-ephemeral-containers
      validate:
        message: Ephemeral (debug) containers are not permitted.
        pattern:
          spec:
            X(ephemeralContainers): "null"
    validationFailureAction: audit
  status:
    autogen:
      rules:
      - exclude:
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
          resources: {}
        mutate: {}
        name: autogen-block-ephemeral-containers
        validate:
          message: Ephemeral (debug) containers are not permitted.
          pattern:
            spec:
              template:
                spec:
                  X(ephemeralContainers): "null"
      - exclude:
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - CronJob
          resources: {}
        mutate: {}
        name: autogen-cronjob-block-ephemeral-containers
        validate:
          message: Ephemeral (debug) containers are not permitted.
          pattern:
            spec:
              jobTemplate:
                spec:
                  template:
                    spec:
                      X(ephemeralContainers): "null"
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:20Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/block-images-with-volumes
      controls.cfasec.com/id: pod2
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/block-images-with-volumes","controls.cfasec.com/id":"pod2","kyverno.io/kubernetes-version":"1.23","kyverno.io/kyverno-version":"1.6.0","policies.kyverno.io/category":"Other","policies.kyverno.io/description":"OCI images may optionally be built with VOLUME statements which, if run in read-only mode, would still result in write access to the specified location. This may be unexpected and undesirable. This policy checks the contents of every container image and inspects them for such VOLUME statements, then blocks if found.      ","policies.kyverno.io/minversion":"1.6.0","policies.kyverno.io/severity":"medium","policies.kyverno.io/subject":"Pod","policies.kyverno.io/title":"Block Images with Volumes"},"creationTimestamp":"2024-02-23T15:54:02Z","generation":1,"name":"block-images-with-volumes","resourceVersion":"727809477","uid":"56ee82db-be1f-4101-91bd-49d91817d8af"},"spec":{"background":true,"rules":[{"exclude":{"any":[{"resources":{"kinds":["Pod"],"namespaces":["gloo-system","akuity-admin","datadog","aws-ebs-csi-driver","aws-efs-csi-driver","fw-prometheus","aws-load-balancer-controller","sigsci-agent"]}}]},"match":{"any":[{"resources":{"kinds":["Pod"]}}]},"name":"block-images-with-vols","preconditions":{"all":[{"key":"{{request.operation || 'BACKGROUND'}}","operator":"NotEquals","value":"DELETE"}]},"validate":{"foreach":[{"context":[{"imageRegistry":{"reference":"{{ element.image }}"},"name":"imageData"}],"deny":{"conditions":{"all":[{"key":"{{ imageData.configData.config.Volumes || '' | length(@) }}","operator":"GreaterThan","value":0}]}},"list":"request.object.spec.containers"}],"message":"Images containing built-in volumes are prohibited."}}],"validationFailureAction":"audit"},"status":{"autogen":{"rules":[{"exclude":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"],"namespaces":["gloo-system","akuity-admin","datadog","aws-ebs-csi-driver","aws-efs-csi-driver","fw-prometheus","aws-load-balancer-controller","sigsci-agent"]}}],"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"]}}],"resources":{}},"mutate":{},"name":"autogen-block-images-with-vols","preconditions":{"all":[{"key":"{{request.operation || 'BACKGROUND'}}","operator":"NotEquals","value":"DELETE"}]},"validate":{"foreach":[{"context":[{"imageRegistry":{"reference":"{{ element.image }}"},"name":"imageData"}],"deny":{"conditions":{"all":[{"key":"{{ imageData.configData.config.Volumes || '' | length(@) }}","operator":"GreaterThan","value":0}]}},"list":"request.object.spec.template.spec.containers"}],"message":"Images containing built-in volumes are prohibited."}},{"exclude":{"any":[{"resources":{"kinds":["CronJob"],"namespaces":["gloo-system","akuity-admin","datadog","aws-ebs-csi-driver","aws-efs-csi-driver","fw-prometheus","aws-load-balancer-controller","sigsci-agent"]}}],"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["CronJob"]}}],"resources":{}},"mutate":{},"name":"autogen-cronjob-block-images-with-vols","preconditions":{"all":[{"key":"{{request.operation || 'BACKGROUND'}}","operator":"NotEquals","value":"DELETE"}]},"validate":{"foreach":[{"context":[{"imageRegistry":{"reference":"{{ element.image }}"},"name":"imageData"}],"deny":{"conditions":{"all":[{"key":"{{ imageData.configData.config.Volumes || '' | length(@) }}","operator":"GreaterThan","value":0}]}},"list":"request.object.spec.jobTemplate.spec.template.spec.containers"}],"message":"Images containing built-in volumes are prohibited."}}]},"conditions":[{"lastTransitionTime":"2024-02-23T15:54:13Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":1,"verifyimages":0}}}
      kyverno.io/kubernetes-version: "1.23"
      kyverno.io/kyverno-version: 1.6.0
      policies.kyverno.io/category: Other
      policies.kyverno.io/description: 'OCI images may optionally be built with VOLUME
        statements which, if run in read-only mode, would still result in write access
        to the specified location. This may be unexpected and undesirable. This policy
        checks the contents of every container image and inspects them for such VOLUME
        statements, then blocks if found.      '
      policies.kyverno.io/minversion: 1.6.0
      policies.kyverno.io/severity: medium
      policies.kyverno.io/subject: Pod
      policies.kyverno.io/title: Block Images with Volumes
    creationTimestamp: "2024-04-16T06:35:20Z"
    generation: 1
    name: block-images-with-volumes
    resourceVersion: "27856"
    uid: 61d9d862-ce26-4217-8943-737b3724fa6c
  spec:
    background: true
    rules:
    - exclude:
        any:
        - resources:
            kinds:
            - Pod
            namespaces:
            - gloo-system
            - akuity-admin
            - datadog
            - aws-ebs-csi-driver
            - aws-efs-csi-driver
            - fw-prometheus
            - aws-load-balancer-controller
            - sigsci-agent
      match:
        any:
        - resources:
            kinds:
            - Pod
      name: block-images-with-vols
      preconditions:
        all:
        - key: '{{request.operation || ''BACKGROUND''}}'
          operator: NotEquals
          value: DELETE
      validate:
        foreach:
        - context:
          - imageRegistry:
              reference: '{{ element.image }}'
            name: imageData
          deny:
            conditions:
              all:
              - key: '{{ imageData.configData.config.Volumes || '''' | length(@) }}'
                operator: GreaterThan
                value: 0
          list: request.object.spec.containers
        message: Images containing built-in volumes are prohibited.
    validationFailureAction: audit
  status:
    autogen:
      rules:
      - exclude:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
              namespaces:
              - gloo-system
              - akuity-admin
              - datadog
              - aws-ebs-csi-driver
              - aws-efs-csi-driver
              - fw-prometheus
              - aws-load-balancer-controller
              - sigsci-agent
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
          resources: {}
        mutate: {}
        name: autogen-block-images-with-vols
        preconditions:
          all:
          - key: '{{request.operation || ''BACKGROUND''}}'
            operator: NotEquals
            value: DELETE
        validate:
          foreach:
          - context:
            - imageRegistry:
                reference: '{{ element.image }}'
              name: imageData
            deny:
              conditions:
                all:
                - key: '{{ imageData.configData.config.Volumes || '''' | length(@)
                    }}'
                  operator: GreaterThan
                  value: 0
            list: request.object.spec.template.spec.containers
          message: Images containing built-in volumes are prohibited.
      - exclude:
          any:
          - resources:
              kinds:
              - CronJob
              namespaces:
              - gloo-system
              - akuity-admin
              - datadog
              - aws-ebs-csi-driver
              - aws-efs-csi-driver
              - fw-prometheus
              - aws-load-balancer-controller
              - sigsci-agent
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - CronJob
          resources: {}
        mutate: {}
        name: autogen-cronjob-block-images-with-vols
        preconditions:
          all:
          - key: '{{request.operation || ''BACKGROUND''}}'
            operator: NotEquals
            value: DELETE
        validate:
          foreach:
          - context:
            - imageRegistry:
                reference: '{{ element.image }}'
              name: imageData
            deny:
              conditions:
                all:
                - key: '{{ imageData.configData.config.Volumes || '''' | length(@)
                    }}'
                  operator: GreaterThan
                  value: 0
            list: request.object.spec.jobTemplate.spec.template.spec.containers
          message: Images containing built-in volumes are prohibited.
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:21Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/block-pod-exec-from-service-accounts
      controls.cfasec.com/id: rbac12
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/block-pod-exec-from-service-accounts","controls.cfasec.com/id":"rbac12","policies.kyverno.io/category":"Sample","policies.kyverno.io/description":"The `exec` command may be used to gain shell access, or run other commands, in a Pod's container. While this can be useful for troubleshooting purposes, it could represent an attack vector and is discouraged. This policy blocks Pod exec from any service account.","policies.kyverno.io/minversion":"1.6.0","policies.kyverno.io/subject":"Pod","policies.kyverno.io/title":"Block Pod Exec From Service Accounts"},"creationTimestamp":"2024-02-23T15:54:14Z","generation":1,"name":"block-pod-exec-from-service-accounts","resourceVersion":"727809642","uid":"d9a57e4a-188e-45b2-b06c-65b1c5e6f087"},"spec":{"background":false,"rules":[{"match":{"any":[{"resources":{"kinds":["Pod/exec"]}}]},"name":"block-pod-exec","preconditions":{"all":[{"key":"{{ request.operation || 'BACKGROUND' }}","operator":"Equals","value":"CONNECT"},{"key":"{{serviceAccountName}}","operator":"NotEquals","value":""}]},"validate":{"deny":{},"message":"Exec'ing into Pods from ServiceAccounts is forbidden."}}],"validationFailureAction":"audit"},"status":{"autogen":{},"conditions":[{"lastTransitionTime":"2024-02-23T15:54:19Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":1,"verifyimages":0}}}
      policies.kyverno.io/category: Sample
      policies.kyverno.io/description: The `exec` command may be used to gain shell
        access, or run other commands, in a Pod's container. While this can be useful
        for troubleshooting purposes, it could represent an attack vector and is discouraged.
        This policy blocks Pod exec from any service account.
      policies.kyverno.io/minversion: 1.6.0
      policies.kyverno.io/subject: Pod
      policies.kyverno.io/title: Block Pod Exec From Service Accounts
    creationTimestamp: "2024-04-16T06:35:21Z"
    generation: 1
    name: block-pod-exec-from-service-accounts
    resourceVersion: "27881"
    uid: 653088dc-5090-49b3-8329-edb0c01fc9f1
  spec:
    background: false
    rules:
    - match:
        any:
        - resources:
            kinds:
            - Pod/exec
      name: block-pod-exec
      preconditions:
        all:
        - key: '{{ request.operation || ''BACKGROUND'' }}'
          operator: Equals
          value: CONNECT
        - key: '{{serviceAccountName}}'
          operator: NotEquals
          value: ""
      validate:
        deny: {}
        message: Exec'ing into Pods from ServiceAccounts is forbidden.
    validationFailureAction: audit
  status:
    autogen: {}
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:21Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/check-sa
      controls.cfasec.com/id: sa1
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/check-sa","controls.cfasec.com/id":"sa1","kyverno.io/kubernetes-version":"1.21","kyverno.io/kyverno-version":"1.6.0","policies.kyverno.io/category":"Sample","policies.kyverno.io/description":"ServiceAccounts with privileges to create Pods may be able to do so and name a ServiceAccount other than the one used to create it. This policy checks the Pod, if created by a ServiceAccount, and ensures the `serviceAccountName` field matches the actual ServiceAccount.      ","policies.kyverno.io/minversion":"1.6.0","policies.kyverno.io/subject":"Pod,ServiceAccount","policies.kyverno.io/title":"Check ServiceAccount"},"creationTimestamp":"2024-02-23T15:54:14Z","generation":1,"name":"check-sa","resourceVersion":"727809633","uid":"4f6ab6b2-2778-4cd3-901b-e804ecf0b575"},"spec":{"background":false,"rules":[{"exclude":{"any":[{"resources":{"kinds":["Pod"],"namespaces":["akuity-admin","akuity-app-team","aws-ebs-csi-driver","aws-efs-csi-driver","calico-*","calico-apiserver","calico-system","cert-manager","chkk-system","cluster-autoscaler","datadog","external-dns","external-secrets","fw-argocd","fw-prometheus","fw-telemetry","gloo-blue","gloo-green","gloo-mesh","gloo-system","grafana-agent","insights-agent","k6-operator","karpenter","kube-engineering","kubelink-system","metrics-server","monitoring","rbac-manager","sigsci-agent","tigera-apiserver","tigera-compliance","tigera-guardian","tigera-intrusion-detection","tigera-operator","tigera-system","wiz"]}}]},"match":{"any":[{"resources":{"kinds":["Pod"]}}]},"name":"check-sa","preconditions":{"all":[{"key":"{{serviceAccountName}}","operator":"Equals","value":"*?"},{"key":"{{serviceAccountName}}","operator":"NotEquals","value":"argocd-application-controller"},{"key":"{{serviceAccountName}}","operator":"NotEquals","value":"replicaset-controller"}]},"validate":{"message":"The ServiceAccount used ({{serviceAccountName}}) to create this Pod is confined to using the same account when running the Pod. ","pattern":{"spec":{"serviceAccountName":"{{serviceAccountName}}"}}}}],"validationFailureAction":"Enforce"},"status":{"autogen":{"rules":[{"exclude":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"],"namespaces":["akuity-admin","akuity-app-team","aws-ebs-csi-driver","aws-efs-csi-driver","calico-*","calico-apiserver","calico-system","cert-manager","chkk-system","cluster-autoscaler","datadog","external-dns","external-secrets","fw-argocd","fw-prometheus","fw-telemetry","gloo-blue","gloo-green","gloo-mesh","gloo-system","grafana-agent","insights-agent","k6-operator","karpenter","kube-engineering","kubelink-system","metrics-server","monitoring","rbac-manager","sigsci-agent","tigera-apiserver","tigera-compliance","tigera-guardian","tigera-intrusion-detection","tigera-operator","tigera-system","wiz"]}}],"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"]}}],"resources":{}},"mutate":{},"name":"autogen-check-sa","preconditions":{"all":[{"key":"{{serviceAccountName}}","operator":"Equals","value":"*?"},{"key":"{{serviceAccountName}}","operator":"NotEquals","value":"argocd-application-controller"},{"key":"{{serviceAccountName}}","operator":"NotEquals","value":"replicaset-controller"}]},"validate":{"message":"The ServiceAccount used ({{serviceAccountName}}) to create this Pod is confined to using the same account when running the Pod. ","pattern":{"spec":{"template":{"spec":{"serviceAccountName":"{{serviceAccountName}}"}}}}}},{"exclude":{"any":[{"resources":{"kinds":["CronJob"],"namespaces":["akuity-admin","akuity-app-team","aws-ebs-csi-driver","aws-efs-csi-driver","calico-*","calico-apiserver","calico-system","cert-manager","chkk-system","cluster-autoscaler","datadog","external-dns","external-secrets","fw-argocd","fw-prometheus","fw-telemetry","gloo-blue","gloo-green","gloo-mesh","gloo-system","grafana-agent","insights-agent","k6-operator","karpenter","kube-engineering","kubelink-system","metrics-server","monitoring","rbac-manager","sigsci-agent","tigera-apiserver","tigera-compliance","tigera-guardian","tigera-intrusion-detection","tigera-operator","tigera-system","wiz"]}}],"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["CronJob"]}}],"resources":{}},"mutate":{},"name":"autogen-cronjob-check-sa","preconditions":{"all":[{"key":"{{serviceAccountName}}","operator":"Equals","value":"*?"},{"key":"{{serviceAccountName}}","operator":"NotEquals","value":"argocd-application-controller"},{"key":"{{serviceAccountName}}","operator":"NotEquals","value":"replicaset-controller"}]},"validate":{"message":"The ServiceAccount used ({{serviceAccountName}}) to create this Pod is confined to using the same account when running the Pod. ","pattern":{"spec":{"jobTemplate":{"spec":{"template":{"spec":{"serviceAccountName":"{{serviceAccountName}}"}}}}}}}}]},"conditions":[{"lastTransitionTime":"2024-02-23T15:54:18Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":1,"verifyimages":0}}}
      kyverno.io/kubernetes-version: "1.21"
      kyverno.io/kyverno-version: 1.6.0
      policies.kyverno.io/category: Sample
      policies.kyverno.io/description: 'ServiceAccounts with privileges to create
        Pods may be able to do so and name a ServiceAccount other than the one used
        to create it. This policy checks the Pod, if created by a ServiceAccount,
        and ensures the `serviceAccountName` field matches the actual ServiceAccount.      '
      policies.kyverno.io/minversion: 1.6.0
      policies.kyverno.io/subject: Pod,ServiceAccount
      policies.kyverno.io/title: Check ServiceAccount
    creationTimestamp: "2024-04-16T06:35:22Z"
    generation: 1
    name: check-sa
    resourceVersion: "27951"
    uid: 5dfe109b-3ff2-4b69-af2d-3d7e09c7ad44
  spec:
    background: false
    rules:
    - exclude:
        any:
        - resources:
            kinds:
            - Pod
            namespaces:
            - akuity-admin
            - akuity-app-team
            - aws-ebs-csi-driver
            - aws-efs-csi-driver
            - calico-*
            - calico-apiserver
            - calico-system
            - cert-manager
            - chkk-system
            - cluster-autoscaler
            - datadog
            - external-dns
            - external-secrets
            - fw-argocd
            - fw-prometheus
            - fw-telemetry
            - gloo-blue
            - gloo-green
            - gloo-mesh
            - gloo-system
            - grafana-agent
            - insights-agent
            - k6-operator
            - karpenter
            - kube-engineering
            - kubelink-system
            - metrics-server
            - monitoring
            - rbac-manager
            - sigsci-agent
            - tigera-apiserver
            - tigera-compliance
            - tigera-guardian
            - tigera-intrusion-detection
            - tigera-operator
            - tigera-system
            - wiz
      match:
        any:
        - resources:
            kinds:
            - Pod
      name: check-sa
      preconditions:
        all:
        - key: '{{serviceAccountName}}'
          operator: Equals
          value: '*?'
        - key: '{{serviceAccountName}}'
          operator: NotEquals
          value: argocd-application-controller
        - key: '{{serviceAccountName}}'
          operator: NotEquals
          value: replicaset-controller
      validate:
        message: 'The ServiceAccount used ({{serviceAccountName}}) to create this
          Pod is confined to using the same account when running the Pod. '
        pattern:
          spec:
            serviceAccountName: '{{serviceAccountName}}'
    validationFailureAction: Enforce
  status:
    autogen:
      rules:
      - exclude:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
              namespaces:
              - akuity-admin
              - akuity-app-team
              - aws-ebs-csi-driver
              - aws-efs-csi-driver
              - calico-*
              - calico-apiserver
              - calico-system
              - cert-manager
              - chkk-system
              - cluster-autoscaler
              - datadog
              - external-dns
              - external-secrets
              - fw-argocd
              - fw-prometheus
              - fw-telemetry
              - gloo-blue
              - gloo-green
              - gloo-mesh
              - gloo-system
              - grafana-agent
              - insights-agent
              - k6-operator
              - karpenter
              - kube-engineering
              - kubelink-system
              - metrics-server
              - monitoring
              - rbac-manager
              - sigsci-agent
              - tigera-apiserver
              - tigera-compliance
              - tigera-guardian
              - tigera-intrusion-detection
              - tigera-operator
              - tigera-system
              - wiz
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
          resources: {}
        mutate: {}
        name: autogen-check-sa
        preconditions:
          all:
          - key: '{{serviceAccountName}}'
            operator: Equals
            value: '*?'
          - key: '{{serviceAccountName}}'
            operator: NotEquals
            value: argocd-application-controller
          - key: '{{serviceAccountName}}'
            operator: NotEquals
            value: replicaset-controller
        validate:
          message: 'The ServiceAccount used ({{serviceAccountName}}) to create this
            Pod is confined to using the same account when running the Pod. '
          pattern:
            spec:
              template:
                spec:
                  serviceAccountName: '{{serviceAccountName}}'
      - exclude:
          any:
          - resources:
              kinds:
              - CronJob
              namespaces:
              - akuity-admin
              - akuity-app-team
              - aws-ebs-csi-driver
              - aws-efs-csi-driver
              - calico-*
              - calico-apiserver
              - calico-system
              - cert-manager
              - chkk-system
              - cluster-autoscaler
              - datadog
              - external-dns
              - external-secrets
              - fw-argocd
              - fw-prometheus
              - fw-telemetry
              - gloo-blue
              - gloo-green
              - gloo-mesh
              - gloo-system
              - grafana-agent
              - insights-agent
              - k6-operator
              - karpenter
              - kube-engineering
              - kubelink-system
              - metrics-server
              - monitoring
              - rbac-manager
              - sigsci-agent
              - tigera-apiserver
              - tigera-compliance
              - tigera-guardian
              - tigera-intrusion-detection
              - tigera-operator
              - tigera-system
              - wiz
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - CronJob
          resources: {}
        mutate: {}
        name: autogen-cronjob-check-sa
        preconditions:
          all:
          - key: '{{serviceAccountName}}'
            operator: Equals
            value: '*?'
          - key: '{{serviceAccountName}}'
            operator: NotEquals
            value: argocd-application-controller
          - key: '{{serviceAccountName}}'
            operator: NotEquals
            value: replicaset-controller
        validate:
          message: 'The ServiceAccount used ({{serviceAccountName}}) to create this
            Pod is confined to using the same account when running the Pod. '
          pattern:
            spec:
              jobTemplate:
                spec:
                  template:
                    spec:
                      serviceAccountName: '{{serviceAccountName}}'
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:22Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/deny-privileged-profile
      controls.cfasec.com/id: hp16
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/deny-privileged-profile","controls.cfasec.com/id":"hp16","kyverno.io/kubernetes-version":"1.24","kyverno.io/kyverno-version":"1.7.1","policies.kyverno.io/category":"Pod Security Admission","policies.kyverno.io/description":"When Pod Security Admission (PSA) is enforced at the cluster level via an AdmissionConfiguration file which defines a default level at baseline or restricted, setting of a label at the `privileged` profile will effectively cause unrestricted workloads in that Namespace, overriding the cluster default. This may effectively represent a circumvention attempt and should be closely controlled. This policy ensures that only those holding the cluster-admin ClusterRole may create Namespaces which assign the label `pod-security.kubernetes.io/enforce=privileged`.","policies.kyverno.io/minversion":"1.6.0","policies.kyverno.io/severity":"medium","policies.kyverno.io/subject":"Namespace","policies.kyverno.io/title":"Deny Privileged Profile"},"creationTimestamp":"2024-02-23T16:11:27Z","generation":1,"name":"deny-privileged-profile","resourceVersion":"727837303","uid":"fac94397-028b-43f8-9d28-1b84a52e0901"},"spec":{"background":false,"rules":[{"exclude":{"any":[{"clusterRoles":["cluster-admin"]},{"resources":{"namespaces":["calico-system","calico-apiserver","tigera-operator","tigera-system","tigera-fluentd","tigera-compliance","tigera-dpi","tigera-elasticsearch"]}}]},"match":{"any":[{"resources":{"kinds":["Namespace"],"selector":{"matchLabels":{"pod-security.kubernetes.io/enforce":"privileged"}}}}]},"name":"check-privileged","validate":{"deny":{},"message":"Only cluster-admins may create Namespaces that allow setting the privileged level."}}],"validationFailureAction":"audit"},"status":{"autogen":{},"conditions":[{"lastTransitionTime":"2024-02-23T16:11:32Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":1,"verifyimages":0}}}
      kyverno.io/kubernetes-version: "1.24"
      kyverno.io/kyverno-version: 1.7.1
      policies.kyverno.io/category: Pod Security Admission
      policies.kyverno.io/description: When Pod Security Admission (PSA) is enforced
        at the cluster level via an AdmissionConfiguration file which defines a default
        level at baseline or restricted, setting of a label at the `privileged` profile
        will effectively cause unrestricted workloads in that Namespace, overriding
        the cluster default. This may effectively represent a circumvention attempt
        and should be closely controlled. This policy ensures that only those holding
        the cluster-admin ClusterRole may create Namespaces which assign the label
        `pod-security.kubernetes.io/enforce=privileged`.
      policies.kyverno.io/minversion: 1.6.0
      policies.kyverno.io/severity: medium
      policies.kyverno.io/subject: Namespace
      policies.kyverno.io/title: Deny Privileged Profile
    creationTimestamp: "2024-04-16T06:35:22Z"
    generation: 1
    name: deny-privileged-profile
    resourceVersion: "27987"
    uid: 2caadb1c-c967-4ac6-8b7a-13562345a459
  spec:
    background: false
    rules:
    - exclude:
        any:
        - clusterRoles:
          - cluster-admin
        - resources:
            namespaces:
            - calico-system
            - calico-apiserver
            - tigera-operator
            - tigera-system
            - tigera-fluentd
            - tigera-compliance
            - tigera-dpi
            - tigera-elasticsearch
      match:
        any:
        - resources:
            kinds:
            - Namespace
            selector:
              matchLabels:
                pod-security.kubernetes.io/enforce: privileged
      name: check-privileged
      validate:
        deny: {}
        message: Only cluster-admins may create Namespaces that allow setting the
          privileged level.
    validationFailureAction: audit
  status:
    autogen: {}
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:22Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/disable-automountserviceaccounttoken
      controls.cfasec.com/id: sm1
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/disable-automountserviceaccounttoken","controls.cfasec.com/id":"sm1","kyverno.io/kubernetes-version":"1.21","kyverno.io/kyverno-version":"1.5.1","policies.kyverno.io/category":"Other","policies.kyverno.io/description":"A new ServiceAccount called `default` is created whenever a new Namespace is created. Pods spawned in that Namespace, unless otherwise set, will be assigned this ServiceAccount. This policy mutates any new `default` ServiceAccounts to disable auto-mounting of the token into Pods obviating the need to do so individually.","policies.kyverno.io/severity":"medium","policies.kyverno.io/subject":"ServiceAccount","policies.kyverno.io/title":"Disable automountServiceAccountToken"},"creationTimestamp":"2024-02-23T15:56:33Z","generation":1,"name":"disable-automountserviceaccounttoken","resourceVersion":"727814532","uid":"4d275052-1b96-4f63-a539-62d77588e155"},"spec":{"background":true,"rules":[{"match":{"resources":{"kinds":["ServiceAccount"],"names":["default"]}},"mutate":{"patchStrategicMerge":{"automountServiceAccountToken":false}},"name":"disable-automountserviceaccounttoken"}],"validationFailureAction":"Audit"},"status":{"autogen":{},"conditions":[{"lastTransitionTime":"2024-02-23T15:57:03Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":1,"validate":0,"verifyimages":0}}}
      kyverno.io/kubernetes-version: "1.21"
      kyverno.io/kyverno-version: 1.5.1
      policies.kyverno.io/category: Other
      policies.kyverno.io/description: A new ServiceAccount called `default` is created
        whenever a new Namespace is created. Pods spawned in that Namespace, unless
        otherwise set, will be assigned this ServiceAccount. This policy mutates any
        new `default` ServiceAccounts to disable auto-mounting of the token into Pods
        obviating the need to do so individually.
      policies.kyverno.io/severity: medium
      policies.kyverno.io/subject: ServiceAccount
      policies.kyverno.io/title: Disable automountServiceAccountToken
    creationTimestamp: "2024-04-16T06:35:22Z"
    generation: 1
    name: disable-automountserviceaccounttoken
    resourceVersion: "28033"
    uid: 1549333e-0ed3-4c4a-a906-5f1495713694
  spec:
    background: true
    rules:
    - match:
        resources:
          kinds:
          - ServiceAccount
          names:
          - default
      mutate:
        patchStrategicMerge:
          automountServiceAccountToken: false
      name: disable-automountserviceaccounttoken
    validationFailureAction: Audit
  status:
    autogen: {}
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:23Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 1
      validate: 0
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/disallow-capabilities-strict
      controls.cfasec.com/id: hp4
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/disallow-capabilities-strict","controls.cfasec.com/id":"hp4","kyverno.io/kubernetes-version":"1.22-1.23","kyverno.io/kyverno-version":"1.6.0","policies.kyverno.io/category":"Pod Security Standards (Restricted)","policies.kyverno.io/description":"Adding capabilities other than `NET_BIND_SERVICE` is disallowed. In addition, all containers must explicitly drop `ALL` capabilities.","policies.kyverno.io/minversion":"1.6.0","policies.kyverno.io/severity":"medium","policies.kyverno.io/subject":"Pod","policies.kyverno.io/title":"Disallow Capabilities (Strict)"},"creationTimestamp":"2024-02-23T16:11:27Z","generation":1,"name":"disallow-capabilities-strict","resourceVersion":"727837335","uid":"80ccc220-6a9f-4324-b73a-b59af7ccc0c5"},"spec":{"background":true,"rules":[{"exclude":{"any":[{"resources":{"kinds":["Pod"],"namespaces":["aws-ebs-csi-driver","aws-efs-csi-driver","calico-apiserver","calico-system","datadog","fw-prometheus","gloo-blue","gloo-green","gloo-system","monitoring","sigsci-agent","tigera-operator"]}}]},"match":{"any":[{"resources":{"kinds":["Pod"]}}]},"name":"require-drop-all","preconditions":{"all":[{"key":"{{ request.operation }}","operator":"NotEquals","value":"DELETE"}]},"validate":{"foreach":[{"deny":{"conditions":{"all":[{"key":"ALL","operator":"AnyNotIn","value":"{{ element.securityContext.capabilities.drop || '' }}"}]}},"list":"request.object.spec.[ephemeralContainers, initContainers, containers][]"}],"message":"Containers must drop `ALL` capabilities."}},{"exclude":{"any":[{"resources":{"kinds":["Pod"],"namespaces":["aws-ebs-csi-driver","aws-efs-csi-driver","calico-apiserver","calico-system","datadog"]}}]},"match":{"any":[{"resources":{"kinds":["Pod"]}}]},"name":"adding-capabilities-strict","preconditions":{"all":[{"key":"{{ request.operation }}","operator":"NotEquals","value":"DELETE"}]},"validate":{"foreach":[{"deny":{"conditions":{"all":[{"key":"{{ element.securityContext.capabilities.add[] || '' }}","operator":"AnyNotIn","value":["NET_BIND_SERVICE",""]}]}},"list":"request.object.spec.[ephemeralContainers, initContainers, containers][]"}],"message":"Any capabilities added other than NET_BIND_SERVICE are disallowed."}}],"validationFailureAction":"audit"},"status":{"autogen":{"rules":[{"exclude":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"],"namespaces":["aws-ebs-csi-driver","aws-efs-csi-driver","calico-apiserver","calico-system","datadog","fw-prometheus","gloo-blue","gloo-green","gloo-system","monitoring","sigsci-agent","tigera-operator"]}}],"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"]}}],"resources":{}},"mutate":{},"name":"autogen-require-drop-all","preconditions":{"all":[{"key":"{{ request.operation }}","operator":"NotEquals","value":"DELETE"}]},"validate":{"foreach":[{"deny":{"conditions":{"all":[{"key":"ALL","operator":"AnyNotIn","value":"{{ element.securityContext.capabilities.drop || '' }}"}]}},"list":"request.object.spec.template.spec.[ephemeralContainers, initContainers, containers][]"}],"message":"Containers must drop `ALL` capabilities."}},{"exclude":{"any":[{"resources":{"kinds":["CronJob"],"namespaces":["aws-ebs-csi-driver","aws-efs-csi-driver","calico-apiserver","calico-system","datadog","fw-prometheus","gloo-blue","gloo-green","gloo-system","monitoring","sigsci-agent","tigera-operator"]}}],"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["CronJob"]}}],"resources":{}},"mutate":{},"name":"autogen-cronjob-require-drop-all","preconditions":{"all":[{"key":"{{ request.operation }}","operator":"NotEquals","value":"DELETE"}]},"validate":{"foreach":[{"deny":{"conditions":{"all":[{"key":"ALL","operator":"AnyNotIn","value":"{{ element.securityContext.capabilities.drop || '' }}"}]}},"list":"request.object.spec.jobTemplate.spec.template.spec.[ephemeralContainers, initContainers, containers][]"}],"message":"Containers must drop `ALL` capabilities."}},{"exclude":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"],"namespaces":["aws-ebs-csi-driver","aws-efs-csi-driver","calico-apiserver","calico-system","datadog"]}}],"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"]}}],"resources":{}},"mutate":{},"name":"autogen-adding-capabilities-strict","preconditions":{"all":[{"key":"{{ request.operation }}","operator":"NotEquals","value":"DELETE"}]},"validate":{"foreach":[{"deny":{"conditions":{"all":[{"key":"{{ element.securityContext.capabilities.add[] || '' }}","operator":"AnyNotIn","value":["NET_BIND_SERVICE",""]}]}},"list":"request.object.spec.template.spec.[ephemeralContainers, initContainers, containers][]"}],"message":"Any capabilities added other than NET_BIND_SERVICE are disallowed."}},{"exclude":{"any":[{"resources":{"kinds":["CronJob"],"namespaces":["aws-ebs-csi-driver","aws-efs-csi-driver","calico-apiserver","calico-system","datadog"]}}],"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["CronJob"]}}],"resources":{}},"mutate":{},"name":"autogen-cronjob-adding-capabilities-strict","preconditions":{"all":[{"key":"{{ request.operation }}","operator":"NotEquals","value":"DELETE"}]},"validate":{"foreach":[{"deny":{"conditions":{"all":[{"key":"{{ element.securityContext.capabilities.add[] || '' }}","operator":"AnyNotIn","value":["NET_BIND_SERVICE",""]}]}},"list":"request.object.spec.jobTemplate.spec.template.spec.[ephemeralContainers, initContainers, containers][]"}],"message":"Any capabilities added other than NET_BIND_SERVICE are disallowed."}}]},"conditions":[{"lastTransitionTime":"2024-02-23T16:11:32Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":2,"verifyimages":0}}}
      kyverno.io/kubernetes-version: 1.22-1.23
      kyverno.io/kyverno-version: 1.6.0
      policies.kyverno.io/category: Pod Security Standards (Restricted)
      policies.kyverno.io/description: Adding capabilities other than `NET_BIND_SERVICE`
        is disallowed. In addition, all containers must explicitly drop `ALL` capabilities.
      policies.kyverno.io/minversion: 1.6.0
      policies.kyverno.io/severity: medium
      policies.kyverno.io/subject: Pod
      policies.kyverno.io/title: Disallow Capabilities (Strict)
    creationTimestamp: "2024-04-16T06:35:23Z"
    generation: 1
    name: disallow-capabilities-strict
    resourceVersion: "28065"
    uid: f88550cc-a657-42d2-8a1d-690c8a705073
  spec:
    background: true
    rules:
    - exclude:
        any:
        - resources:
            kinds:
            - Pod
            namespaces:
            - aws-ebs-csi-driver
            - aws-efs-csi-driver
            - calico-apiserver
            - calico-system
            - datadog
            - fw-prometheus
            - gloo-blue
            - gloo-green
            - gloo-system
            - monitoring
            - sigsci-agent
            - tigera-operator
      match:
        any:
        - resources:
            kinds:
            - Pod
      name: require-drop-all
      preconditions:
        all:
        - key: '{{ request.operation }}'
          operator: NotEquals
          value: DELETE
      validate:
        foreach:
        - deny:
            conditions:
              all:
              - key: ALL
                operator: AnyNotIn
                value: '{{ element.securityContext.capabilities.drop || '''' }}'
          list: request.object.spec.[ephemeralContainers, initContainers, containers][]
        message: Containers must drop `ALL` capabilities.
    - exclude:
        any:
        - resources:
            kinds:
            - Pod
            namespaces:
            - aws-ebs-csi-driver
            - aws-efs-csi-driver
            - calico-apiserver
            - calico-system
            - datadog
      match:
        any:
        - resources:
            kinds:
            - Pod
      name: adding-capabilities-strict
      preconditions:
        all:
        - key: '{{ request.operation }}'
          operator: NotEquals
          value: DELETE
      validate:
        foreach:
        - deny:
            conditions:
              all:
              - key: '{{ element.securityContext.capabilities.add[] || '''' }}'
                operator: AnyNotIn
                value:
                - NET_BIND_SERVICE
                - ""
          list: request.object.spec.[ephemeralContainers, initContainers, containers][]
        message: Any capabilities added other than NET_BIND_SERVICE are disallowed.
    validationFailureAction: audit
  status:
    autogen:
      rules:
      - exclude:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
              namespaces:
              - aws-ebs-csi-driver
              - aws-efs-csi-driver
              - calico-apiserver
              - calico-system
              - datadog
              - fw-prometheus
              - gloo-blue
              - gloo-green
              - gloo-system
              - monitoring
              - sigsci-agent
              - tigera-operator
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
          resources: {}
        mutate: {}
        name: autogen-require-drop-all
        preconditions:
          all:
          - key: '{{ request.operation }}'
            operator: NotEquals
            value: DELETE
        validate:
          foreach:
          - deny:
              conditions:
                all:
                - key: ALL
                  operator: AnyNotIn
                  value: '{{ element.securityContext.capabilities.drop || '''' }}'
            list: request.object.spec.template.spec.[ephemeralContainers, initContainers,
              containers][]
          message: Containers must drop `ALL` capabilities.
      - exclude:
          any:
          - resources:
              kinds:
              - CronJob
              namespaces:
              - aws-ebs-csi-driver
              - aws-efs-csi-driver
              - calico-apiserver
              - calico-system
              - datadog
              - fw-prometheus
              - gloo-blue
              - gloo-green
              - gloo-system
              - monitoring
              - sigsci-agent
              - tigera-operator
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - CronJob
          resources: {}
        mutate: {}
        name: autogen-cronjob-require-drop-all
        preconditions:
          all:
          - key: '{{ request.operation }}'
            operator: NotEquals
            value: DELETE
        validate:
          foreach:
          - deny:
              conditions:
                all:
                - key: ALL
                  operator: AnyNotIn
                  value: '{{ element.securityContext.capabilities.drop || '''' }}'
            list: request.object.spec.jobTemplate.spec.template.spec.[ephemeralContainers,
              initContainers, containers][]
          message: Containers must drop `ALL` capabilities.
      - exclude:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
              namespaces:
              - aws-ebs-csi-driver
              - aws-efs-csi-driver
              - calico-apiserver
              - calico-system
              - datadog
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
          resources: {}
        mutate: {}
        name: autogen-adding-capabilities-strict
        preconditions:
          all:
          - key: '{{ request.operation }}'
            operator: NotEquals
            value: DELETE
        validate:
          foreach:
          - deny:
              conditions:
                all:
                - key: '{{ element.securityContext.capabilities.add[] || '''' }}'
                  operator: AnyNotIn
                  value:
                  - NET_BIND_SERVICE
                  - ""
            list: request.object.spec.template.spec.[ephemeralContainers, initContainers,
              containers][]
          message: Any capabilities added other than NET_BIND_SERVICE are disallowed.
      - exclude:
          any:
          - resources:
              kinds:
              - CronJob
              namespaces:
              - aws-ebs-csi-driver
              - aws-efs-csi-driver
              - calico-apiserver
              - calico-system
              - datadog
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - CronJob
          resources: {}
        mutate: {}
        name: autogen-cronjob-adding-capabilities-strict
        preconditions:
          all:
          - key: '{{ request.operation }}'
            operator: NotEquals
            value: DELETE
        validate:
          foreach:
          - deny:
              conditions:
                all:
                - key: '{{ element.securityContext.capabilities.add[] || '''' }}'
                  operator: AnyNotIn
                  value:
                  - NET_BIND_SERVICE
                  - ""
            list: request.object.spec.jobTemplate.spec.template.spec.[ephemeralContainers,
              initContainers, containers][]
          message: Any capabilities added other than NET_BIND_SERVICE are disallowed.
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:23Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 2
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/disallow-container-sock-mounts
      controls.cfasec.com/id: hp18
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/disallow-container-sock-mounts","controls.cfasec.com/id":"hp18","policies.kyverno.io/category":"Best Practices","policies.kyverno.io/description":"Container daemon socket bind mounts allows access to the container engine on the node. This access can be used for privilege escalation and to manage containers outside of Kubernetes, and hence should not be allowed. This policy validates that the sockets used for CRI engines Docker, Containerd, and CRI-O are not used.","policies.kyverno.io/severity":"medium","policies.kyverno.io/subject":"Pod","policies.kyverno.io/title":"Disallow CRI socket mounts"},"creationTimestamp":"2024-02-23T16:11:27Z","generation":1,"name":"disallow-container-sock-mounts","resourceVersion":"727837324","uid":"931497ee-f1fe-453d-8498-33e3f622836d"},"spec":{"background":true,"rules":[{"match":{"resources":{"kinds":["Pod"]}},"name":"validate-docker-sock-mount","validate":{"message":"Use of the Docker Unix socket is not allowed.","pattern":{"spec":{"=(volumes)":[{"=(hostPath)":{"path":"!/var/run/docker.sock"}}]}}}},{"match":{"resources":{"kinds":["Pod"]}},"name":"validate-containerd-sock-mount","validate":{"message":"Use of the Containerd Unix socket is not allowed.","pattern":{"spec":{"=(volumes)":[{"=(hostPath)":{"path":"!/var/run/containerd.sock"}}]}}}},{"match":{"resources":{"kinds":["Pod"]}},"name":"validate-crio-sock-mount","validate":{"message":"Use of the CRI-O Unix socket is not allowed.","pattern":{"spec":{"=(volumes)":[{"=(hostPath)":{"path":"!/var/run/crio.sock"}}]}}}}],"validationFailureAction":"audit"},"status":{"autogen":{"rules":[{"exclude":{"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"]}},"mutate":{},"name":"autogen-validate-docker-sock-mount","validate":{"message":"Use of the Docker Unix socket is not allowed.","pattern":{"spec":{"template":{"spec":{"=(volumes)":[{"=(hostPath)":{"path":"!/var/run/docker.sock"}}]}}}}}},{"exclude":{"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"resources":{"kinds":["CronJob"]}},"mutate":{},"name":"autogen-cronjob-validate-docker-sock-mount","validate":{"message":"Use of the Docker Unix socket is not allowed.","pattern":{"spec":{"jobTemplate":{"spec":{"template":{"spec":{"=(volumes)":[{"=(hostPath)":{"path":"!/var/run/docker.sock"}}]}}}}}}}},{"exclude":{"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"]}},"mutate":{},"name":"autogen-validate-containerd-sock-mount","validate":{"message":"Use of the Containerd Unix socket is not allowed.","pattern":{"spec":{"template":{"spec":{"=(volumes)":[{"=(hostPath)":{"path":"!/var/run/containerd.sock"}}]}}}}}},{"exclude":{"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"resources":{"kinds":["CronJob"]}},"mutate":{},"name":"autogen-cronjob-validate-containerd-sock-mount","validate":{"message":"Use of the Containerd Unix socket is not allowed.","pattern":{"spec":{"jobTemplate":{"spec":{"template":{"spec":{"=(volumes)":[{"=(hostPath)":{"path":"!/var/run/containerd.sock"}}]}}}}}}}},{"exclude":{"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"]}},"mutate":{},"name":"autogen-validate-crio-sock-mount","validate":{"message":"Use of the CRI-O Unix socket is not allowed.","pattern":{"spec":{"template":{"spec":{"=(volumes)":[{"=(hostPath)":{"path":"!/var/run/crio.sock"}}]}}}}}},{"exclude":{"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"resources":{"kinds":["CronJob"]}},"mutate":{},"name":"autogen-cronjob-validate-crio-sock-mount","validate":{"message":"Use of the CRI-O Unix socket is not allowed.","pattern":{"spec":{"jobTemplate":{"spec":{"template":{"spec":{"=(volumes)":[{"=(hostPath)":{"path":"!/var/run/crio.sock"}}]}}}}}}}}]},"conditions":[{"lastTransitionTime":"2024-02-23T16:11:32Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":3,"verifyimages":0}}}
      policies.kyverno.io/category: Best Practices
      policies.kyverno.io/description: Container daemon socket bind mounts allows
        access to the container engine on the node. This access can be used for privilege
        escalation and to manage containers outside of Kubernetes, and hence should
        not be allowed. This policy validates that the sockets used for CRI engines
        Docker, Containerd, and CRI-O are not used.
      policies.kyverno.io/severity: medium
      policies.kyverno.io/subject: Pod
      policies.kyverno.io/title: Disallow CRI socket mounts
    creationTimestamp: "2024-04-16T06:35:23Z"
    generation: 1
    name: disallow-container-sock-mounts
    resourceVersion: "28087"
    uid: 5d1cc214-192d-47d4-a327-6fe3dfa29abf
  spec:
    background: true
    rules:
    - match:
        resources:
          kinds:
          - Pod
      name: validate-docker-sock-mount
      validate:
        message: Use of the Docker Unix socket is not allowed.
        pattern:
          spec:
            =(volumes):
            - =(hostPath):
                path: '!/var/run/docker.sock'
    - match:
        resources:
          kinds:
          - Pod
      name: validate-containerd-sock-mount
      validate:
        message: Use of the Containerd Unix socket is not allowed.
        pattern:
          spec:
            =(volumes):
            - =(hostPath):
                path: '!/var/run/containerd.sock'
    - match:
        resources:
          kinds:
          - Pod
      name: validate-crio-sock-mount
      validate:
        message: Use of the CRI-O Unix socket is not allowed.
        pattern:
          spec:
            =(volumes):
            - =(hostPath):
                path: '!/var/run/crio.sock'
    validationFailureAction: audit
  status:
    autogen:
      rules:
      - exclude:
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          resources:
            kinds:
            - DaemonSet
            - Deployment
            - Job
            - StatefulSet
            - ReplicaSet
            - ReplicationController
        mutate: {}
        name: autogen-validate-docker-sock-mount
        validate:
          message: Use of the Docker Unix socket is not allowed.
          pattern:
            spec:
              template:
                spec:
                  =(volumes):
                  - =(hostPath):
                      path: '!/var/run/docker.sock'
      - exclude:
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          resources:
            kinds:
            - CronJob
        mutate: {}
        name: autogen-cronjob-validate-docker-sock-mount
        validate:
          message: Use of the Docker Unix socket is not allowed.
          pattern:
            spec:
              jobTemplate:
                spec:
                  template:
                    spec:
                      =(volumes):
                      - =(hostPath):
                          path: '!/var/run/docker.sock'
      - exclude:
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          resources:
            kinds:
            - DaemonSet
            - Deployment
            - Job
            - StatefulSet
            - ReplicaSet
            - ReplicationController
        mutate: {}
        name: autogen-validate-containerd-sock-mount
        validate:
          message: Use of the Containerd Unix socket is not allowed.
          pattern:
            spec:
              template:
                spec:
                  =(volumes):
                  - =(hostPath):
                      path: '!/var/run/containerd.sock'
      - exclude:
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          resources:
            kinds:
            - CronJob
        mutate: {}
        name: autogen-cronjob-validate-containerd-sock-mount
        validate:
          message: Use of the Containerd Unix socket is not allowed.
          pattern:
            spec:
              jobTemplate:
                spec:
                  template:
                    spec:
                      =(volumes):
                      - =(hostPath):
                          path: '!/var/run/containerd.sock'
      - exclude:
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          resources:
            kinds:
            - DaemonSet
            - Deployment
            - Job
            - StatefulSet
            - ReplicaSet
            - ReplicationController
        mutate: {}
        name: autogen-validate-crio-sock-mount
        validate:
          message: Use of the CRI-O Unix socket is not allowed.
          pattern:
            spec:
              template:
                spec:
                  =(volumes):
                  - =(hostPath):
                      path: '!/var/run/crio.sock'
      - exclude:
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          resources:
            kinds:
            - CronJob
        mutate: {}
        name: autogen-cronjob-validate-crio-sock-mount
        validate:
          message: Use of the CRI-O Unix socket is not allowed.
          pattern:
            spec:
              jobTemplate:
                spec:
                  template:
                    spec:
                      =(volumes):
                      - =(hostPath):
                          path: '!/var/run/crio.sock'
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:23Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 3
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/disallow-default-namespace
      controls.cfasec.com/id: ns1
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/disallow-default-namespace","controls.cfasec.com/id":"ns1","pod-policies.kyverno.io/autogen-controllers":"none","policies.kyverno.io/category":"Multi-Tenancy","policies.kyverno.io/description":"Kubernetes Namespaces are an optional feature that provide a way to segment and isolate cluster resources across multiple applications and users. As a best practice, workloads should be isolated with Namespaces. Namespaces should be required and the default (empty) Namespace should not be used. This policy validates that Pods specify a Namespace name other than `default`.      ","policies.kyverno.io/severity":"medium","policies.kyverno.io/subject":"Pod","policies.kyverno.io/title":"Disallow Default Namespace"},"creationTimestamp":"2024-02-23T15:54:14Z","generation":1,"name":"disallow-default-namespace","resourceVersion":"727809664","uid":"2eac8193-0eb1-420a-96f6-c468fed12817"},"spec":{"background":true,"rules":[{"match":{"resources":{"kinds":["Pod"]}},"name":"validate-namespace","validate":{"message":"Using 'default' namespace is not allowed.","pattern":{"metadata":{"namespace":"!default"}}}},{"match":{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet"]}},"name":"validate-podcontroller-namespace","validate":{"message":"Using 'default' namespace is not allowed for pod controllers.","pattern":{"metadata":{"namespace":"!default"}}}}],"validationFailureAction":"audit"},"status":{"autogen":{},"conditions":[{"lastTransitionTime":"2024-02-23T15:54:19Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":2,"verifyimages":0}}}
      pod-policies.kyverno.io/autogen-controllers: none
      policies.kyverno.io/category: Multi-Tenancy
      policies.kyverno.io/description: 'Kubernetes Namespaces are an optional feature
        that provide a way to segment and isolate cluster resources across multiple
        applications and users. As a best practice, workloads should be isolated with
        Namespaces. Namespaces should be required and the default (empty) Namespace
        should not be used. This policy validates that Pods specify a Namespace name
        other than `default`.      '
      policies.kyverno.io/severity: medium
      policies.kyverno.io/subject: Pod
      policies.kyverno.io/title: Disallow Default Namespace
    creationTimestamp: "2024-04-16T06:35:23Z"
    generation: 1
    name: disallow-default-namespace
    resourceVersion: "28116"
    uid: 571a8d7e-781d-4f68-842b-41ee3fb25b91
  spec:
    background: true
    rules:
    - match:
        resources:
          kinds:
          - Pod
      name: validate-namespace
      validate:
        message: Using 'default' namespace is not allowed.
        pattern:
          metadata:
            namespace: '!default'
    - match:
        resources:
          kinds:
          - DaemonSet
          - Deployment
          - Job
          - StatefulSet
      name: validate-podcontroller-namespace
      validate:
        message: Using 'default' namespace is not allowed for pod controllers.
        pattern:
          metadata:
            namespace: '!default'
    validationFailureAction: audit
  status:
    autogen: {}
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:24Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 2
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/disallow-helm-tiller
      controls.cfasec.com/id: pod5
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/disallow-helm-tiller","controls.cfasec.com/id":"pod5","policies.kyverno.io/category":"Sample","policies.kyverno.io/description":"Tiller, found in Helm v2, has known security challenges. It requires administrative privileges and acts as a shared resource accessible to any authenticated user. Tiller can lead to privilege escalation as restricted users can impact other users. It is recommend to use Helm v3+ which does not contain Tiller for these reasons. This policy validates that there is not an image containing the name `tiller`.","policies.kyverno.io/severity":"medium","policies.kyverno.io/subject":"Pod","policies.kyverno.io/title":"Disallow Helm Tiller"},"creationTimestamp":"2024-02-23T15:54:14Z","generation":1,"name":"disallow-helm-tiller","resourceVersion":"727809657","uid":"6db4a0a2-fb5a-4093-928e-f70f3f22174a"},"spec":{"background":true,"rules":[{"match":{"resources":{"kinds":["Pod"]}},"name":"validate-helm-tiller","validate":{"message":"Helm Tiller is not allowed","pattern":{"spec":{"containers":[{"image":"!*tiller*","name":"*"}]}}}}],"validationFailureAction":"audit"},"status":{"autogen":{"rules":[{"exclude":{"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"]}},"mutate":{},"name":"autogen-validate-helm-tiller","validate":{"message":"Helm Tiller is not allowed","pattern":{"spec":{"template":{"spec":{"containers":[{"image":"!*tiller*","name":"*"}]}}}}}},{"exclude":{"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"resources":{"kinds":["CronJob"]}},"mutate":{},"name":"autogen-cronjob-validate-helm-tiller","validate":{"message":"Helm Tiller is not allowed","pattern":{"spec":{"jobTemplate":{"spec":{"template":{"spec":{"containers":[{"image":"!*tiller*","name":"*"}]}}}}}}}}]},"conditions":[{"lastTransitionTime":"2024-02-23T15:54:19Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":1,"verifyimages":0}}}
      policies.kyverno.io/category: Sample
      policies.kyverno.io/description: Tiller, found in Helm v2, has known security
        challenges. It requires administrative privileges and acts as a shared resource
        accessible to any authenticated user. Tiller can lead to privilege escalation
        as restricted users can impact other users. It is recommend to use Helm v3+
        which does not contain Tiller for these reasons. This policy validates that
        there is not an image containing the name `tiller`.
      policies.kyverno.io/severity: medium
      policies.kyverno.io/subject: Pod
      policies.kyverno.io/title: Disallow Helm Tiller
    creationTimestamp: "2024-04-16T06:35:24Z"
    generation: 1
    name: disallow-helm-tiller
    resourceVersion: "28144"
    uid: aaf2abd7-8bb3-4f4d-a5ca-5a5c771e1028
  spec:
    background: true
    rules:
    - match:
        resources:
          kinds:
          - Pod
      name: validate-helm-tiller
      validate:
        message: Helm Tiller is not allowed
        pattern:
          spec:
            containers:
            - image: '!*tiller*'
              name: '*'
    validationFailureAction: audit
  status:
    autogen:
      rules:
      - exclude:
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          resources:
            kinds:
            - DaemonSet
            - Deployment
            - Job
            - StatefulSet
            - ReplicaSet
            - ReplicationController
        mutate: {}
        name: autogen-validate-helm-tiller
        validate:
          message: Helm Tiller is not allowed
          pattern:
            spec:
              template:
                spec:
                  containers:
                  - image: '!*tiller*'
                    name: '*'
      - exclude:
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          resources:
            kinds:
            - CronJob
        mutate: {}
        name: autogen-cronjob-validate-helm-tiller
        validate:
          message: Helm Tiller is not allowed
          pattern:
            spec:
              jobTemplate:
                spec:
                  template:
                    spec:
                      containers:
                      - image: '!*tiller*'
                        name: '*'
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:24Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/disallow-host-namespaces
      controls.cfasec.com/id: hp5
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/disallow-host-namespaces","controls.cfasec.com/id":"hp5","kyverno.io/kubernetes-version":"1.22-1.23","kyverno.io/kyverno-version":"1.6.0","policies.kyverno.io/category":"Pod Security Standards (Baseline)","policies.kyverno.io/description":"Host namespaces (Process ID namespace, Inter-Process Communication namespace, and network namespace) allow access to shared information and can be used to elevate privileges. Pods should not be allowed access to host namespaces. This policy ensures fields which make use of these host namespaces are unset or set to `false`.","policies.kyverno.io/severity":"medium","policies.kyverno.io/subject":"Pod","policies.kyverno.io/title":"Disallow Host Namespaces"},"creationTimestamp":"2024-02-23T16:11:27Z","generation":1,"name":"disallow-host-namespaces","resourceVersion":"727837310","uid":"3b5b442b-b27e-4140-9694-d511203c8fc8"},"spec":{"background":true,"rules":[{"exclude":{"any":[{"resources":{"kinds":["Pod"],"namespaces":["calico-system","calico-apiserver","tigera-operator","aws-ebs-csi-driver","aws-efs-csi-driver","datadog","fw-prometheus"]}}]},"match":{"any":[{"resources":{"kinds":["Pod"]}}]},"name":"host-namespaces","validate":{"message":"Sharing the host namespaces is disallowed. The fields spec.hostNetwork, spec.hostIPC, and spec.hostPID must be unset or set to `false`.","pattern":{"spec":{"=(hostIPC)":"false","=(hostNetwork)":"false","=(hostPID)":"false"}}}}],"validationFailureAction":"audit"},"status":{"autogen":{"rules":[{"exclude":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"],"namespaces":["calico-system","calico-apiserver","tigera-operator","aws-ebs-csi-driver","aws-efs-csi-driver","datadog","fw-prometheus"]}}],"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"]}}],"resources":{}},"mutate":{},"name":"autogen-host-namespaces","validate":{"message":"Sharing the host namespaces is disallowed. The fields spec.hostNetwork, spec.hostIPC, and spec.hostPID must be unset or set to `false`.","pattern":{"spec":{"template":{"spec":{"=(hostIPC)":"false","=(hostNetwork)":"false","=(hostPID)":"false"}}}}}},{"exclude":{"any":[{"resources":{"kinds":["CronJob"],"namespaces":["calico-system","calico-apiserver","tigera-operator","aws-ebs-csi-driver","aws-efs-csi-driver","datadog","fw-prometheus"]}}],"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["CronJob"]}}],"resources":{}},"mutate":{},"name":"autogen-cronjob-host-namespaces","validate":{"message":"Sharing the host namespaces is disallowed. The fields spec.hostNetwork, spec.hostIPC, and spec.hostPID must be unset or set to `false`.","pattern":{"spec":{"jobTemplate":{"spec":{"template":{"spec":{"=(hostIPC)":"false","=(hostNetwork)":"false","=(hostPID)":"false"}}}}}}}}]},"conditions":[{"lastTransitionTime":"2024-02-23T16:11:32Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":1,"verifyimages":0}}}
      kyverno.io/kubernetes-version: 1.22-1.23
      kyverno.io/kyverno-version: 1.6.0
      policies.kyverno.io/category: Pod Security Standards (Baseline)
      policies.kyverno.io/description: Host namespaces (Process ID namespace, Inter-Process
        Communication namespace, and network namespace) allow access to shared information
        and can be used to elevate privileges. Pods should not be allowed access to
        host namespaces. This policy ensures fields which make use of these host namespaces
        are unset or set to `false`.
      policies.kyverno.io/severity: medium
      policies.kyverno.io/subject: Pod
      policies.kyverno.io/title: Disallow Host Namespaces
    creationTimestamp: "2024-04-16T06:35:24Z"
    generation: 1
    name: disallow-host-namespaces
    resourceVersion: "28190"
    uid: 7f192845-88d4-4d8d-97b1-b1f18ee3a6fe
  spec:
    background: true
    rules:
    - exclude:
        any:
        - resources:
            kinds:
            - Pod
            namespaces:
            - calico-system
            - calico-apiserver
            - tigera-operator
            - aws-ebs-csi-driver
            - aws-efs-csi-driver
            - datadog
            - fw-prometheus
      match:
        any:
        - resources:
            kinds:
            - Pod
      name: host-namespaces
      validate:
        message: Sharing the host namespaces is disallowed. The fields spec.hostNetwork,
          spec.hostIPC, and spec.hostPID must be unset or set to `false`.
        pattern:
          spec:
            =(hostIPC): "false"
            =(hostNetwork): "false"
            =(hostPID): "false"
    validationFailureAction: audit
  status:
    autogen:
      rules:
      - exclude:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
              namespaces:
              - calico-system
              - calico-apiserver
              - tigera-operator
              - aws-ebs-csi-driver
              - aws-efs-csi-driver
              - datadog
              - fw-prometheus
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
          resources: {}
        mutate: {}
        name: autogen-host-namespaces
        validate:
          message: Sharing the host namespaces is disallowed. The fields spec.hostNetwork,
            spec.hostIPC, and spec.hostPID must be unset or set to `false`.
          pattern:
            spec:
              template:
                spec:
                  =(hostIPC): "false"
                  =(hostNetwork): "false"
                  =(hostPID): "false"
      - exclude:
          any:
          - resources:
              kinds:
              - CronJob
              namespaces:
              - calico-system
              - calico-apiserver
              - tigera-operator
              - aws-ebs-csi-driver
              - aws-efs-csi-driver
              - datadog
              - fw-prometheus
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - CronJob
          resources: {}
        mutate: {}
        name: autogen-cronjob-host-namespaces
        validate:
          message: Sharing the host namespaces is disallowed. The fields spec.hostNetwork,
            spec.hostIPC, and spec.hostPID must be unset or set to `false`.
          pattern:
            spec:
              jobTemplate:
                spec:
                  template:
                    spec:
                      =(hostIPC): "false"
                      =(hostNetwork): "false"
                      =(hostPID): "false"
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:24Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/disallow-host-path
      controls.cfasec.com/id: hp6
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/disallow-host-path","controls.cfasec.com/id":"hp6","kyverno.io/kubernetes-version":"1.22-1.23","kyverno.io/kyverno-version":"1.6.0","policies.kyverno.io/category":"Pod Security Standards (Baseline)","policies.kyverno.io/description":"HostPath volumes let Pods use host directories and volumes in containers. Using host resources can be used to access shared data or escalate privileges and should not be allowed. This policy ensures no hostPath volumes are in use.","policies.kyverno.io/severity":"medium","policies.kyverno.io/subject":"Pod,Volume","policies.kyverno.io/title":"Disallow hostPath"},"creationTimestamp":"2024-02-23T15:56:32Z","generation":1,"name":"disallow-host-path","resourceVersion":"727814521","uid":"e5ca12ba-42f4-4c2e-903a-ccacd30c5348"},"spec":{"background":true,"rules":[{"exclude":{"any":[{"resources":{"kinds":["Pod"],"namespaces":["aws-ebs-csi-driver","aws-efs-csi-driver","brupop-bottlerocket-aws","calico-apiserver","calico-system","datadog","fw-prometheus","grafana-agent","kube-system","monitoring","tigera-operator"]}}]},"match":{"any":[{"resources":{"kinds":["Pod"]}}]},"name":"host-path","validate":{"message":"HostPath volumes are forbidden. The field spec.volumes[*].hostPath must be unset.","pattern":{"spec":{"=(volumes)":[{"X(hostPath)":"null"}]}}}}],"validationFailureAction":"audit"},"status":{"autogen":{"rules":[{"exclude":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"],"namespaces":["aws-ebs-csi-driver","aws-efs-csi-driver","brupop-bottlerocket-aws","calico-apiserver","calico-system","datadog","fw-prometheus","grafana-agent","kube-system","monitoring","tigera-operator"]}}],"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"]}}],"resources":{}},"mutate":{},"name":"autogen-host-path","validate":{"message":"HostPath volumes are forbidden. The field spec.volumes[*].hostPath must be unset.","pattern":{"spec":{"template":{"spec":{"=(volumes)":[{"X(hostPath)":"null"}]}}}}}},{"exclude":{"any":[{"resources":{"kinds":["CronJob"],"namespaces":["aws-ebs-csi-driver","aws-efs-csi-driver","brupop-bottlerocket-aws","calico-apiserver","calico-system","datadog","fw-prometheus","grafana-agent","kube-system","monitoring","tigera-operator"]}}],"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["CronJob"]}}],"resources":{}},"mutate":{},"name":"autogen-cronjob-host-path","validate":{"message":"HostPath volumes are forbidden. The field spec.volumes[*].hostPath must be unset.","pattern":{"spec":{"jobTemplate":{"spec":{"template":{"spec":{"=(volumes)":[{"X(hostPath)":"null"}]}}}}}}}}]},"conditions":[{"lastTransitionTime":"2024-02-23T15:57:03Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":1,"verifyimages":0}}}
      kyverno.io/kubernetes-version: 1.22-1.23
      kyverno.io/kyverno-version: 1.6.0
      policies.kyverno.io/category: Pod Security Standards (Baseline)
      policies.kyverno.io/description: HostPath volumes let Pods use host directories
        and volumes in containers. Using host resources can be used to access shared
        data or escalate privileges and should not be allowed. This policy ensures
        no hostPath volumes are in use.
      policies.kyverno.io/severity: medium
      policies.kyverno.io/subject: Pod,Volume
      policies.kyverno.io/title: Disallow hostPath
    creationTimestamp: "2024-04-16T06:35:24Z"
    generation: 1
    name: disallow-host-path
    resourceVersion: "28220"
    uid: 656cd2d0-035c-4cef-8e3a-9f1c24644232
  spec:
    background: true
    rules:
    - exclude:
        any:
        - resources:
            kinds:
            - Pod
            namespaces:
            - aws-ebs-csi-driver
            - aws-efs-csi-driver
            - brupop-bottlerocket-aws
            - calico-apiserver
            - calico-system
            - datadog
            - fw-prometheus
            - grafana-agent
            - kube-system
            - monitoring
            - tigera-operator
      match:
        any:
        - resources:
            kinds:
            - Pod
      name: host-path
      validate:
        message: HostPath volumes are forbidden. The field spec.volumes[*].hostPath
          must be unset.
        pattern:
          spec:
            =(volumes):
            - X(hostPath): "null"
    validationFailureAction: audit
  status:
    autogen:
      rules:
      - exclude:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
              namespaces:
              - aws-ebs-csi-driver
              - aws-efs-csi-driver
              - brupop-bottlerocket-aws
              - calico-apiserver
              - calico-system
              - datadog
              - fw-prometheus
              - grafana-agent
              - kube-system
              - monitoring
              - tigera-operator
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
          resources: {}
        mutate: {}
        name: autogen-host-path
        validate:
          message: HostPath volumes are forbidden. The field spec.volumes[*].hostPath
            must be unset.
          pattern:
            spec:
              template:
                spec:
                  =(volumes):
                  - X(hostPath): "null"
      - exclude:
          any:
          - resources:
              kinds:
              - CronJob
              namespaces:
              - aws-ebs-csi-driver
              - aws-efs-csi-driver
              - brupop-bottlerocket-aws
              - calico-apiserver
              - calico-system
              - datadog
              - fw-prometheus
              - grafana-agent
              - kube-system
              - monitoring
              - tigera-operator
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - CronJob
          resources: {}
        mutate: {}
        name: autogen-cronjob-host-path
        validate:
          message: HostPath volumes are forbidden. The field spec.volumes[*].hostPath
            must be unset.
          pattern:
            spec:
              jobTemplate:
                spec:
                  template:
                    spec:
                      =(volumes):
                      - X(hostPath): "null"
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:25Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/disallow-host-ports
      controls.cfasec.com/id: hp7
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/disallow-host-ports","controls.cfasec.com/id":"hp7","kyverno.io/kubernetes-version":"1.22-1.23","kyverno.io/kyverno-version":"1.6.0","policies.kyverno.io/category":"Pod Security Standards (Baseline)","policies.kyverno.io/description":"Access to host ports allows potential snooping of network traffic and should not be allowed, or at minimum restricted to a known list. This policy ensures the `hostPort` field is unset or set to `0`.","policies.kyverno.io/severity":"medium","policies.kyverno.io/subject":"Pod","policies.kyverno.io/title":"Disallow hostPorts"},"creationTimestamp":"2024-02-23T15:54:16Z","generation":1,"name":"disallow-host-ports","resourceVersion":"727810041","uid":"ce4a2f2f-6635-4d88-8771-cc2c9727b363"},"spec":{"background":true,"rules":[{"exclude":{"any":[{"resources":{"kinds":["Pod"],"namespaces":["tigera-operator","calico-system","calico-apiserver","datadog","aws-ebs-csi-driver","aws-efs-csi-driver","fw-prometheus"]}}]},"match":{"any":[{"resources":{"kinds":["Pod"]}}]},"name":"host-ports-none","validate":{"message":"Use of host ports is disallowed. The fields spec.containers[*].ports[*].hostPort , spec.initContainers[*].ports[*].hostPort, and spec.ephemeralContainers[*].ports[*].hostPort must either be unset or set to `0`.","pattern":{"spec":{"=(ephemeralContainers)":[{"=(ports)":[{"=(hostPort)":0}]}],"=(initContainers)":[{"=(ports)":[{"=(hostPort)":0}]}],"containers":[{"=(ports)":[{"=(hostPort)":0}]}]}}}}],"validationFailureAction":"audit"},"status":{"autogen":{"rules":[{"exclude":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"],"namespaces":["tigera-operator","calico-system","calico-apiserver","datadog","aws-ebs-csi-driver","aws-efs-csi-driver","fw-prometheus"]}}],"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"]}}],"resources":{}},"mutate":{},"name":"autogen-host-ports-none","validate":{"message":"Use of host ports is disallowed. The fields spec.containers[*].ports[*].hostPort , spec.initContainers[*].ports[*].hostPort, and spec.ephemeralContainers[*].ports[*].hostPort must either be unset or set to `0`.","pattern":{"spec":{"template":{"spec":{"=(ephemeralContainers)":[{"=(ports)":[{"=(hostPort)":0}]}],"=(initContainers)":[{"=(ports)":[{"=(hostPort)":0}]}],"containers":[{"=(ports)":[{"=(hostPort)":0}]}]}}}}}},{"exclude":{"any":[{"resources":{"kinds":["CronJob"],"namespaces":["tigera-operator","calico-system","calico-apiserver","datadog","aws-ebs-csi-driver","aws-efs-csi-driver","fw-prometheus"]}}],"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["CronJob"]}}],"resources":{}},"mutate":{},"name":"autogen-cronjob-host-ports-none","validate":{"message":"Use of host ports is disallowed. The fields spec.containers[*].ports[*].hostPort , spec.initContainers[*].ports[*].hostPort, and spec.ephemeralContainers[*].ports[*].hostPort must either be unset or set to `0`.","pattern":{"spec":{"jobTemplate":{"spec":{"template":{"spec":{"=(ephemeralContainers)":[{"=(ports)":[{"=(hostPort)":0}]}],"=(initContainers)":[{"=(ports)":[{"=(hostPort)":0}]}],"containers":[{"=(ports)":[{"=(hostPort)":0}]}]}}}}}}}}]},"conditions":[{"lastTransitionTime":"2024-02-23T15:54:36Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":1,"verifyimages":0}}}
      kyverno.io/kubernetes-version: 1.22-1.23
      kyverno.io/kyverno-version: 1.6.0
      policies.kyverno.io/category: Pod Security Standards (Baseline)
      policies.kyverno.io/description: Access to host ports allows potential snooping
        of network traffic and should not be allowed, or at minimum restricted to
        a known list. This policy ensures the `hostPort` field is unset or set to
        `0`.
      policies.kyverno.io/severity: medium
      policies.kyverno.io/subject: Pod
      policies.kyverno.io/title: Disallow hostPorts
    creationTimestamp: "2024-04-16T06:35:25Z"
    generation: 1
    name: disallow-host-ports
    resourceVersion: "28254"
    uid: f066a60e-4de3-4156-a1b7-d903316dc728
  spec:
    background: true
    rules:
    - exclude:
        any:
        - resources:
            kinds:
            - Pod
            namespaces:
            - tigera-operator
            - calico-system
            - calico-apiserver
            - datadog
            - aws-ebs-csi-driver
            - aws-efs-csi-driver
            - fw-prometheus
      match:
        any:
        - resources:
            kinds:
            - Pod
      name: host-ports-none
      validate:
        message: Use of host ports is disallowed. The fields spec.containers[*].ports[*].hostPort
          , spec.initContainers[*].ports[*].hostPort, and spec.ephemeralContainers[*].ports[*].hostPort
          must either be unset or set to `0`.
        pattern:
          spec:
            =(ephemeralContainers):
            - =(ports):
              - =(hostPort): 0
            =(initContainers):
            - =(ports):
              - =(hostPort): 0
            containers:
            - =(ports):
              - =(hostPort): 0
    validationFailureAction: audit
  status:
    autogen:
      rules:
      - exclude:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
              namespaces:
              - tigera-operator
              - calico-system
              - calico-apiserver
              - datadog
              - aws-ebs-csi-driver
              - aws-efs-csi-driver
              - fw-prometheus
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
          resources: {}
        mutate: {}
        name: autogen-host-ports-none
        validate:
          message: Use of host ports is disallowed. The fields spec.containers[*].ports[*].hostPort
            , spec.initContainers[*].ports[*].hostPort, and spec.ephemeralContainers[*].ports[*].hostPort
            must either be unset or set to `0`.
          pattern:
            spec:
              template:
                spec:
                  =(ephemeralContainers):
                  - =(ports):
                    - =(hostPort): 0
                  =(initContainers):
                  - =(ports):
                    - =(hostPort): 0
                  containers:
                  - =(ports):
                    - =(hostPort): 0
      - exclude:
          any:
          - resources:
              kinds:
              - CronJob
              namespaces:
              - tigera-operator
              - calico-system
              - calico-apiserver
              - datadog
              - aws-ebs-csi-driver
              - aws-efs-csi-driver
              - fw-prometheus
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - CronJob
          resources: {}
        mutate: {}
        name: autogen-cronjob-host-ports-none
        validate:
          message: Use of host ports is disallowed. The fields spec.containers[*].ports[*].hostPort
            , spec.initContainers[*].ports[*].hostPort, and spec.ephemeralContainers[*].ports[*].hostPort
            must either be unset or set to `0`.
          pattern:
            spec:
              jobTemplate:
                spec:
                  template:
                    spec:
                      =(ephemeralContainers):
                      - =(ports):
                        - =(hostPort): 0
                      =(initContainers):
                      - =(ports):
                        - =(hostPort): 0
                      containers:
                      - =(ports):
                        - =(hostPort): 0
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:25Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/disallow-host-ports-range
      controls.cfasec.com/id: hp7
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/disallow-host-ports-range","controls.cfasec.com/id":"hp7","kyverno.io/kubernetes-version":"1.22-1.23","kyverno.io/kyverno-version":"1.6.0","policies.kyverno.io/category":"Pod Security Standards (Baseline)","policies.kyverno.io/description":"Access to host ports allows potential snooping of network traffic and should not be allowed, or at minimum restricted to a known list. This policy ensures the `hostPort` field is set to one in the designated list. ","policies.kyverno.io/minversion":"1.6.0","policies.kyverno.io/severity":"medium","policies.kyverno.io/subject":"Pod","policies.kyverno.io/title":"Disallow hostPorts Range (Alternate)"},"creationTimestamp":"2024-02-23T16:11:51Z","generation":1,"name":"disallow-host-ports-range","resourceVersion":"727837815","uid":"6d770923-b725-45b0-9c46-9ffc138b769b"},"spec":{"background":true,"rules":[{"exclude":{"any":[{"resources":{"kinds":["Pod"],"namespaces":["datadog","aws-efs-csi-driver","fw-prometheus"]}}]},"match":{"any":[{"resources":{"kinds":["Pod"]}}]},"name":"host-port-range","validate":{"deny":{"conditions":{"all":[{"key":"{{ request.object.spec.[ephemeralContainers, initContainers, containers][].ports[].hostPort }}","operator":"AnyNotIn","value":"5000-6000"}]}},"message":"The only permitted hostPorts are in the range 5000-6000."}}],"validationFailureAction":"audit"},"status":{"autogen":{"rules":[{"exclude":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"],"namespaces":["datadog","aws-efs-csi-driver","fw-prometheus"]}}],"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"]}}],"resources":{}},"mutate":{},"name":"autogen-host-port-range","validate":{"deny":{"conditions":{"all":[{"key":"{{ request.object.spec.template.spec.[ephemeralContainers, initContainers, containers][].ports[].hostPort }}","operator":"AnyNotIn","value":"5000-6000"}]}},"message":"The only permitted hostPorts are in the range 5000-6000."}},{"exclude":{"any":[{"resources":{"kinds":["CronJob"],"namespaces":["datadog","aws-efs-csi-driver","fw-prometheus"]}}],"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["CronJob"]}}],"resources":{}},"mutate":{},"name":"autogen-cronjob-host-port-range","validate":{"deny":{"conditions":{"all":[{"key":"{{ request.object.spec.jobTemplate.spec.template.spec.[ephemeralContainers, initContainers, containers][].ports[].hostPort }}","operator":"AnyNotIn","value":"5000-6000"}]}},"message":"The only permitted hostPorts are in the range 5000-6000."}}]},"conditions":[{"lastTransitionTime":"2024-02-23T16:11:54Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":1,"verifyimages":0}}}
      kyverno.io/kubernetes-version: 1.22-1.23
      kyverno.io/kyverno-version: 1.6.0
      policies.kyverno.io/category: Pod Security Standards (Baseline)
      policies.kyverno.io/description: 'Access to host ports allows potential snooping
        of network traffic and should not be allowed, or at minimum restricted to
        a known list. This policy ensures the `hostPort` field is set to one in the
        designated list. '
      policies.kyverno.io/minversion: 1.6.0
      policies.kyverno.io/severity: medium
      policies.kyverno.io/subject: Pod
      policies.kyverno.io/title: Disallow hostPorts Range (Alternate)
    creationTimestamp: "2024-04-16T06:35:25Z"
    generation: 1
    name: disallow-host-ports-range
    resourceVersion: "28289"
    uid: aaf7b06e-c846-4910-9a1e-52de1f34153b
  spec:
    background: true
    rules:
    - exclude:
        any:
        - resources:
            kinds:
            - Pod
            namespaces:
            - datadog
            - aws-efs-csi-driver
            - fw-prometheus
      match:
        any:
        - resources:
            kinds:
            - Pod
      name: host-port-range
      validate:
        deny:
          conditions:
            all:
            - key: '{{ request.object.spec.[ephemeralContainers, initContainers, containers][].ports[].hostPort
                }}'
              operator: AnyNotIn
              value: 5000-6000
        message: The only permitted hostPorts are in the range 5000-6000.
    validationFailureAction: audit
  status:
    autogen:
      rules:
      - exclude:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
              namespaces:
              - datadog
              - aws-efs-csi-driver
              - fw-prometheus
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
          resources: {}
        mutate: {}
        name: autogen-host-port-range
        validate:
          deny:
            conditions:
              all:
              - key: '{{ request.object.spec.template.spec.[ephemeralContainers, initContainers,
                  containers][].ports[].hostPort }}'
                operator: AnyNotIn
                value: 5000-6000
          message: The only permitted hostPorts are in the range 5000-6000.
      - exclude:
          any:
          - resources:
              kinds:
              - CronJob
              namespaces:
              - datadog
              - aws-efs-csi-driver
              - fw-prometheus
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - CronJob
          resources: {}
        mutate: {}
        name: autogen-cronjob-host-port-range
        validate:
          deny:
            conditions:
              all:
              - key: '{{ request.object.spec.jobTemplate.spec.template.spec.[ephemeralContainers,
                  initContainers, containers][].ports[].hostPort }}'
                operator: AnyNotIn
                value: 5000-6000
          message: The only permitted hostPorts are in the range 5000-6000.
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:25Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/disallow-host-process
      controls.cfasec.com/id: hp10
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/disallow-host-process","controls.cfasec.com/id":"hp10","kyverno.io/kubernetes-version":"1.22-1.23","kyverno.io/kyverno-version":"1.6.0","policies.kyverno.io/category":"Pod Security Standards (Baseline)","policies.kyverno.io/description":"Windows pods offer the ability to run HostProcess containers which enables privileged access to the Windows node. Privileged access to the host is disallowed in the baseline policy. HostProcess pods are an alpha feature as of Kubernetes v1.22. This policy ensures the `hostProcess` field, if present, is set to `false`.","policies.kyverno.io/severity":"medium","policies.kyverno.io/subject":"Pod","policies.kyverno.io/title":"Disallow hostProcess"},"creationTimestamp":"2024-02-23T15:54:14Z","generation":1,"name":"disallow-host-process","resourceVersion":"727809659","uid":"a21393da-0b54-4a15-a3d5-f9383188781d"},"spec":{"background":true,"rules":[{"match":{"any":[{"resources":{"kinds":["Pod"]}}]},"name":"host-process-containers","validate":{"message":"HostProcess containers are disallowed. The fields spec.securityContext.windowsOptions.hostProcess, spec.containers[*].securityContext.windowsOptions.hostProcess, spec.initContainers[*].securityContext.windowsOptions.hostProcess, and spec.ephemeralContainers[*].securityContext.windowsOptions.hostProcess must either be undefined or set to `false`.","pattern":{"spec":{"=(ephemeralContainers)":[{"=(securityContext)":{"=(windowsOptions)":{"=(hostProcess)":"false"}}}],"=(initContainers)":[{"=(securityContext)":{"=(windowsOptions)":{"=(hostProcess)":"false"}}}],"containers":[{"=(securityContext)":{"=(windowsOptions)":{"=(hostProcess)":"false"}}}]}}}}],"validationFailureAction":"audit"},"status":{"autogen":{"rules":[{"exclude":{"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"]}}],"resources":{}},"mutate":{},"name":"autogen-host-process-containers","validate":{"message":"HostProcess containers are disallowed. The fields spec.securityContext.windowsOptions.hostProcess, spec.containers[*].securityContext.windowsOptions.hostProcess, spec.initContainers[*].securityContext.windowsOptions.hostProcess, and spec.ephemeralContainers[*].securityContext.windowsOptions.hostProcess must either be undefined or set to `false`.","pattern":{"spec":{"template":{"spec":{"=(ephemeralContainers)":[{"=(securityContext)":{"=(windowsOptions)":{"=(hostProcess)":"false"}}}],"=(initContainers)":[{"=(securityContext)":{"=(windowsOptions)":{"=(hostProcess)":"false"}}}],"containers":[{"=(securityContext)":{"=(windowsOptions)":{"=(hostProcess)":"false"}}}]}}}}}},{"exclude":{"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["CronJob"]}}],"resources":{}},"mutate":{},"name":"autogen-cronjob-host-process-containers","validate":{"message":"HostProcess containers are disallowed. The fields spec.securityContext.windowsOptions.hostProcess, spec.containers[*].securityContext.windowsOptions.hostProcess, spec.initContainers[*].securityContext.windowsOptions.hostProcess, and spec.ephemeralContainers[*].securityContext.windowsOptions.hostProcess must either be undefined or set to `false`.","pattern":{"spec":{"jobTemplate":{"spec":{"template":{"spec":{"=(ephemeralContainers)":[{"=(securityContext)":{"=(windowsOptions)":{"=(hostProcess)":"false"}}}],"=(initContainers)":[{"=(securityContext)":{"=(windowsOptions)":{"=(hostProcess)":"false"}}}],"containers":[{"=(securityContext)":{"=(windowsOptions)":{"=(hostProcess)":"false"}}}]}}}}}}}}]},"conditions":[{"lastTransitionTime":"2024-02-23T15:54:19Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":1,"verifyimages":0}}}
      kyverno.io/kubernetes-version: 1.22-1.23
      kyverno.io/kyverno-version: 1.6.0
      policies.kyverno.io/category: Pod Security Standards (Baseline)
      policies.kyverno.io/description: Windows pods offer the ability to run HostProcess
        containers which enables privileged access to the Windows node. Privileged
        access to the host is disallowed in the baseline policy. HostProcess pods
        are an alpha feature as of Kubernetes v1.22. This policy ensures the `hostProcess`
        field, if present, is set to `false`.
      policies.kyverno.io/severity: medium
      policies.kyverno.io/subject: Pod
      policies.kyverno.io/title: Disallow hostProcess
    creationTimestamp: "2024-04-16T06:35:25Z"
    generation: 1
    name: disallow-host-process
    resourceVersion: "28322"
    uid: 4bb02dbb-2d6a-4bad-99f2-7a70798e6945
  spec:
    background: true
    rules:
    - match:
        any:
        - resources:
            kinds:
            - Pod
      name: host-process-containers
      validate:
        message: HostProcess containers are disallowed. The fields spec.securityContext.windowsOptions.hostProcess,
          spec.containers[*].securityContext.windowsOptions.hostProcess, spec.initContainers[*].securityContext.windowsOptions.hostProcess,
          and spec.ephemeralContainers[*].securityContext.windowsOptions.hostProcess
          must either be undefined or set to `false`.
        pattern:
          spec:
            =(ephemeralContainers):
            - =(securityContext):
                =(windowsOptions):
                  =(hostProcess): "false"
            =(initContainers):
            - =(securityContext):
                =(windowsOptions):
                  =(hostProcess): "false"
            containers:
            - =(securityContext):
                =(windowsOptions):
                  =(hostProcess): "false"
    validationFailureAction: audit
  status:
    autogen:
      rules:
      - exclude:
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
          resources: {}
        mutate: {}
        name: autogen-host-process-containers
        validate:
          message: HostProcess containers are disallowed. The fields spec.securityContext.windowsOptions.hostProcess,
            spec.containers[*].securityContext.windowsOptions.hostProcess, spec.initContainers[*].securityContext.windowsOptions.hostProcess,
            and spec.ephemeralContainers[*].securityContext.windowsOptions.hostProcess
            must either be undefined or set to `false`.
          pattern:
            spec:
              template:
                spec:
                  =(ephemeralContainers):
                  - =(securityContext):
                      =(windowsOptions):
                        =(hostProcess): "false"
                  =(initContainers):
                  - =(securityContext):
                      =(windowsOptions):
                        =(hostProcess): "false"
                  containers:
                  - =(securityContext):
                      =(windowsOptions):
                        =(hostProcess): "false"
      - exclude:
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - CronJob
          resources: {}
        mutate: {}
        name: autogen-cronjob-host-process-containers
        validate:
          message: HostProcess containers are disallowed. The fields spec.securityContext.windowsOptions.hostProcess,
            spec.containers[*].securityContext.windowsOptions.hostProcess, spec.initContainers[*].securityContext.windowsOptions.hostProcess,
            and spec.ephemeralContainers[*].securityContext.windowsOptions.hostProcess
            must either be undefined or set to `false`.
          pattern:
            spec:
              jobTemplate:
                spec:
                  template:
                    spec:
                      =(ephemeralContainers):
                      - =(securityContext):
                          =(windowsOptions):
                            =(hostProcess): "false"
                      =(initContainers):
                      - =(securityContext):
                          =(windowsOptions):
                            =(hostProcess): "false"
                      containers:
                      - =(securityContext):
                          =(windowsOptions):
                            =(hostProcess): "false"
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:26Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/disallow-labels-to-namespace
      controls.cfasec.com/id: na
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/disallow-labels-to-namespace","controls.cfasec.com/id":"na","pod-policies.kyverno.io/autogen-controllers":"None","policies.kyverno.io/category":"Sample","policies.kyverno.io/description":"Some label control functionality driven by other cluster-wide tools and are not normally set by some class of users. This policy prevents the use of an label beginning with `gid-ENG_GROUP`. This can be useful to ensure users either don't set reserved label or to force them to use a newer version of an label.      ","policies.kyverno.io/minversion":"1.3.0","policies.kyverno.io/subject":"Namespace, Label","policies.kyverno.io/title":"Restrict Labels"},"creationTimestamp":"2024-02-23T15:56:32Z","generation":1,"name":"disallow-labels-to-namespace","resourceVersion":"727814523","uid":"84694df5-562f-4832-a0f2-7d93d68a6cee"},"spec":{"background":true,"rules":[{"match":{"resources":{"kinds":["Namespace"],"namespaces":["kyverno","kube-system","test-namespace","kube-engineering","sre"]}},"name":"disallow-labels-to-namespace","validate":{"message":"Cannot use any labels.","pattern":{"metadata":{"labels":{"X(gid-ENG_GROUP*)":"*"}}}}}],"validationFailureAction":"audit"},"status":{"autogen":{},"conditions":[{"lastTransitionTime":"2024-02-23T15:57:03Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":1,"verifyimages":0}}}
      pod-policies.kyverno.io/autogen-controllers: None
      policies.kyverno.io/category: Sample
      policies.kyverno.io/description: 'Some label control functionality driven by
        other cluster-wide tools and are not normally set by some class of users.
        This policy prevents the use of an label beginning with `gid-ENG_GROUP`. This
        can be useful to ensure users either don''t set reserved label or to force
        them to use a newer version of an label.      '
      policies.kyverno.io/minversion: 1.3.0
      policies.kyverno.io/subject: Namespace, Label
      policies.kyverno.io/title: Restrict Labels
    creationTimestamp: "2024-04-16T06:35:26Z"
    generation: 1
    name: disallow-labels-to-namespace
    resourceVersion: "28354"
    uid: f217269a-c65e-433a-8516-0895068b0ad9
  spec:
    background: true
    rules:
    - match:
        resources:
          kinds:
          - Namespace
          namespaces:
          - kyverno
          - kube-system
          - test-namespace
          - kube-engineering
          - sre
      name: disallow-labels-to-namespace
      validate:
        message: Cannot use any labels.
        pattern:
          metadata:
            labels:
              X(gid-ENG_GROUP*): '*'
    validationFailureAction: audit
  status:
    autogen: {}
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:26Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/disallow-privilege-escalation
      controls.cfasec.com/id: hp15
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/disallow-privilege-escalation","controls.cfasec.com/id":"hp15","kyverno.io/kubernetes-version":"1.22-1.23","kyverno.io/kyverno-version":"1.6.0","policies.kyverno.io/category":"Pod Security Standards (Restricted)","policies.kyverno.io/description":"Privilege escalation, such as via set-user-ID or set-group-ID file mode, should not be allowed. This policy ensures the `allowPrivilegeEscalation` field is set to `false`.","policies.kyverno.io/severity":"medium","policies.kyverno.io/subject":"Pod","policies.kyverno.io/title":"Disallow Privilege Escalation"},"creationTimestamp":"2024-02-23T16:11:27Z","generation":1,"name":"disallow-privilege-escalation","resourceVersion":"727837305","uid":"b033bb9c-4a40-4235-9d21-6ac0e24697b3"},"spec":{"background":true,"rules":[{"exclude":{"any":[{"resources":{"kinds":["Pod","DaemonSet","StatefulSet"],"namespaces":["aws-ebs-csi-driver","aws-efs-csi-driver","calico-apiserver","calico-system","datadog","fw-prometheus","gloo-system","grafana-agent","monitoring","tigera-operator"]}}]},"match":{"any":[{"resources":{"kinds":["Pod"]}}]},"name":"privilege-escalation","validate":{"message":"Privilege escalation is disallowed. The fields spec.containers[*].securityContext.allowPrivilegeEscalation, spec.initContainers[*].securityContext.allowPrivilegeEscalation, and spec.ephemeralContainers[*].securityContext.allowPrivilegeEscalation must be set to `false`.","pattern":{"spec":{"=(ephemeralContainers)":[{"securityContext":{"allowPrivilegeEscalation":"false"}}],"=(initContainers)":[{"securityContext":{"allowPrivilegeEscalation":"false"}}],"containers":[{"securityContext":{"allowPrivilegeEscalation":"false"}}]}}}}],"validationFailureAction":"audit"},"status":{"autogen":{},"conditions":[{"lastTransitionTime":"2024-02-23T16:11:32Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":1,"verifyimages":0}}}
      kyverno.io/kubernetes-version: 1.22-1.23
      kyverno.io/kyverno-version: 1.6.0
      policies.kyverno.io/category: Pod Security Standards (Restricted)
      policies.kyverno.io/description: Privilege escalation, such as via set-user-ID
        or set-group-ID file mode, should not be allowed. This policy ensures the
        `allowPrivilegeEscalation` field is set to `false`.
      policies.kyverno.io/severity: medium
      policies.kyverno.io/subject: Pod
      policies.kyverno.io/title: Disallow Privilege Escalation
    creationTimestamp: "2024-04-16T06:35:26Z"
    generation: 1
    name: disallow-privilege-escalation
    resourceVersion: "28388"
    uid: 85c7bc4b-ebf5-4473-9e8f-ac6f25019326
  spec:
    background: true
    rules:
    - exclude:
        any:
        - resources:
            kinds:
            - Pod
            - DaemonSet
            - StatefulSet
            namespaces:
            - aws-ebs-csi-driver
            - aws-efs-csi-driver
            - calico-apiserver
            - calico-system
            - datadog
            - fw-prometheus
            - gloo-system
            - grafana-agent
            - monitoring
            - tigera-operator
      match:
        any:
        - resources:
            kinds:
            - Pod
      name: privilege-escalation
      validate:
        message: Privilege escalation is disallowed. The fields spec.containers[*].securityContext.allowPrivilegeEscalation,
          spec.initContainers[*].securityContext.allowPrivilegeEscalation, and spec.ephemeralContainers[*].securityContext.allowPrivilegeEscalation
          must be set to `false`.
        pattern:
          spec:
            =(ephemeralContainers):
            - securityContext:
                allowPrivilegeEscalation: "false"
            =(initContainers):
            - securityContext:
                allowPrivilegeEscalation: "false"
            containers:
            - securityContext:
                allowPrivilegeEscalation: "false"
    validationFailureAction: audit
  status:
    autogen: {}
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:26Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/disallow-privileged-containers
      controls.cfasec.com/id: hp8
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/disallow-privileged-containers","controls.cfasec.com/id":"hp8","kyverno.io/kubernetes-version":"1.22-1.23","kyverno.io/kyverno-version":"1.6.0","policies.kyverno.io/category":"Pod Security Standards (Baseline)","policies.kyverno.io/description":"Privileged mode disables most security mechanisms and must not be allowed. This policy ensures Pods do not call for privileged mode.","policies.kyverno.io/severity":"medium","policies.kyverno.io/subject":"Pod","policies.kyverno.io/title":"Disallow Privileged Containers"},"creationTimestamp":"2024-02-23T16:11:27Z","generation":1,"name":"disallow-privileged-containers","resourceVersion":"727837339","uid":"6b5902ee-c570-4388-bd51-7190f0748b84"},"spec":{"background":true,"rules":[{"exclude":{"any":[{"resources":{"kinds":["Pod"],"namespaces":["grafana-agent","calico-system","calico-apiserver","aws-ebs-csi-driver","aws-efs-csi-driver","fw-prometheus"]}}]},"match":{"any":[{"resources":{"kinds":["Pod"]}}]},"name":"privileged-containers","validate":{"message":"Privileged mode is disallowed. The fields spec.containers[*].securityContext.privileged and spec.initContainers[*].securityContext.privileged must be unset or set to `false`.","pattern":{"spec":{"=(ephemeralContainers)":[{"=(securityContext)":{"=(privileged)":"false"}}],"=(initContainers)":[{"=(securityContext)":{"=(privileged)":"false"}}],"containers":[{"=(securityContext)":{"=(privileged)":"false"}}]}}}}],"validationFailureAction":"audit"},"status":{"autogen":{"rules":[{"exclude":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"],"namespaces":["grafana-agent","calico-system","calico-apiserver","aws-ebs-csi-driver","aws-efs-csi-driver","fw-prometheus"]}}],"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"]}}],"resources":{}},"mutate":{},"name":"autogen-privileged-containers","validate":{"message":"Privileged mode is disallowed. The fields spec.containers[*].securityContext.privileged and spec.initContainers[*].securityContext.privileged must be unset or set to `false`.","pattern":{"spec":{"template":{"spec":{"=(ephemeralContainers)":[{"=(securityContext)":{"=(privileged)":"false"}}],"=(initContainers)":[{"=(securityContext)":{"=(privileged)":"false"}}],"containers":[{"=(securityContext)":{"=(privileged)":"false"}}]}}}}}},{"exclude":{"any":[{"resources":{"kinds":["CronJob"],"namespaces":["grafana-agent","calico-system","calico-apiserver","aws-ebs-csi-driver","aws-efs-csi-driver","fw-prometheus"]}}],"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["CronJob"]}}],"resources":{}},"mutate":{},"name":"autogen-cronjob-privileged-containers","validate":{"message":"Privileged mode is disallowed. The fields spec.containers[*].securityContext.privileged and spec.initContainers[*].securityContext.privileged must be unset or set to `false`.","pattern":{"spec":{"jobTemplate":{"spec":{"template":{"spec":{"=(ephemeralContainers)":[{"=(securityContext)":{"=(privileged)":"false"}}],"=(initContainers)":[{"=(securityContext)":{"=(privileged)":"false"}}],"containers":[{"=(securityContext)":{"=(privileged)":"false"}}]}}}}}}}}]},"conditions":[{"lastTransitionTime":"2024-02-23T16:11:32Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":1,"verifyimages":0}}}
      kyverno.io/kubernetes-version: 1.22-1.23
      kyverno.io/kyverno-version: 1.6.0
      policies.kyverno.io/category: Pod Security Standards (Baseline)
      policies.kyverno.io/description: Privileged mode disables most security mechanisms
        and must not be allowed. This policy ensures Pods do not call for privileged
        mode.
      policies.kyverno.io/severity: medium
      policies.kyverno.io/subject: Pod
      policies.kyverno.io/title: Disallow Privileged Containers
    creationTimestamp: "2024-04-16T06:35:26Z"
    generation: 1
    name: disallow-privileged-containers
    resourceVersion: "28420"
    uid: c072dd72-108e-4432-b96b-ddc7fcbf01e4
  spec:
    background: true
    rules:
    - exclude:
        any:
        - resources:
            kinds:
            - Pod
            namespaces:
            - grafana-agent
            - calico-system
            - calico-apiserver
            - aws-ebs-csi-driver
            - aws-efs-csi-driver
            - fw-prometheus
      match:
        any:
        - resources:
            kinds:
            - Pod
      name: privileged-containers
      validate:
        message: Privileged mode is disallowed. The fields spec.containers[*].securityContext.privileged
          and spec.initContainers[*].securityContext.privileged must be unset or set
          to `false`.
        pattern:
          spec:
            =(ephemeralContainers):
            - =(securityContext):
                =(privileged): "false"
            =(initContainers):
            - =(securityContext):
                =(privileged): "false"
            containers:
            - =(securityContext):
                =(privileged): "false"
    validationFailureAction: audit
  status:
    autogen:
      rules:
      - exclude:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
              namespaces:
              - grafana-agent
              - calico-system
              - calico-apiserver
              - aws-ebs-csi-driver
              - aws-efs-csi-driver
              - fw-prometheus
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
          resources: {}
        mutate: {}
        name: autogen-privileged-containers
        validate:
          message: Privileged mode is disallowed. The fields spec.containers[*].securityContext.privileged
            and spec.initContainers[*].securityContext.privileged must be unset or
            set to `false`.
          pattern:
            spec:
              template:
                spec:
                  =(ephemeralContainers):
                  - =(securityContext):
                      =(privileged): "false"
                  =(initContainers):
                  - =(securityContext):
                      =(privileged): "false"
                  containers:
                  - =(securityContext):
                      =(privileged): "false"
      - exclude:
          any:
          - resources:
              kinds:
              - CronJob
              namespaces:
              - grafana-agent
              - calico-system
              - calico-apiserver
              - aws-ebs-csi-driver
              - aws-efs-csi-driver
              - fw-prometheus
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - CronJob
          resources: {}
        mutate: {}
        name: autogen-cronjob-privileged-containers
        validate:
          message: Privileged mode is disallowed. The fields spec.containers[*].securityContext.privileged
            and spec.initContainers[*].securityContext.privileged must be unset or
            set to `false`.
          pattern:
            spec:
              jobTemplate:
                spec:
                  template:
                    spec:
                      =(ephemeralContainers):
                      - =(securityContext):
                          =(privileged): "false"
                      =(initContainers):
                      - =(securityContext):
                          =(privileged): "false"
                      containers:
                      - =(securityContext):
                          =(privileged): "false"
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:27Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/disallow-proc-mount
      controls.cfasec.com/id: hp9
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/disallow-proc-mount","controls.cfasec.com/id":"hp9","kyverno.io/kubernetes-version":"1.22-1.23","kyverno.io/kyverno-version":"1.6.0","policies.kyverno.io/category":"Pod Security Standards (Baseline)","policies.kyverno.io/description":"The default /proc masks are set up to reduce attack surface and should be required. This policy ensures nothing but the default procMount can be specified. Note that in order for users to deviate from the `Default` procMount requires setting a feature gate at the API server.","policies.kyverno.io/severity":"medium","policies.kyverno.io/subject":"Pod","policies.kyverno.io/title":"Disallow procMount"},"creationTimestamp":"2024-02-23T15:54:16Z","generation":1,"name":"disallow-proc-mount","resourceVersion":"727810036","uid":"ccbcc592-95d5-4f9f-8cd6-65885dbb8266"},"spec":{"background":true,"rules":[{"match":{"any":[{"resources":{"kinds":["Pod"]}}]},"name":"check-proc-mount","validate":{"message":"Changing the proc mount from the default is not allowed. The fields spec.containers[*].securityContext.procMount, spec.initContainers[*].securityContext.procMount, and spec.ephemeralContainers[*].securityContext.procMount must be unset or set to `Default`.","pattern":{"spec":{"=(ephemeralContainers)":[{"=(securityContext)":{"=(procMount)":"Default"}}],"=(initContainers)":[{"=(securityContext)":{"=(procMount)":"Default"}}],"containers":[{"=(securityContext)":{"=(procMount)":"Default"}}]}}}}],"validationFailureAction":"audit"},"status":{"autogen":{"rules":[{"exclude":{"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"]}}],"resources":{}},"mutate":{},"name":"autogen-check-proc-mount","validate":{"message":"Changing the proc mount from the default is not allowed. The fields spec.containers[*].securityContext.procMount, spec.initContainers[*].securityContext.procMount, and spec.ephemeralContainers[*].securityContext.procMount must be unset or set to `Default`.","pattern":{"spec":{"template":{"spec":{"=(ephemeralContainers)":[{"=(securityContext)":{"=(procMount)":"Default"}}],"=(initContainers)":[{"=(securityContext)":{"=(procMount)":"Default"}}],"containers":[{"=(securityContext)":{"=(procMount)":"Default"}}]}}}}}},{"exclude":{"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["CronJob"]}}],"resources":{}},"mutate":{},"name":"autogen-cronjob-check-proc-mount","validate":{"message":"Changing the proc mount from the default is not allowed. The fields spec.containers[*].securityContext.procMount, spec.initContainers[*].securityContext.procMount, and spec.ephemeralContainers[*].securityContext.procMount must be unset or set to `Default`.","pattern":{"spec":{"jobTemplate":{"spec":{"template":{"spec":{"=(ephemeralContainers)":[{"=(securityContext)":{"=(procMount)":"Default"}}],"=(initContainers)":[{"=(securityContext)":{"=(procMount)":"Default"}}],"containers":[{"=(securityContext)":{"=(procMount)":"Default"}}]}}}}}}}}]},"conditions":[{"lastTransitionTime":"2024-02-23T15:54:36Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":1,"verifyimages":0}}}
      kyverno.io/kubernetes-version: 1.22-1.23
      kyverno.io/kyverno-version: 1.6.0
      policies.kyverno.io/category: Pod Security Standards (Baseline)
      policies.kyverno.io/description: The default /proc masks are set up to reduce
        attack surface and should be required. This policy ensures nothing but the
        default procMount can be specified. Note that in order for users to deviate
        from the `Default` procMount requires setting a feature gate at the API server.
      policies.kyverno.io/severity: medium
      policies.kyverno.io/subject: Pod
      policies.kyverno.io/title: Disallow procMount
    creationTimestamp: "2024-04-16T06:35:27Z"
    generation: 1
    name: disallow-proc-mount
    resourceVersion: "28447"
    uid: 6873cfd5-e384-4e13-a930-9bc2e44a78d8
  spec:
    background: true
    rules:
    - match:
        any:
        - resources:
            kinds:
            - Pod
      name: check-proc-mount
      validate:
        message: Changing the proc mount from the default is not allowed. The fields
          spec.containers[*].securityContext.procMount, spec.initContainers[*].securityContext.procMount,
          and spec.ephemeralContainers[*].securityContext.procMount must be unset
          or set to `Default`.
        pattern:
          spec:
            =(ephemeralContainers):
            - =(securityContext):
                =(procMount): Default
            =(initContainers):
            - =(securityContext):
                =(procMount): Default
            containers:
            - =(securityContext):
                =(procMount): Default
    validationFailureAction: audit
  status:
    autogen:
      rules:
      - exclude:
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
          resources: {}
        mutate: {}
        name: autogen-check-proc-mount
        validate:
          message: Changing the proc mount from the default is not allowed. The fields
            spec.containers[*].securityContext.procMount, spec.initContainers[*].securityContext.procMount,
            and spec.ephemeralContainers[*].securityContext.procMount must be unset
            or set to `Default`.
          pattern:
            spec:
              template:
                spec:
                  =(ephemeralContainers):
                  - =(securityContext):
                      =(procMount): Default
                  =(initContainers):
                  - =(securityContext):
                      =(procMount): Default
                  containers:
                  - =(securityContext):
                      =(procMount): Default
      - exclude:
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - CronJob
          resources: {}
        mutate: {}
        name: autogen-cronjob-check-proc-mount
        validate:
          message: Changing the proc mount from the default is not allowed. The fields
            spec.containers[*].securityContext.procMount, spec.initContainers[*].securityContext.procMount,
            and spec.ephemeralContainers[*].securityContext.procMount must be unset
            or set to `Default`.
          pattern:
            spec:
              jobTemplate:
                spec:
                  template:
                    spec:
                      =(ephemeralContainers):
                      - =(securityContext):
                          =(procMount): Default
                      =(initContainers):
                      - =(securityContext):
                          =(procMount): Default
                      containers:
                      - =(securityContext):
                          =(procMount): Default
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:27Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/disallow-selinux
      controls.cfasec.com/id: hp11
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/disallow-selinux","controls.cfasec.com/id":"hp11","kyverno.io/kubernetes-version":"1.22-1.23","kyverno.io/kyverno-version":"1.6.0","policies.kyverno.io/category":"Pod Security Standards (Baseline)","policies.kyverno.io/description":"SELinux options can be used to escalate privileges and should not be allowed. This policy ensures that the `seLinuxOptions` field is undefined.","policies.kyverno.io/severity":"medium","policies.kyverno.io/subject":"Pod","policies.kyverno.io/title":"Disallow SELinux"},"creationTimestamp":"2024-02-23T16:11:51Z","generation":1,"name":"disallow-selinux","resourceVersion":"727837832","uid":"25fbbeac-bc7c-4c7e-8236-11c322b52cbd"},"spec":{"background":true,"rules":[{"exclude":{"any":[{"resources":{"kinds":["Pod"],"namespaceSelector":{"matchExpressions":[{"key":"exception/selinux","operator":"In","values":["true"]}]}}}]},"match":{"any":[{"resources":{"kinds":["Pod"]}}]},"name":"selinux-type","validate":{"message":"Setting the SELinux type is restricted. The fields spec.securityContext.seLinuxOptions.type, spec.containers[*].securityContext.seLinuxOptions.type, , spec.initContainers[*].securityContext.seLinuxOptions, and spec.ephemeralContainers[*].securityContext.seLinuxOptions.type must either be unset or set to one of the allowed values (container_t, container_init_t, or container_kvm_t).","pattern":{"spec":{"=(ephemeralContainers)":[{"=(securityContext)":{"=(seLinuxOptions)":{"=(type)":"container_t | container_init_t | container_kvm_t"}}}],"=(initContainers)":[{"=(securityContext)":{"=(seLinuxOptions)":{"=(type)":"container_t | container_init_t | container_kvm_t"}}}],"=(securityContext)":{"=(seLinuxOptions)":{"=(type)":"container_t | container_init_t | container_kvm_t"}},"containers":[{"=(securityContext)":{"=(seLinuxOptions)":{"=(type)":"container_t | container_init_t | container_kvm_t"}}}]}}}},{"exclude":{"any":[{"resources":{"kinds":["Pod"],"namespaceSelector":{"matchExpressions":[{"key":"exception/selinux","operator":"In","values":["true"]}]}}}]},"match":{"any":[{"resources":{"kinds":["Pod"]}}]},"name":"selinux-user-role","validate":{"message":"Setting the SELinux user or role is forbidden. The fields spec.securityContext.seLinuxOptions.user, spec.securityContext.seLinuxOptions.role, spec.containers[*].securityContext.seLinuxOptions.user, spec.containers[*].securityContext.seLinuxOptions.role, spec.initContainers[*].securityContext.seLinuxOptions.user, spec.initContainers[*].securityContext.seLinuxOptions.role, spec.ephemeralContainers[*].securityContext.seLinuxOptions.user, and spec.ephemeralContainers[*].securityContext.seLinuxOptions.role must be unset.","pattern":{"spec":{"=(ephemeralContainers)":[{"=(securityContext)":{"=(seLinuxOptions)":{"X(role)":"null","X(user)":"null"}}}],"=(initContainers)":[{"=(securityContext)":{"=(seLinuxOptions)":{"X(role)":"null","X(user)":"null"}}}],"=(securityContext)":{"=(seLinuxOptions)":{"X(role)":"null","X(user)":"null"}},"containers":[{"=(securityContext)":{"=(seLinuxOptions)":{"X(role)":"null","X(user)":"null"}}}]}}}}],"validationFailureAction":"audit"},"status":{"autogen":{"rules":[{"exclude":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"],"namespaceSelector":{"matchExpressions":[{"key":"exception/selinux","operator":"In","values":["true"]}]}}}],"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"]}}],"resources":{}},"mutate":{},"name":"autogen-selinux-type","validate":{"message":"Setting the SELinux type is restricted. The fields spec.securityContext.seLinuxOptions.type, spec.containers[*].securityContext.seLinuxOptions.type, , spec.initContainers[*].securityContext.seLinuxOptions, and spec.ephemeralContainers[*].securityContext.seLinuxOptions.type must either be unset or set to one of the allowed values (container_t, container_init_t, or container_kvm_t).","pattern":{"spec":{"template":{"spec":{"=(ephemeralContainers)":[{"=(securityContext)":{"=(seLinuxOptions)":{"=(type)":"container_t | container_init_t | container_kvm_t"}}}],"=(initContainers)":[{"=(securityContext)":{"=(seLinuxOptions)":{"=(type)":"container_t | container_init_t | container_kvm_t"}}}],"=(securityContext)":{"=(seLinuxOptions)":{"=(type)":"container_t | container_init_t | container_kvm_t"}},"containers":[{"=(securityContext)":{"=(seLinuxOptions)":{"=(type)":"container_t | container_init_t | container_kvm_t"}}}]}}}}}},{"exclude":{"any":[{"resources":{"kinds":["CronJob"],"namespaceSelector":{"matchExpressions":[{"key":"exception/selinux","operator":"In","values":["true"]}]}}}],"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["CronJob"]}}],"resources":{}},"mutate":{},"name":"autogen-cronjob-selinux-type","validate":{"message":"Setting the SELinux type is restricted. The fields spec.securityContext.seLinuxOptions.type, spec.containers[*].securityContext.seLinuxOptions.type, , spec.initContainers[*].securityContext.seLinuxOptions, and spec.ephemeralContainers[*].securityContext.seLinuxOptions.type must either be unset or set to one of the allowed values (container_t, container_init_t, or container_kvm_t).","pattern":{"spec":{"jobTemplate":{"spec":{"template":{"spec":{"=(ephemeralContainers)":[{"=(securityContext)":{"=(seLinuxOptions)":{"=(type)":"container_t | container_init_t | container_kvm_t"}}}],"=(initContainers)":[{"=(securityContext)":{"=(seLinuxOptions)":{"=(type)":"container_t | container_init_t | container_kvm_t"}}}],"=(securityContext)":{"=(seLinuxOptions)":{"=(type)":"container_t | container_init_t | container_kvm_t"}},"containers":[{"=(securityContext)":{"=(seLinuxOptions)":{"=(type)":"container_t | container_init_t | container_kvm_t"}}}]}}}}}}}},{"exclude":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"],"namespaceSelector":{"matchExpressions":[{"key":"exception/selinux","operator":"In","values":["true"]}]}}}],"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"]}}],"resources":{}},"mutate":{},"name":"autogen-selinux-user-role","validate":{"message":"Setting the SELinux user or role is forbidden. The fields spec.securityContext.seLinuxOptions.user, spec.securityContext.seLinuxOptions.role, spec.containers[*].securityContext.seLinuxOptions.user, spec.containers[*].securityContext.seLinuxOptions.role, spec.initContainers[*].securityContext.seLinuxOptions.user, spec.initContainers[*].securityContext.seLinuxOptions.role, spec.ephemeralContainers[*].securityContext.seLinuxOptions.user, and spec.ephemeralContainers[*].securityContext.seLinuxOptions.role must be unset.","pattern":{"spec":{"template":{"spec":{"=(ephemeralContainers)":[{"=(securityContext)":{"=(seLinuxOptions)":{"X(role)":"null","X(user)":"null"}}}],"=(initContainers)":[{"=(securityContext)":{"=(seLinuxOptions)":{"X(role)":"null","X(user)":"null"}}}],"=(securityContext)":{"=(seLinuxOptions)":{"X(role)":"null","X(user)":"null"}},"containers":[{"=(securityContext)":{"=(seLinuxOptions)":{"X(role)":"null","X(user)":"null"}}}]}}}}}},{"exclude":{"any":[{"resources":{"kinds":["CronJob"],"namespaceSelector":{"matchExpressions":[{"key":"exception/selinux","operator":"In","values":["true"]}]}}}],"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["CronJob"]}}],"resources":{}},"mutate":{},"name":"autogen-cronjob-selinux-user-role","validate":{"message":"Setting the SELinux user or role is forbidden. The fields spec.securityContext.seLinuxOptions.user, spec.securityContext.seLinuxOptions.role, spec.containers[*].securityContext.seLinuxOptions.user, spec.containers[*].securityContext.seLinuxOptions.role, spec.initContainers[*].securityContext.seLinuxOptions.user, spec.initContainers[*].securityContext.seLinuxOptions.role, spec.ephemeralContainers[*].securityContext.seLinuxOptions.user, and spec.ephemeralContainers[*].securityContext.seLinuxOptions.role must be unset.","pattern":{"spec":{"jobTemplate":{"spec":{"template":{"spec":{"=(ephemeralContainers)":[{"=(securityContext)":{"=(seLinuxOptions)":{"X(role)":"null","X(user)":"null"}}}],"=(initContainers)":[{"=(securityContext)":{"=(seLinuxOptions)":{"X(role)":"null","X(user)":"null"}}}],"=(securityContext)":{"=(seLinuxOptions)":{"X(role)":"null","X(user)":"null"}},"containers":[{"=(securityContext)":{"=(seLinuxOptions)":{"X(role)":"null","X(user)":"null"}}}]}}}}}}}}]},"conditions":[{"lastTransitionTime":"2024-02-23T16:11:54Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":2,"verifyimages":0}}}
      kyverno.io/kubernetes-version: 1.22-1.23
      kyverno.io/kyverno-version: 1.6.0
      policies.kyverno.io/category: Pod Security Standards (Baseline)
      policies.kyverno.io/description: SELinux options can be used to escalate privileges
        and should not be allowed. This policy ensures that the `seLinuxOptions` field
        is undefined.
      policies.kyverno.io/severity: medium
      policies.kyverno.io/subject: Pod
      policies.kyverno.io/title: Disallow SELinux
    creationTimestamp: "2024-04-16T06:35:27Z"
    generation: 1
    name: disallow-selinux
    resourceVersion: "28523"
    uid: 63251373-be34-4ed7-a762-3433288fed3c
  spec:
    background: true
    rules:
    - exclude:
        any:
        - resources:
            kinds:
            - Pod
            namespaceSelector:
              matchExpressions:
              - key: exception/selinux
                operator: In
                values:
                - "true"
      match:
        any:
        - resources:
            kinds:
            - Pod
      name: selinux-type
      validate:
        message: Setting the SELinux type is restricted. The fields spec.securityContext.seLinuxOptions.type,
          spec.containers[*].securityContext.seLinuxOptions.type, , spec.initContainers[*].securityContext.seLinuxOptions,
          and spec.ephemeralContainers[*].securityContext.seLinuxOptions.type must
          either be unset or set to one of the allowed values (container_t, container_init_t,
          or container_kvm_t).
        pattern:
          spec:
            =(ephemeralContainers):
            - =(securityContext):
                =(seLinuxOptions):
                  =(type): container_t | container_init_t | container_kvm_t
            =(initContainers):
            - =(securityContext):
                =(seLinuxOptions):
                  =(type): container_t | container_init_t | container_kvm_t
            =(securityContext):
              =(seLinuxOptions):
                =(type): container_t | container_init_t | container_kvm_t
            containers:
            - =(securityContext):
                =(seLinuxOptions):
                  =(type): container_t | container_init_t | container_kvm_t
    - exclude:
        any:
        - resources:
            kinds:
            - Pod
            namespaceSelector:
              matchExpressions:
              - key: exception/selinux
                operator: In
                values:
                - "true"
      match:
        any:
        - resources:
            kinds:
            - Pod
      name: selinux-user-role
      validate:
        message: Setting the SELinux user or role is forbidden. The fields spec.securityContext.seLinuxOptions.user,
          spec.securityContext.seLinuxOptions.role, spec.containers[*].securityContext.seLinuxOptions.user,
          spec.containers[*].securityContext.seLinuxOptions.role, spec.initContainers[*].securityContext.seLinuxOptions.user,
          spec.initContainers[*].securityContext.seLinuxOptions.role, spec.ephemeralContainers[*].securityContext.seLinuxOptions.user,
          and spec.ephemeralContainers[*].securityContext.seLinuxOptions.role must
          be unset.
        pattern:
          spec:
            =(ephemeralContainers):
            - =(securityContext):
                =(seLinuxOptions):
                  X(role): "null"
                  X(user): "null"
            =(initContainers):
            - =(securityContext):
                =(seLinuxOptions):
                  X(role): "null"
                  X(user): "null"
            =(securityContext):
              =(seLinuxOptions):
                X(role): "null"
                X(user): "null"
            containers:
            - =(securityContext):
                =(seLinuxOptions):
                  X(role): "null"
                  X(user): "null"
    validationFailureAction: audit
  status:
    autogen:
      rules:
      - exclude:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
              namespaceSelector:
                matchExpressions:
                - key: exception/selinux
                  operator: In
                  values:
                  - "true"
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
          resources: {}
        mutate: {}
        name: autogen-selinux-type
        validate:
          message: Setting the SELinux type is restricted. The fields spec.securityContext.seLinuxOptions.type,
            spec.containers[*].securityContext.seLinuxOptions.type, , spec.initContainers[*].securityContext.seLinuxOptions,
            and spec.ephemeralContainers[*].securityContext.seLinuxOptions.type must
            either be unset or set to one of the allowed values (container_t, container_init_t,
            or container_kvm_t).
          pattern:
            spec:
              template:
                spec:
                  =(ephemeralContainers):
                  - =(securityContext):
                      =(seLinuxOptions):
                        =(type): container_t | container_init_t | container_kvm_t
                  =(initContainers):
                  - =(securityContext):
                      =(seLinuxOptions):
                        =(type): container_t | container_init_t | container_kvm_t
                  =(securityContext):
                    =(seLinuxOptions):
                      =(type): container_t | container_init_t | container_kvm_t
                  containers:
                  - =(securityContext):
                      =(seLinuxOptions):
                        =(type): container_t | container_init_t | container_kvm_t
      - exclude:
          any:
          - resources:
              kinds:
              - CronJob
              namespaceSelector:
                matchExpressions:
                - key: exception/selinux
                  operator: In
                  values:
                  - "true"
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - CronJob
          resources: {}
        mutate: {}
        name: autogen-cronjob-selinux-type
        validate:
          message: Setting the SELinux type is restricted. The fields spec.securityContext.seLinuxOptions.type,
            spec.containers[*].securityContext.seLinuxOptions.type, , spec.initContainers[*].securityContext.seLinuxOptions,
            and spec.ephemeralContainers[*].securityContext.seLinuxOptions.type must
            either be unset or set to one of the allowed values (container_t, container_init_t,
            or container_kvm_t).
          pattern:
            spec:
              jobTemplate:
                spec:
                  template:
                    spec:
                      =(ephemeralContainers):
                      - =(securityContext):
                          =(seLinuxOptions):
                            =(type): container_t | container_init_t | container_kvm_t
                      =(initContainers):
                      - =(securityContext):
                          =(seLinuxOptions):
                            =(type): container_t | container_init_t | container_kvm_t
                      =(securityContext):
                        =(seLinuxOptions):
                          =(type): container_t | container_init_t | container_kvm_t
                      containers:
                      - =(securityContext):
                          =(seLinuxOptions):
                            =(type): container_t | container_init_t | container_kvm_t
      - exclude:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
              namespaceSelector:
                matchExpressions:
                - key: exception/selinux
                  operator: In
                  values:
                  - "true"
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
          resources: {}
        mutate: {}
        name: autogen-selinux-user-role
        validate:
          message: Setting the SELinux user or role is forbidden. The fields spec.securityContext.seLinuxOptions.user,
            spec.securityContext.seLinuxOptions.role, spec.containers[*].securityContext.seLinuxOptions.user,
            spec.containers[*].securityContext.seLinuxOptions.role, spec.initContainers[*].securityContext.seLinuxOptions.user,
            spec.initContainers[*].securityContext.seLinuxOptions.role, spec.ephemeralContainers[*].securityContext.seLinuxOptions.user,
            and spec.ephemeralContainers[*].securityContext.seLinuxOptions.role must
            be unset.
          pattern:
            spec:
              template:
                spec:
                  =(ephemeralContainers):
                  - =(securityContext):
                      =(seLinuxOptions):
                        X(role): "null"
                        X(user): "null"
                  =(initContainers):
                  - =(securityContext):
                      =(seLinuxOptions):
                        X(role): "null"
                        X(user): "null"
                  =(securityContext):
                    =(seLinuxOptions):
                      X(role): "null"
                      X(user): "null"
                  containers:
                  - =(securityContext):
                      =(seLinuxOptions):
                        X(role): "null"
                        X(user): "null"
      - exclude:
          any:
          - resources:
              kinds:
              - CronJob
              namespaceSelector:
                matchExpressions:
                - key: exception/selinux
                  operator: In
                  values:
                  - "true"
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - CronJob
          resources: {}
        mutate: {}
        name: autogen-cronjob-selinux-user-role
        validate:
          message: Setting the SELinux user or role is forbidden. The fields spec.securityContext.seLinuxOptions.user,
            spec.securityContext.seLinuxOptions.role, spec.containers[*].securityContext.seLinuxOptions.user,
            spec.containers[*].securityContext.seLinuxOptions.role, spec.initContainers[*].securityContext.seLinuxOptions.user,
            spec.initContainers[*].securityContext.seLinuxOptions.role, spec.ephemeralContainers[*].securityContext.seLinuxOptions.user,
            and spec.ephemeralContainers[*].securityContext.seLinuxOptions.role must
            be unset.
          pattern:
            spec:
              jobTemplate:
                spec:
                  template:
                    spec:
                      =(ephemeralContainers):
                      - =(securityContext):
                          =(seLinuxOptions):
                            X(role): "null"
                            X(user): "null"
                      =(initContainers):
                      - =(securityContext):
                          =(seLinuxOptions):
                            X(role): "null"
                            X(user): "null"
                      =(securityContext):
                        =(seLinuxOptions):
                          X(role): "null"
                          X(user): "null"
                      containers:
                      - =(securityContext):
                          =(seLinuxOptions):
                            X(role): "null"
                            X(user): "null"
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:28Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 2
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/generate-default-securitycontext-pod
      controls.cfasec.com/id: n/a
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/generate-default-securitycontext-pod","controls.cfasec.com/id":"n/a","policies.kyverno.io/category":"Sample","policies.kyverno.io/description":"A Pod securityContext entry defines fields such as the user and group which should be used to run the Pod. Sometimes choosing default values for users rather than blocking is a better alternative to not impede such Pod definitions. This policy will mutate a Pod to set `runAsNonRoot`, runAsUser`, `runAsGroup`, and `fsGroup` fields within the Pod securityContext if they are not already set.","policies.kyverno.io/subject":"Pod","policies.kyverno.io/title":"Add Default securityContext"},"creationTimestamp":"2024-02-23T15:54:16Z","generation":1,"name":"generate-default-securitycontext-pod","resourceVersion":"727810039","uid":"df54775d-d7c5-4501-879d-9d72d2a266ff"},"spec":{"background":true,"rules":[{"match":{"resources":{"kinds":["Pod"],"namespaceSelector":{"matchExpressions":[{"key":"feature/autoPodSecurityContext","operator":"In","values":["true"]}]}}},"mutate":{"patchStrategicMerge":{"spec":{"securityContext":{"+(fsGroup)":2000,"+(runAsGroup)":3000,"+(runAsNonRoot)":true,"+(runAsUser)":1000}}}},"name":"add-default-securitycontext"}],"validationFailureAction":"Audit"},"status":{"autogen":{"rules":[{"exclude":{"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"],"namespaceSelector":{"matchExpressions":[{"key":"feature/autoPodSecurityContext","operator":"In","values":["true"]}]}}},"mutate":{"patchStrategicMerge":{"spec":{"template":{"spec":{"securityContext":{"+(fsGroup)":2000,"+(runAsGroup)":3000,"+(runAsNonRoot)":true,"+(runAsUser)":1000}}}}}},"name":"autogen-add-default-securitycontext","validate":{}},{"exclude":{"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"resources":{"kinds":["CronJob"],"namespaceSelector":{"matchExpressions":[{"key":"feature/autoPodSecurityContext","operator":"In","values":["true"]}]}}},"mutate":{"patchStrategicMerge":{"spec":{"jobTemplate":{"spec":{"template":{"spec":{"securityContext":{"+(fsGroup)":2000,"+(runAsGroup)":3000,"+(runAsNonRoot)":true,"+(runAsUser)":1000}}}}}}}},"name":"autogen-cronjob-add-default-securitycontext","validate":{}}]},"conditions":[{"lastTransitionTime":"2024-02-23T15:54:36Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":1,"validate":0,"verifyimages":0}}}
      policies.kyverno.io/category: Sample
      policies.kyverno.io/description: A Pod securityContext entry defines fields
        such as the user and group which should be used to run the Pod. Sometimes
        choosing default values for users rather than blocking is a better alternative
        to not impede such Pod definitions. This policy will mutate a Pod to set `runAsNonRoot`,
        runAsUser`, `runAsGroup`, and `fsGroup` fields within the Pod securityContext
        if they are not already set.
      policies.kyverno.io/subject: Pod
      policies.kyverno.io/title: Add Default securityContext
    creationTimestamp: "2024-04-16T06:35:28Z"
    generation: 1
    name: generate-default-securitycontext-pod
    resourceVersion: "28592"
    uid: 6246a23f-d0fb-45ff-9378-a039100c63af
  spec:
    background: true
    rules:
    - match:
        resources:
          kinds:
          - Pod
          namespaceSelector:
            matchExpressions:
            - key: feature/autoPodSecurityContext
              operator: In
              values:
              - "true"
      mutate:
        patchStrategicMerge:
          spec:
            securityContext:
              +(fsGroup): 2000
              +(runAsGroup): 3000
              +(runAsNonRoot): true
              +(runAsUser): 1000
      name: add-default-securitycontext
    validationFailureAction: Audit
  status:
    autogen:
      rules:
      - exclude:
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          resources:
            kinds:
            - DaemonSet
            - Deployment
            - Job
            - StatefulSet
            - ReplicaSet
            - ReplicationController
            namespaceSelector:
              matchExpressions:
              - key: feature/autoPodSecurityContext
                operator: In
                values:
                - "true"
        mutate:
          patchStrategicMerge:
            spec:
              template:
                spec:
                  securityContext:
                    +(fsGroup): 2000
                    +(runAsGroup): 3000
                    +(runAsNonRoot): true
                    +(runAsUser): 1000
        name: autogen-add-default-securitycontext
        validate: {}
      - exclude:
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          resources:
            kinds:
            - CronJob
            namespaceSelector:
              matchExpressions:
              - key: feature/autoPodSecurityContext
                operator: In
                values:
                - "true"
        mutate:
          patchStrategicMerge:
            spec:
              jobTemplate:
                spec:
                  template:
                    spec:
                      securityContext:
                        +(fsGroup): 2000
                        +(runAsGroup): 3000
                        +(runAsNonRoot): true
                        +(runAsUser): 1000
        name: autogen-cronjob-add-default-securitycontext
        validate: {}
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:28Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 1
      validate: 0
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/inspect-csr
      controls.cfasec.com/id: rbac14
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/inspect-csr","controls.cfasec.com/id":"rbac14","kyverno.io/kubernetes-version":"1.26","policies.kyverno.io/category":"Other","policies.kyverno.io/description":"The Kubernetes API includes a CertificateSigningRequest resource which can be used to generate a certificate for an entity. Because this API can be abused to create a long-lived credential, it is important to be able to audit this API to understand who/what is creating these CSRs and for what actors they are being created. This policy, intended to always be run in audit mode and produce failure results in a Policy Report, inspects all incoming CertificateSigningRequests and writes out into the Policy Report information on who/what requested it and parsing the CSR to show the Subject information of that CSR resource.      ","policies.kyverno.io/minversion":"1.10.0","policies.kyverno.io/subject":"CertificateSigningRequest","policies.kyverno.io/title":"Inspect CertificateSigningRequest"},"creationTimestamp":"2024-02-23T15:58:33Z","generation":1,"name":"inspect-csr","resourceVersion":"727817491","uid":"4c2c5b7e-bc84-4549-aac7-5994edb6d0d3"},"spec":{"background":false,"rules":[{"match":{"any":[{"resources":{"kinds":["CertificateSigningRequest"]}}]},"name":"csr","validate":{"deny":{},"message":"A CSR was created by {{ request.userInfo | to_string(@) }} holding ClusterRoles {{ request.clusterRoles | to_string(@) }} and Roles {{ request.roles | to_string(@) }}. The subjects and groups requested in the CSR were \"{{ x509_decode(base64_decode('{{ request.object.spec.request }}')).Subject | to_string(@) }}\"        "}}],"validationFailureAction":"audit"},"status":{"autogen":{},"conditions":[{"lastTransitionTime":"2024-02-23T15:58:35Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":1,"verifyimages":0}}}
      kyverno.io/kubernetes-version: "1.26"
      policies.kyverno.io/category: Other
      policies.kyverno.io/description: 'The Kubernetes API includes a CertificateSigningRequest
        resource which can be used to generate a certificate for an entity. Because
        this API can be abused to create a long-lived credential, it is important
        to be able to audit this API to understand who/what is creating these CSRs
        and for what actors they are being created. This policy, intended to always
        be run in audit mode and produce failure results in a Policy Report, inspects
        all incoming CertificateSigningRequests and writes out into the Policy Report
        information on who/what requested it and parsing the CSR to show the Subject
        information of that CSR resource.      '
      policies.kyverno.io/minversion: 1.10.0
      policies.kyverno.io/subject: CertificateSigningRequest
      policies.kyverno.io/title: Inspect CertificateSigningRequest
    creationTimestamp: "2024-04-16T06:35:28Z"
    generation: 1
    name: inspect-csr
    resourceVersion: "28614"
    uid: 874e3b9a-d635-4cc5-987a-5f049239b2c6
  spec:
    background: false
    rules:
    - match:
        any:
        - resources:
            kinds:
            - CertificateSigningRequest
      name: csr
      validate:
        deny: {}
        message: 'A CSR was created by {{ request.userInfo | to_string(@) }} holding
          ClusterRoles {{ request.clusterRoles | to_string(@) }} and Roles {{ request.roles
          | to_string(@) }}. The subjects and groups requested in the CSR were "{{
          x509_decode(base64_decode(''{{ request.object.spec.request }}'')).Subject
          | to_string(@) }}"        '
    validationFailureAction: audit
  status:
    autogen: {}
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:29Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/mutate-default-securitycontext
      controls.cfasec.com/id: na
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/mutate-default-securitycontext","controls.cfasec.com/id":"na","policies.kyverno.io/category":"Sample","policies.kyverno.io/description":"A Pod securityContext entry defines fields such as the user and group which should be used to run the Pod. Sometimes choosing default values for users rather than blocking is a better alternative to not impede such Pod definitions. This policy will mutate a Pod to set `runAsNonRoot`, runAsUser`, `runAsGroup`, and `fsGroup` fields within the Pod securityContext if they are not already set.","policies.kyverno.io/subject":"Pod","policies.kyverno.io/title":"Add Default securityContext"},"creationTimestamp":"2024-02-23T16:11:51Z","generation":1,"name":"mutate-default-securitycontext","resourceVersion":"727837836","uid":"0428976e-8293-4f21-9acf-bdd28b4bfeb2"},"spec":{"background":true,"rules":[{"match":{"resources":{"kinds":["Pod"],"namespaceSelector":{"matchExpressions":[{"key":"feature/autoPodSecurityContext","operator":"In","values":["true"]}]}}},"mutate":{"patchStrategicMerge":{"spec":{"securityContext":{"+(fsGroup)":2000,"+(runAsGroup)":3000,"+(runAsNonRoot)":true,"+(runAsUser)":1000}}}},"name":"add-default-securitycontext"}],"validationFailureAction":"Audit"},"status":{"autogen":{"rules":[{"exclude":{"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"],"namespaceSelector":{"matchExpressions":[{"key":"feature/autoPodSecurityContext","operator":"In","values":["true"]}]}}},"mutate":{"patchStrategicMerge":{"spec":{"template":{"spec":{"securityContext":{"+(fsGroup)":2000,"+(runAsGroup)":3000,"+(runAsNonRoot)":true,"+(runAsUser)":1000}}}}}},"name":"autogen-add-default-securitycontext","validate":{}},{"exclude":{"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"resources":{"kinds":["CronJob"],"namespaceSelector":{"matchExpressions":[{"key":"feature/autoPodSecurityContext","operator":"In","values":["true"]}]}}},"mutate":{"patchStrategicMerge":{"spec":{"jobTemplate":{"spec":{"template":{"spec":{"securityContext":{"+(fsGroup)":2000,"+(runAsGroup)":3000,"+(runAsNonRoot)":true,"+(runAsUser)":1000}}}}}}}},"name":"autogen-cronjob-add-default-securitycontext","validate":{}}]},"conditions":[{"lastTransitionTime":"2024-02-23T16:11:54Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":1,"validate":0,"verifyimages":0}}}
      policies.kyverno.io/category: Sample
      policies.kyverno.io/description: A Pod securityContext entry defines fields
        such as the user and group which should be used to run the Pod. Sometimes
        choosing default values for users rather than blocking is a better alternative
        to not impede such Pod definitions. This policy will mutate a Pod to set `runAsNonRoot`,
        runAsUser`, `runAsGroup`, and `fsGroup` fields within the Pod securityContext
        if they are not already set.
      policies.kyverno.io/subject: Pod
      policies.kyverno.io/title: Add Default securityContext
    creationTimestamp: "2024-04-16T06:35:29Z"
    generation: 1
    name: mutate-default-securitycontext
    resourceVersion: "28659"
    uid: 2fe2808f-254a-47f2-b288-ff4e1dd55abd
  spec:
    background: true
    rules:
    - match:
        resources:
          kinds:
          - Pod
          namespaceSelector:
            matchExpressions:
            - key: feature/autoPodSecurityContext
              operator: In
              values:
              - "true"
      mutate:
        patchStrategicMerge:
          spec:
            securityContext:
              +(fsGroup): 2000
              +(runAsGroup): 3000
              +(runAsNonRoot): true
              +(runAsUser): 1000
      name: add-default-securitycontext
    validationFailureAction: Audit
  status:
    autogen:
      rules:
      - exclude:
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          resources:
            kinds:
            - DaemonSet
            - Deployment
            - Job
            - StatefulSet
            - ReplicaSet
            - ReplicationController
            namespaceSelector:
              matchExpressions:
              - key: feature/autoPodSecurityContext
                operator: In
                values:
                - "true"
        mutate:
          patchStrategicMerge:
            spec:
              template:
                spec:
                  securityContext:
                    +(fsGroup): 2000
                    +(runAsGroup): 3000
                    +(runAsNonRoot): true
                    +(runAsUser): 1000
        name: autogen-add-default-securitycontext
        validate: {}
      - exclude:
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          resources:
            kinds:
            - CronJob
            namespaceSelector:
              matchExpressions:
              - key: feature/autoPodSecurityContext
                operator: In
                values:
                - "true"
        mutate:
          patchStrategicMerge:
            spec:
              jobTemplate:
                spec:
                  template:
                    spec:
                      securityContext:
                        +(fsGroup): 2000
                        +(runAsGroup): 3000
                        +(runAsNonRoot): true
                        +(runAsUser): 1000
        name: autogen-cronjob-add-default-securitycontext
        validate: {}
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:29Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 1
      validate: 0
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/no-localhost-service
      controls.cfasec.com/id: na
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/no-localhost-service","controls.cfasec.com/id":"na","policies.kyverno.io/category":"Sample","policies.kyverno.io/description":"A Service of type ExternalName which points back to localhost can potentially be used to exploit vulnerabilities in some Ingress controllers. This policy audits Services of type ExternalName if the externalName field refers to localhost.","policies.kyverno.io/severity":"medium","policies.kyverno.io/subject":"Service","policies.kyverno.io/title":"Disallow Localhost ExternalName Services"},"creationTimestamp":"2024-02-23T16:11:27Z","generation":1,"name":"no-localhost-service","resourceVersion":"727837297","uid":"b916b395-300b-45ee-ba1c-aeb717c5d601"},"spec":{"background":true,"rules":[{"match":{"resources":{"kinds":["Service"]}},"name":"no-localhost-service","validate":{"message":"Service of type ExternalName cannot point to localhost.","pattern":{"spec":{"(type)":"ExternalName","externalName":"!localhost"}}}}],"validationFailureAction":"audit"},"status":{"autogen":{},"conditions":[{"lastTransitionTime":"2024-02-23T16:11:32Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":1,"verifyimages":0}}}
      policies.kyverno.io/category: Sample
      policies.kyverno.io/description: A Service of type ExternalName which points
        back to localhost can potentially be used to exploit vulnerabilities in some
        Ingress controllers. This policy audits Services of type ExternalName if the
        externalName field refers to localhost.
      policies.kyverno.io/severity: medium
      policies.kyverno.io/subject: Service
      policies.kyverno.io/title: Disallow Localhost ExternalName Services
    creationTimestamp: "2024-04-16T06:35:29Z"
    generation: 1
    name: no-localhost-service
    resourceVersion: "28696"
    uid: 2a475947-1e3a-455c-ac52-e3ad5cc0fc72
  spec:
    background: true
    rules:
    - match:
        resources:
          kinds:
          - Service
      name: no-localhost-service
      validate:
        message: Service of type ExternalName cannot point to localhost.
        pattern:
          spec:
            (type): ExternalName
            externalName: '!localhost'
    validationFailureAction: audit
  status:
    autogen: {}
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:29Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/only-clusterip-service
      controls.cfasec.com/id: nw3
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/only-clusterip-service","controls.cfasec.com/id":"nw3","policies.kyverno.io/category":"Sample","policies.kyverno.io/description":"The only allowable service type is ClusterIP","policies.kyverno.io/severity":"medium","policies.kyverno.io/subject":"Service","policies.kyverno.io/title":"Only allow Service Type ClusterIP"},"creationTimestamp":"2024-02-23T15:54:14Z","generation":1,"name":"only-clusterip-service","resourceVersion":"727809546","uid":"c692f380-9bcf-45f5-ad10-bad5c991603e"},"spec":{"background":true,"rules":[{"exclude":{"any":[{"resources":{"kinds":["Service"],"namespaceSelector":{"matchExpressions":[{"key":"exception/clusterIP","operator":"In","values":["true"]}]}}},{"resources":{"kinds":["Service"],"namespaces":["tigera-image-assurance","tigera-elasticsearch"]}}]},"match":{"any":[{"resources":{"kinds":["Service"]}}]},"name":"clusterIP-only","validate":{"message":"Service is not of type ClusterIP.","pattern":{"spec":{"type":"ClusterIP"}}}}],"validationFailureAction":"audit"},"status":{"autogen":{},"conditions":[{"lastTransitionTime":"2024-02-23T15:54:16Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":1,"verifyimages":0}}}
      policies.kyverno.io/category: Sample
      policies.kyverno.io/description: The only allowable service type is ClusterIP
      policies.kyverno.io/severity: medium
      policies.kyverno.io/subject: Service
      policies.kyverno.io/title: Only allow Service Type ClusterIP
    creationTimestamp: "2024-04-16T06:35:29Z"
    generation: 1
    name: only-clusterip-service
    resourceVersion: "28730"
    uid: 536f0c90-171a-4a65-aa49-9499fde8e52b
  spec:
    background: true
    rules:
    - exclude:
        any:
        - resources:
            kinds:
            - Service
            namespaceSelector:
              matchExpressions:
              - key: exception/clusterIP
                operator: In
                values:
                - "true"
        - resources:
            kinds:
            - Service
            namespaces:
            - tigera-image-assurance
            - tigera-elasticsearch
      match:
        any:
        - resources:
            kinds:
            - Service
      name: clusterIP-only
      validate:
        message: Service is not of type ClusterIP.
        pattern:
          spec:
            type: ClusterIP
    validationFailureAction: audit
  status:
    autogen: {}
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:30Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/prevent-cr8escape
      controls.cfasec.com/id: hp1
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/prevent-cr8escape","controls.cfasec.com/id":"hp1","kyverno.io/kubernetes-version":"1.23","kyverno.io/kyverno-version":"1.6.0","policies.kyverno.io/category":"Other","policies.kyverno.io/description":"A vulnerability \"cr8escape\" (CVE-2022-0811) in CRI-O the container runtime engine underpinning Kubernetes allows attackers to escape from a Kubernetes container and gain root access to the host. The recommended remediation is to disallow sysctl settings with + or = in their value.","policies.kyverno.io/minversion":"1.6.0","policies.kyverno.io/severity":"high","policies.kyverno.io/subject":"Pod","policies.kyverno.io/title":"Prevent cr8escape (CVE-2022-0811)"},"creationTimestamp":"2024-02-23T16:11:27Z","generation":1,"name":"prevent-cr8escape","resourceVersion":"727837301","uid":"2c163480-0225-4dd7-8e45-24fc0a93b447"},"spec":{"background":true,"rules":[{"match":{"any":[{"resources":{"kinds":["Pod"]}}]},"name":"restrict-sysctls-cr8escape","validate":{"message":"characters '+' or '=' are not allowed in sysctls values","pattern":{"spec":{"=(securityContext)":{"=(sysctls)":[{"=(value)":"!*+* \u0026 !*=*"}]}}}}}],"validationFailureAction":"audit"},"status":{"autogen":{"rules":[{"exclude":{"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"]}}],"resources":{}},"mutate":{},"name":"autogen-restrict-sysctls-cr8escape","validate":{"message":"characters '+' or '=' are not allowed in sysctls values","pattern":{"spec":{"template":{"spec":{"=(securityContext)":{"=(sysctls)":[{"=(value)":"!*+* \u0026 !*=*"}]}}}}}}},{"exclude":{"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["CronJob"]}}],"resources":{}},"mutate":{},"name":"autogen-cronjob-restrict-sysctls-cr8escape","validate":{"message":"characters '+' or '=' are not allowed in sysctls values","pattern":{"spec":{"jobTemplate":{"spec":{"template":{"spec":{"=(securityContext)":{"=(sysctls)":[{"=(value)":"!*+* \u0026 !*=*"}]}}}}}}}}}]},"conditions":[{"lastTransitionTime":"2024-02-23T16:11:32Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":1,"verifyimages":0}}}
      kyverno.io/kubernetes-version: "1.23"
      kyverno.io/kyverno-version: 1.6.0
      policies.kyverno.io/category: Other
      policies.kyverno.io/description: A vulnerability "cr8escape" (CVE-2022-0811)
        in CRI-O the container runtime engine underpinning Kubernetes allows attackers
        to escape from a Kubernetes container and gain root access to the host. The
        recommended remediation is to disallow sysctl settings with + or = in their
        value.
      policies.kyverno.io/minversion: 1.6.0
      policies.kyverno.io/severity: high
      policies.kyverno.io/subject: Pod
      policies.kyverno.io/title: Prevent cr8escape (CVE-2022-0811)
    creationTimestamp: "2024-04-16T06:35:30Z"
    generation: 1
    name: prevent-cr8escape
    resourceVersion: "28780"
    uid: e01e4596-1614-4d84-bbc2-f0c594b299d2
  spec:
    background: true
    rules:
    - match:
        any:
        - resources:
            kinds:
            - Pod
      name: restrict-sysctls-cr8escape
      validate:
        message: characters '+' or '=' are not allowed in sysctls values
        pattern:
          spec:
            =(securityContext):
              =(sysctls):
              - =(value): '!*+* & !*=*'
    validationFailureAction: audit
  status:
    autogen:
      rules:
      - exclude:
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
          resources: {}
        mutate: {}
        name: autogen-restrict-sysctls-cr8escape
        validate:
          message: characters '+' or '=' are not allowed in sysctls values
          pattern:
            spec:
              template:
                spec:
                  =(securityContext):
                    =(sysctls):
                    - =(value): '!*+* & !*=*'
      - exclude:
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - CronJob
          resources: {}
        mutate: {}
        name: autogen-cronjob-restrict-sysctls-cr8escape
        validate:
          message: characters '+' or '=' are not allowed in sysctls values
          pattern:
            spec:
              jobTemplate:
                spec:
                  template:
                    spec:
                      =(securityContext):
                        =(sysctls):
                        - =(value): '!*+* & !*=*'
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:30Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/protect-node-label-foo
      controls.cfasec.com/id: node2
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/protect-node-label-foo","controls.cfasec.com/id":"node2","policies.kyverno.io/category":"Sample","policies.kyverno.io/description":"Node labels are critical pieces of metadata upon which many other applications and logic may depend and should not be altered or removed by regular users. This policy prevents changes or deletions to a label called `foo` on cluster Nodes. Use of this policy requires removal of the Node resource filter in the Kyverno ConfigMap ([Node,*,*]). Due to Kubernetes CVE-2021-25735, this policy requires, at minimum, one of the following versions of Kubernetes: v1.18.18, v1.19.10, v1.20.6, or v1.21.0.","policies.kyverno.io/subject":"Node, Label","policies.kyverno.io/title":"Restrict node label changes"},"creationTimestamp":"2024-02-23T15:54:16Z","generation":1,"name":"protect-node-label-foo","resourceVersion":"727810031","uid":"432df80b-a6e4-42d2-acf2-3eb4225d1ac8"},"spec":{"background":false,"rules":[{"match":{"resources":{"kinds":["Node"]}},"name":"prevent-label-value-changes","validate":{"deny":{"conditions":{"all":[{"key":"{{ request.object.metadata.labels.foo || '' }}","operator":"NotEquals","value":""},{"key":"{{ request.object.metadata.labels.foo || '' }}","operator":"NotEquals","value":"{{ request.oldObject.metadata.labels.foo || '' }}"}]}},"message":"Modifying the `foo` label on a Node is not allowed."}},{"match":{"resources":{"kinds":["Node"]}},"name":"prevent-label-key-removal","preconditions":{"all":[{"key":"{{ request.operation }}","operator":"Equals","value":"UPDATE"},{"key":"{{ request.oldObject.metadata.labels.foo || '' }}","operator":"Equals","value":"?*"}]},"validate":{"message":"Removing the `foo` label on a Node is not allowed.","pattern":{"metadata":{"labels":{"foo":"*"}}}}}],"validationFailureAction":"audit"},"status":{"autogen":{},"conditions":[{"lastTransitionTime":"2024-02-23T15:54:36Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":2,"verifyimages":0}}}
      policies.kyverno.io/category: Sample
      policies.kyverno.io/description: 'Node labels are critical pieces of metadata
        upon which many other applications and logic may depend and should not be
        altered or removed by regular users. This policy prevents changes or deletions
        to a label called `foo` on cluster Nodes. Use of this policy requires removal
        of the Node resource filter in the Kyverno ConfigMap ([Node,*,*]). Due to
        Kubernetes CVE-2021-25735, this policy requires, at minimum, one of the following
        versions of Kubernetes: v1.18.18, v1.19.10, v1.20.6, or v1.21.0.'
      policies.kyverno.io/subject: Node, Label
      policies.kyverno.io/title: Restrict node label changes
    creationTimestamp: "2024-04-16T06:35:30Z"
    generation: 1
    name: protect-node-label-foo
    resourceVersion: "28830"
    uid: ca790674-1037-482c-9564-efd42f496b37
  spec:
    background: false
    rules:
    - match:
        resources:
          kinds:
          - Node
      name: prevent-label-value-changes
      validate:
        deny:
          conditions:
            all:
            - key: '{{ request.object.metadata.labels.foo || '''' }}'
              operator: NotEquals
              value: ""
            - key: '{{ request.object.metadata.labels.foo || '''' }}'
              operator: NotEquals
              value: '{{ request.oldObject.metadata.labels.foo || '''' }}'
        message: Modifying the `foo` label on a Node is not allowed.
    - match:
        resources:
          kinds:
          - Node
      name: prevent-label-key-removal
      preconditions:
        all:
        - key: '{{ request.operation }}'
          operator: Equals
          value: UPDATE
        - key: '{{ request.oldObject.metadata.labels.foo || '''' }}'
          operator: Equals
          value: ?*
      validate:
        message: Removing the `foo` label on a Node is not allowed.
        pattern:
          metadata:
            labels:
              foo: '*'
    validationFailureAction: audit
  status:
    autogen: {}
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:31Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 2
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/require-labels
      controls.cfasec.com/id: sm2
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/require-labels","controls.cfasec.com/id":"sm2","policies.kyverno.io/category":"Best Practices","policies.kyverno.io/description":"Define and use labels that identify semantic attributes of your application or Deployment. A common set of labels allows tools to work collaboratively, describing objects in a common manner that all tools can understand. The recommended labels describe applications in a way that can be queried. This policy validates that the label `app` is specified with some value.","policies.kyverno.io/minversion":"1.6.0","policies.kyverno.io/severity":"medium","policies.kyverno.io/subject":"Pod, Label","policies.kyverno.io/title":"Require Labels"},"creationTimestamp":"2024-02-23T15:54:02Z","generation":1,"name":"require-labels","resourceVersion":"727809464","uid":"255454a3-97d3-46eb-8010-85fea7295149"},"spec":{"background":true,"rules":[{"exclude":{"any":[{"resources":{"kinds":["Pod"],"namespaces":["kubelink-system","akuity-admin","gloo-system","tigera-operator"]}}]},"match":{"any":[{"resources":{"kinds":["Pod"]}}]},"name":"check-for-app-label","validate":{"message":"The label `app` is required.","pattern":{"metadata":{"labels":{"app.kubernetes.io/name":"?*"}}}}}],"validationFailureAction":"audit"},"status":{"autogen":{"rules":[{"exclude":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"],"namespaces":["kubelink-system","akuity-admin","gloo-system","tigera-operator"]}}],"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"]}}],"resources":{}},"mutate":{},"name":"autogen-check-for-app-label","validate":{"message":"The label `app` is required.","pattern":{"spec":{"template":{"metadata":{"labels":{"app.kubernetes.io/name":"?*"}}}}}}},{"exclude":{"any":[{"resources":{"kinds":["CronJob"],"namespaces":["kubelink-system","akuity-admin","gloo-system","tigera-operator"]}}],"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["CronJob"]}}],"resources":{}},"mutate":{},"name":"autogen-cronjob-check-for-app-label","validate":{"message":"The label `app` is required.","pattern":{"spec":{"jobTemplate":{"spec":{"template":{"metadata":{"labels":{"app.kubernetes.io/name":"?*"}}}}}}}}}]},"conditions":[{"lastTransitionTime":"2024-02-23T15:54:13Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":1,"verifyimages":0}}}
      policies.kyverno.io/category: Best Practices
      policies.kyverno.io/description: Define and use labels that identify semantic
        attributes of your application or Deployment. A common set of labels allows
        tools to work collaboratively, describing objects in a common manner that
        all tools can understand. The recommended labels describe applications in
        a way that can be queried. This policy validates that the label `app` is specified
        with some value.
      policies.kyverno.io/minversion: 1.6.0
      policies.kyverno.io/severity: medium
      policies.kyverno.io/subject: Pod, Label
      policies.kyverno.io/title: Require Labels
    creationTimestamp: "2024-04-16T06:35:31Z"
    generation: 1
    name: require-labels
    resourceVersion: "28860"
    uid: 9183b59e-b354-4dfc-9876-29896612b430
  spec:
    background: true
    rules:
    - exclude:
        any:
        - resources:
            kinds:
            - Pod
            namespaces:
            - kubelink-system
            - akuity-admin
            - gloo-system
            - tigera-operator
      match:
        any:
        - resources:
            kinds:
            - Pod
      name: check-for-app-label
      validate:
        message: The label `app` is required.
        pattern:
          metadata:
            labels:
              app.kubernetes.io/name: ?*
    validationFailureAction: audit
  status:
    autogen:
      rules:
      - exclude:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
              namespaces:
              - kubelink-system
              - akuity-admin
              - gloo-system
              - tigera-operator
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
          resources: {}
        mutate: {}
        name: autogen-check-for-app-label
        validate:
          message: The label `app` is required.
          pattern:
            spec:
              template:
                metadata:
                  labels:
                    app.kubernetes.io/name: ?*
      - exclude:
          any:
          - resources:
              kinds:
              - CronJob
              namespaces:
              - kubelink-system
              - akuity-admin
              - gloo-system
              - tigera-operator
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - CronJob
          resources: {}
        mutate: {}
        name: autogen-cronjob-check-for-app-label
        validate:
          message: The label `app` is required.
          pattern:
            spec:
              jobTemplate:
                spec:
                  template:
                    metadata:
                      labels:
                        app.kubernetes.io/name: ?*
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:31Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/require-non-root-groups
      controls.cfasec.com/id: hp21
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/require-non-root-groups","controls.cfasec.com/id":"hp21","kyverno.io/kubernetes-version":"1.22-1.23","kyverno.io/kyverno-version":"1.6.0","policies.kyverno.io/category":"Sample, EKS Best Practices","policies.kyverno.io/description":"Containers should be forbidden from running with a root primary or supplementary GID. This policy ensures the `runAsGroup`, `supplementalGroups`, and `fsGroup` fields are set to a number greater than zero (i.e., non root). A known issue prevents a policy such as this using `anyPattern` from being persisted properly in Kubernetes 1.23.0-1.23.2.","policies.kyverno.io/minversion":"1.3.6","policies.kyverno.io/severity":"medium","policies.kyverno.io/subject":"Pod","policies.kyverno.io/title":"Require Non-Root Groups"},"creationTimestamp":"2024-02-23T16:11:51Z","generation":1,"name":"require-non-root-groups","resourceVersion":"727837825","uid":"1e73cfaa-d9cc-4436-afb4-c7bddec1dcb4"},"spec":{"background":true,"rules":[{"exclude":{"any":[{"resources":{"kinds":["Pod"],"namespaces":["akuity-admin","gloo-system","rbac-manager","tigera-operator","tigera-apiserver","tigera-system","tigera-fluentd","tigera-compliance","grafana-agent","calico-apiserver","calico-system","aws-ebs-csi-driver","aws-efs-csi-driver","datadog","monitoring","kubecross-system","datadog"]}}]},"match":{"any":[{"resources":{"kinds":["Pod"]}}]},"name":"check-runasgroup","validate":{"anyPattern":[{"spec":{"=(ephemeralContainers)":[{"=(securityContext)":{"=(runAsGroup)":"\u003e0"}}],"=(initContainers)":[{"=(securityContext)":{"=(runAsGroup)":"\u003e0"}}],"containers":[{"=(securityContext)":{"=(runAsGroup)":"\u003e0"}}],"securityContext":{"runAsGroup":"\u003e0"}}},{"spec":{"=(ephemeralContainers)":[{"securityContext":{"runAsGroup":"\u003e0"}}],"=(initContainers)":[{"securityContext":{"runAsGroup":"\u003e0"}}],"containers":[{"securityContext":{"runAsGroup":"\u003e0"}}]}}],"message":"Running with root group IDs is disallowed. The fields spec.securityContext.runAsGroup, spec.containers[*].securityContext.runAsGroup, spec.initContainers[*].securityContext.runAsGroup, and spec.ephemeralContainers[*].securityContext.runAsGroup must be set to a value greater than zero."}},{"exclude":{"any":[{"resources":{"kinds":["Pod"],"namespaces":["grafana-agent","calico-system","calico-apiserver","aws-ebs-csi-driver","aws-efs-csi-driver","datadog","akuity-admin","grafana-agent","monitoring","kubecross-system"]}}]},"match":{"any":[{"resources":{"kinds":["Pod"]}}]},"name":"check-supplementalgroups","validate":{"message":"Containers cannot run with a root primary or supplementary GID. The field spec.securityContext.supplementalGroups must be unset or set to a value greater than zero.","pattern":{"spec":{"=(securityContext)":{"=(supplementalGroups)":"\u003e0"}}}}},{"exclude":{"any":[{"resources":{"kinds":["Pod"],"namespaces":["grafana-agent","calico-system","calico-apiserver","aws-ebs-csi-driver","aws-efs-csi-driver","datadog","akuity-admin","monitoring"]}}]},"match":{"any":[{"resources":{"kinds":["Pod"]}}]},"name":"check-fsgroup","validate":{"message":"Containers cannot run with a root primary or supplementary GID. The field spec.securityContext.fsGroup must be unset or set to a value greater than zero.","pattern":{"spec":{"=(securityContext)":{"=(fsGroup)":"\u003e0"}}}}}],"validationFailureAction":"audit"},"status":{"autogen":{"rules":[{"exclude":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"],"namespaces":["akuity-admin","gloo-system","rbac-manager","tigera-operator","tigera-apiserver","tigera-system","tigera-fluentd","tigera-compliance","grafana-agent","calico-apiserver","calico-system","aws-ebs-csi-driver","aws-efs-csi-driver","datadog","monitoring","kubecross-system","datadog"]}}],"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"]}}],"resources":{}},"mutate":{},"name":"autogen-check-runasgroup","validate":{"anyPattern":[{"spec":{"template":{"spec":{"=(ephemeralContainers)":[{"=(securityContext)":{"=(runAsGroup)":"\u003e0"}}],"=(initContainers)":[{"=(securityContext)":{"=(runAsGroup)":"\u003e0"}}],"containers":[{"=(securityContext)":{"=(runAsGroup)":"\u003e0"}}],"securityContext":{"runAsGroup":"\u003e0"}}}}},{"spec":{"template":{"spec":{"=(ephemeralContainers)":[{"securityContext":{"runAsGroup":"\u003e0"}}],"=(initContainers)":[{"securityContext":{"runAsGroup":"\u003e0"}}],"containers":[{"securityContext":{"runAsGroup":"\u003e0"}}]}}}}],"message":"Running with root group IDs is disallowed. The fields spec.securityContext.runAsGroup, spec.containers[*].securityContext.runAsGroup, spec.initContainers[*].securityContext.runAsGroup, and spec.ephemeralContainers[*].securityContext.runAsGroup must be set to a value greater than zero."}},{"exclude":{"any":[{"resources":{"kinds":["CronJob"],"namespaces":["akuity-admin","gloo-system","rbac-manager","tigera-operator","tigera-apiserver","tigera-system","tigera-fluentd","tigera-compliance","grafana-agent","calico-apiserver","calico-system","aws-ebs-csi-driver","aws-efs-csi-driver","datadog","monitoring","kubecross-system","datadog"]}}],"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["CronJob"]}}],"resources":{}},"mutate":{},"name":"autogen-cronjob-check-runasgroup","validate":{"anyPattern":[{"spec":{"jobTemplate":{"spec":{"template":{"spec":{"=(ephemeralContainers)":[{"=(securityContext)":{"=(runAsGroup)":"\u003e0"}}],"=(initContainers)":[{"=(securityContext)":{"=(runAsGroup)":"\u003e0"}}],"containers":[{"=(securityContext)":{"=(runAsGroup)":"\u003e0"}}],"securityContext":{"runAsGroup":"\u003e0"}}}}}}},{"spec":{"jobTemplate":{"spec":{"template":{"spec":{"=(ephemeralContainers)":[{"securityContext":{"runAsGroup":"\u003e0"}}],"=(initContainers)":[{"securityContext":{"runAsGroup":"\u003e0"}}],"containers":[{"securityContext":{"runAsGroup":"\u003e0"}}]}}}}}}],"message":"Running with root group IDs is disallowed. The fields spec.securityContext.runAsGroup, spec.containers[*].securityContext.runAsGroup, spec.initContainers[*].securityContext.runAsGroup, and spec.ephemeralContainers[*].securityContext.runAsGroup must be set to a value greater than zero."}},{"exclude":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"],"namespaces":["grafana-agent","calico-system","calico-apiserver","aws-ebs-csi-driver","aws-efs-csi-driver","datadog","akuity-admin","grafana-agent","monitoring","kubecross-system"]}}],"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"]}}],"resources":{}},"mutate":{},"name":"autogen-check-supplementalgroups","validate":{"message":"Containers cannot run with a root primary or supplementary GID. The field spec.securityContext.supplementalGroups must be unset or set to a value greater than zero.","pattern":{"spec":{"template":{"spec":{"=(securityContext)":{"=(supplementalGroups)":"\u003e0"}}}}}}},{"exclude":{"any":[{"resources":{"kinds":["CronJob"],"namespaces":["grafana-agent","calico-system","calico-apiserver","aws-ebs-csi-driver","aws-efs-csi-driver","datadog","akuity-admin","grafana-agent","monitoring","kubecross-system"]}}],"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["CronJob"]}}],"resources":{}},"mutate":{},"name":"autogen-cronjob-check-supplementalgroups","validate":{"message":"Containers cannot run with a root primary or supplementary GID. The field spec.securityContext.supplementalGroups must be unset or set to a value greater than zero.","pattern":{"spec":{"jobTemplate":{"spec":{"template":{"spec":{"=(securityContext)":{"=(supplementalGroups)":"\u003e0"}}}}}}}}},{"exclude":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"],"namespaces":["grafana-agent","calico-system","calico-apiserver","aws-ebs-csi-driver","aws-efs-csi-driver","datadog","akuity-admin","monitoring"]}}],"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"]}}],"resources":{}},"mutate":{},"name":"autogen-check-fsgroup","validate":{"message":"Containers cannot run with a root primary or supplementary GID. The field spec.securityContext.fsGroup must be unset or set to a value greater than zero.","pattern":{"spec":{"template":{"spec":{"=(securityContext)":{"=(fsGroup)":"\u003e0"}}}}}}},{"exclude":{"any":[{"resources":{"kinds":["CronJob"],"namespaces":["grafana-agent","calico-system","calico-apiserver","aws-ebs-csi-driver","aws-efs-csi-driver","datadog","akuity-admin","monitoring"]}}],"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["CronJob"]}}],"resources":{}},"mutate":{},"name":"autogen-cronjob-check-fsgroup","validate":{"message":"Containers cannot run with a root primary or supplementary GID. The field spec.securityContext.fsGroup must be unset or set to a value greater than zero.","pattern":{"spec":{"jobTemplate":{"spec":{"template":{"spec":{"=(securityContext)":{"=(fsGroup)":"\u003e0"}}}}}}}}}]},"conditions":[{"lastTransitionTime":"2024-02-23T16:11:54Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":3,"verifyimages":0}}}
      kyverno.io/kubernetes-version: 1.22-1.23
      kyverno.io/kyverno-version: 1.6.0
      policies.kyverno.io/category: Sample, EKS Best Practices
      policies.kyverno.io/description: Containers should be forbidden from running
        with a root primary or supplementary GID. This policy ensures the `runAsGroup`,
        `supplementalGroups`, and `fsGroup` fields are set to a number greater than
        zero (i.e., non root). A known issue prevents a policy such as this using
        `anyPattern` from being persisted properly in Kubernetes 1.23.0-1.23.2.
      policies.kyverno.io/minversion: 1.3.6
      policies.kyverno.io/severity: medium
      policies.kyverno.io/subject: Pod
      policies.kyverno.io/title: Require Non-Root Groups
    creationTimestamp: "2024-04-16T06:35:31Z"
    generation: 1
    name: require-non-root-groups
    resourceVersion: "28892"
    uid: 1d878e4f-2268-4d57-b27f-4320ef24ac80
  spec:
    background: true
    rules:
    - exclude:
        any:
        - resources:
            kinds:
            - Pod
            namespaces:
            - akuity-admin
            - gloo-system
            - rbac-manager
            - tigera-operator
            - tigera-apiserver
            - tigera-system
            - tigera-fluentd
            - tigera-compliance
            - grafana-agent
            - calico-apiserver
            - calico-system
            - aws-ebs-csi-driver
            - aws-efs-csi-driver
            - datadog
            - monitoring
            - kubecross-system
            - datadog
      match:
        any:
        - resources:
            kinds:
            - Pod
      name: check-runasgroup
      validate:
        anyPattern:
        - spec:
            =(ephemeralContainers):
            - =(securityContext):
                =(runAsGroup): '>0'
            =(initContainers):
            - =(securityContext):
                =(runAsGroup): '>0'
            containers:
            - =(securityContext):
                =(runAsGroup): '>0'
            securityContext:
              runAsGroup: '>0'
        - spec:
            =(ephemeralContainers):
            - securityContext:
                runAsGroup: '>0'
            =(initContainers):
            - securityContext:
                runAsGroup: '>0'
            containers:
            - securityContext:
                runAsGroup: '>0'
        message: Running with root group IDs is disallowed. The fields spec.securityContext.runAsGroup,
          spec.containers[*].securityContext.runAsGroup, spec.initContainers[*].securityContext.runAsGroup,
          and spec.ephemeralContainers[*].securityContext.runAsGroup must be set to
          a value greater than zero.
    - exclude:
        any:
        - resources:
            kinds:
            - Pod
            namespaces:
            - grafana-agent
            - calico-system
            - calico-apiserver
            - aws-ebs-csi-driver
            - aws-efs-csi-driver
            - datadog
            - akuity-admin
            - grafana-agent
            - monitoring
            - kubecross-system
      match:
        any:
        - resources:
            kinds:
            - Pod
      name: check-supplementalgroups
      validate:
        message: Containers cannot run with a root primary or supplementary GID. The
          field spec.securityContext.supplementalGroups must be unset or set to a
          value greater than zero.
        pattern:
          spec:
            =(securityContext):
              =(supplementalGroups): '>0'
    - exclude:
        any:
        - resources:
            kinds:
            - Pod
            namespaces:
            - grafana-agent
            - calico-system
            - calico-apiserver
            - aws-ebs-csi-driver
            - aws-efs-csi-driver
            - datadog
            - akuity-admin
            - monitoring
      match:
        any:
        - resources:
            kinds:
            - Pod
      name: check-fsgroup
      validate:
        message: Containers cannot run with a root primary or supplementary GID. The
          field spec.securityContext.fsGroup must be unset or set to a value greater
          than zero.
        pattern:
          spec:
            =(securityContext):
              =(fsGroup): '>0'
    validationFailureAction: audit
  status:
    autogen:
      rules:
      - exclude:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
              namespaces:
              - akuity-admin
              - gloo-system
              - rbac-manager
              - tigera-operator
              - tigera-apiserver
              - tigera-system
              - tigera-fluentd
              - tigera-compliance
              - grafana-agent
              - calico-apiserver
              - calico-system
              - aws-ebs-csi-driver
              - aws-efs-csi-driver
              - datadog
              - monitoring
              - kubecross-system
              - datadog
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
          resources: {}
        mutate: {}
        name: autogen-check-runasgroup
        validate:
          anyPattern:
          - spec:
              template:
                spec:
                  =(ephemeralContainers):
                  - =(securityContext):
                      =(runAsGroup): '>0'
                  =(initContainers):
                  - =(securityContext):
                      =(runAsGroup): '>0'
                  containers:
                  - =(securityContext):
                      =(runAsGroup): '>0'
                  securityContext:
                    runAsGroup: '>0'
          - spec:
              template:
                spec:
                  =(ephemeralContainers):
                  - securityContext:
                      runAsGroup: '>0'
                  =(initContainers):
                  - securityContext:
                      runAsGroup: '>0'
                  containers:
                  - securityContext:
                      runAsGroup: '>0'
          message: Running with root group IDs is disallowed. The fields spec.securityContext.runAsGroup,
            spec.containers[*].securityContext.runAsGroup, spec.initContainers[*].securityContext.runAsGroup,
            and spec.ephemeralContainers[*].securityContext.runAsGroup must be set
            to a value greater than zero.
      - exclude:
          any:
          - resources:
              kinds:
              - CronJob
              namespaces:
              - akuity-admin
              - gloo-system
              - rbac-manager
              - tigera-operator
              - tigera-apiserver
              - tigera-system
              - tigera-fluentd
              - tigera-compliance
              - grafana-agent
              - calico-apiserver
              - calico-system
              - aws-ebs-csi-driver
              - aws-efs-csi-driver
              - datadog
              - monitoring
              - kubecross-system
              - datadog
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - CronJob
          resources: {}
        mutate: {}
        name: autogen-cronjob-check-runasgroup
        validate:
          anyPattern:
          - spec:
              jobTemplate:
                spec:
                  template:
                    spec:
                      =(ephemeralContainers):
                      - =(securityContext):
                          =(runAsGroup): '>0'
                      =(initContainers):
                      - =(securityContext):
                          =(runAsGroup): '>0'
                      containers:
                      - =(securityContext):
                          =(runAsGroup): '>0'
                      securityContext:
                        runAsGroup: '>0'
          - spec:
              jobTemplate:
                spec:
                  template:
                    spec:
                      =(ephemeralContainers):
                      - securityContext:
                          runAsGroup: '>0'
                      =(initContainers):
                      - securityContext:
                          runAsGroup: '>0'
                      containers:
                      - securityContext:
                          runAsGroup: '>0'
          message: Running with root group IDs is disallowed. The fields spec.securityContext.runAsGroup,
            spec.containers[*].securityContext.runAsGroup, spec.initContainers[*].securityContext.runAsGroup,
            and spec.ephemeralContainers[*].securityContext.runAsGroup must be set
            to a value greater than zero.
      - exclude:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
              namespaces:
              - grafana-agent
              - calico-system
              - calico-apiserver
              - aws-ebs-csi-driver
              - aws-efs-csi-driver
              - datadog
              - akuity-admin
              - grafana-agent
              - monitoring
              - kubecross-system
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
          resources: {}
        mutate: {}
        name: autogen-check-supplementalgroups
        validate:
          message: Containers cannot run with a root primary or supplementary GID.
            The field spec.securityContext.supplementalGroups must be unset or set
            to a value greater than zero.
          pattern:
            spec:
              template:
                spec:
                  =(securityContext):
                    =(supplementalGroups): '>0'
      - exclude:
          any:
          - resources:
              kinds:
              - CronJob
              namespaces:
              - grafana-agent
              - calico-system
              - calico-apiserver
              - aws-ebs-csi-driver
              - aws-efs-csi-driver
              - datadog
              - akuity-admin
              - grafana-agent
              - monitoring
              - kubecross-system
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - CronJob
          resources: {}
        mutate: {}
        name: autogen-cronjob-check-supplementalgroups
        validate:
          message: Containers cannot run with a root primary or supplementary GID.
            The field spec.securityContext.supplementalGroups must be unset or set
            to a value greater than zero.
          pattern:
            spec:
              jobTemplate:
                spec:
                  template:
                    spec:
                      =(securityContext):
                        =(supplementalGroups): '>0'
      - exclude:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
              namespaces:
              - grafana-agent
              - calico-system
              - calico-apiserver
              - aws-ebs-csi-driver
              - aws-efs-csi-driver
              - datadog
              - akuity-admin
              - monitoring
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
          resources: {}
        mutate: {}
        name: autogen-check-fsgroup
        validate:
          message: Containers cannot run with a root primary or supplementary GID.
            The field spec.securityContext.fsGroup must be unset or set to a value
            greater than zero.
          pattern:
            spec:
              template:
                spec:
                  =(securityContext):
                    =(fsGroup): '>0'
      - exclude:
          any:
          - resources:
              kinds:
              - CronJob
              namespaces:
              - grafana-agent
              - calico-system
              - calico-apiserver
              - aws-ebs-csi-driver
              - aws-efs-csi-driver
              - datadog
              - akuity-admin
              - monitoring
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - CronJob
          resources: {}
        mutate: {}
        name: autogen-cronjob-check-fsgroup
        validate:
          message: Containers cannot run with a root primary or supplementary GID.
            The field spec.securityContext.fsGroup must be unset or set to a value
            greater than zero.
          pattern:
            spec:
              jobTemplate:
                spec:
                  template:
                    spec:
                      =(securityContext):
                        =(fsGroup): '>0'
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:31Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 3
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/require-ro-rootfs
      controls.cfasec.com/id: pod6
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/require-ro-rootfs","controls.cfasec.com/id":"pod6","policies.kyverno.io/category":"Best Practices","policies.kyverno.io/description":"A read-only root file system helps to enforce an immutable infrastructure strategy; the container only needs to write on the mounted volume that persists the state. An immutable root filesystem can also prevent malicious binaries from writing to the host system. This policy validates that containers define a securityContext with `readOnlyRootFilesystem: true`.","policies.kyverno.io/severity":"medium","policies.kyverno.io/subject":"Pod","policies.kyverno.io/title":"Require Read-Only Root Filesystem"},"creationTimestamp":"2024-02-23T16:11:27Z","generation":1,"name":"require-ro-rootfs","resourceVersion":"727837351","uid":"3c554e80-b3c3-40c6-adac-905a058a48b7"},"spec":{"background":true,"rules":[{"exclude":{"resources":{"kinds":["Pod"],"namespaceSelector":{"matchExpressions":[{"key":"exception/readOnlyFS","operator":"In","values":["true"]}]}}},"match":{"resources":{"kinds":["Pod"]}},"name":"validate-readOnlyRootFilesystem","validate":{"message":"Root filesystem must be read-only.","pattern":{"spec":{"containers":[{"securityContext":{"readOnlyRootFilesystem":true}}]}}}}],"validationFailureAction":"audit"},"status":{"autogen":{"rules":[{"exclude":{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"],"namespaceSelector":{"matchExpressions":[{"key":"exception/readOnlyFS","operator":"In","values":["true"]}]}}},"generate":{"clone":{},"cloneList":{}},"match":{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"]}},"mutate":{},"name":"autogen-validate-readOnlyRootFilesystem","validate":{"message":"Root filesystem must be read-only.","pattern":{"spec":{"template":{"spec":{"containers":[{"securityContext":{"readOnlyRootFilesystem":true}}]}}}}}},{"exclude":{"resources":{"kinds":["CronJob"],"namespaceSelector":{"matchExpressions":[{"key":"exception/readOnlyFS","operator":"In","values":["true"]}]}}},"generate":{"clone":{},"cloneList":{}},"match":{"resources":{"kinds":["CronJob"]}},"mutate":{},"name":"autogen-cronjob-validate-readOnlyRootFilesystem","validate":{"message":"Root filesystem must be read-only.","pattern":{"spec":{"jobTemplate":{"spec":{"template":{"spec":{"containers":[{"securityContext":{"readOnlyRootFilesystem":true}}]}}}}}}}}]},"conditions":[{"lastTransitionTime":"2024-02-23T16:11:32Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":1,"verifyimages":0}}}
      policies.kyverno.io/category: Best Practices
      policies.kyverno.io/description: 'A read-only root file system helps to enforce
        an immutable infrastructure strategy; the container only needs to write on
        the mounted volume that persists the state. An immutable root filesystem can
        also prevent malicious binaries from writing to the host system. This policy
        validates that containers define a securityContext with `readOnlyRootFilesystem:
        true`.'
      policies.kyverno.io/severity: medium
      policies.kyverno.io/subject: Pod
      policies.kyverno.io/title: Require Read-Only Root Filesystem
    creationTimestamp: "2024-04-16T06:35:32Z"
    generation: 1
    name: require-ro-rootfs
    resourceVersion: "28945"
    uid: 2f5a9075-98b6-49fb-8e1c-7caf49ac3f02
  spec:
    background: true
    rules:
    - exclude:
        resources:
          kinds:
          - Pod
          namespaceSelector:
            matchExpressions:
            - key: exception/readOnlyFS
              operator: In
              values:
              - "true"
      match:
        resources:
          kinds:
          - Pod
      name: validate-readOnlyRootFilesystem
      validate:
        message: Root filesystem must be read-only.
        pattern:
          spec:
            containers:
            - securityContext:
                readOnlyRootFilesystem: true
    validationFailureAction: audit
  status:
    autogen:
      rules:
      - exclude:
          resources:
            kinds:
            - DaemonSet
            - Deployment
            - Job
            - StatefulSet
            - ReplicaSet
            - ReplicationController
            namespaceSelector:
              matchExpressions:
              - key: exception/readOnlyFS
                operator: In
                values:
                - "true"
        generate:
          clone: {}
          cloneList: {}
        match:
          resources:
            kinds:
            - DaemonSet
            - Deployment
            - Job
            - StatefulSet
            - ReplicaSet
            - ReplicationController
        mutate: {}
        name: autogen-validate-readOnlyRootFilesystem
        validate:
          message: Root filesystem must be read-only.
          pattern:
            spec:
              template:
                spec:
                  containers:
                  - securityContext:
                      readOnlyRootFilesystem: true
      - exclude:
          resources:
            kinds:
            - CronJob
            namespaceSelector:
              matchExpressions:
              - key: exception/readOnlyFS
                operator: In
                values:
                - "true"
        generate:
          clone: {}
          cloneList: {}
        match:
          resources:
            kinds:
            - CronJob
        mutate: {}
        name: autogen-cronjob-validate-readOnlyRootFilesystem
        validate:
          message: Root filesystem must be read-only.
          pattern:
            spec:
              jobTemplate:
                spec:
                  template:
                    spec:
                      containers:
                      - securityContext:
                          readOnlyRootFilesystem: true
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:32Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/require-run-as-non-root-user
      controls.cfasec.com/id: hp14
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/require-run-as-non-root-user","controls.cfasec.com/id":"hp14","kyverno.io/kubernetes-version":"1.22-1.23","kyverno.io/kyverno-version":"1.6.0","policies.kyverno.io/category":"Pod Security Standards (Restricted)","policies.kyverno.io/description":"Containers must be required to run as non-root users. This policy ensures `runAsUser` is either unset or set to a number greater than zero.","policies.kyverno.io/severity":"medium","policies.kyverno.io/subject":"Pod","policies.kyverno.io/title":"Require Run As Non-Root User"},"creationTimestamp":"2024-02-23T15:54:02Z","generation":1,"name":"require-run-as-non-root-user","resourceVersion":"727809466","uid":"58ecb5af-0f4f-4d8f-a3ac-cff7c72f3e7b"},"spec":{"background":true,"rules":[{"exclude":{"any":[{"resources":{"kinds":["Pod"],"namespaces":["datadog","grafana-agent","calico-apiserver","calico-system","gloo-system","aws-ebs-csi-driver","aws-efs-csi-driver","tigera-operator","tigera-apiserver","tigera-system","tigera-fluentd","tigera-compliance"]}}]},"match":{"any":[{"resources":{"kinds":["Pod"]}}]},"name":"run-as-non-root-user","validate":{"message":"Running as root is not allowed. The fields spec.securityContext.runAsUser, spec.containers[*].securityContext.runAsUser, spec.initContainers[*].securityContext.runAsUser, and spec.ephemeralContainers[*].securityContext.runAsUser must be unset or set to a number greater than zero.","pattern":{"spec":{"=(ephemeralContainers)":[{"=(securityContext)":{"=(runAsUser)":"\u003e0"}}],"=(initContainers)":[{"=(securityContext)":{"=(runAsUser)":"\u003e0"}}],"=(securityContext)":{"=(runAsUser)":"\u003e0"},"containers":[{"=(securityContext)":{"=(runAsUser)":"\u003e0"}}]}}}}],"validationFailureAction":"audit"},"status":{"autogen":{"rules":[{"exclude":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"],"namespaces":["datadog","grafana-agent","calico-apiserver","calico-system","gloo-system","aws-ebs-csi-driver","aws-efs-csi-driver","tigera-operator","tigera-apiserver","tigera-system","tigera-fluentd","tigera-compliance"]}}],"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"]}}],"resources":{}},"mutate":{},"name":"autogen-run-as-non-root-user","validate":{"message":"Running as root is not allowed. The fields spec.securityContext.runAsUser, spec.containers[*].securityContext.runAsUser, spec.initContainers[*].securityContext.runAsUser, and spec.ephemeralContainers[*].securityContext.runAsUser must be unset or set to a number greater than zero.","pattern":{"spec":{"template":{"spec":{"=(ephemeralContainers)":[{"=(securityContext)":{"=(runAsUser)":"\u003e0"}}],"=(initContainers)":[{"=(securityContext)":{"=(runAsUser)":"\u003e0"}}],"=(securityContext)":{"=(runAsUser)":"\u003e0"},"containers":[{"=(securityContext)":{"=(runAsUser)":"\u003e0"}}]}}}}}},{"exclude":{"any":[{"resources":{"kinds":["CronJob"],"namespaces":["datadog","grafana-agent","calico-apiserver","calico-system","gloo-system","aws-ebs-csi-driver","aws-efs-csi-driver","tigera-operator","tigera-apiserver","tigera-system","tigera-fluentd","tigera-compliance"]}}],"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["CronJob"]}}],"resources":{}},"mutate":{},"name":"autogen-cronjob-run-as-non-root-user","validate":{"message":"Running as root is not allowed. The fields spec.securityContext.runAsUser, spec.containers[*].securityContext.runAsUser, spec.initContainers[*].securityContext.runAsUser, and spec.ephemeralContainers[*].securityContext.runAsUser must be unset or set to a number greater than zero.","pattern":{"spec":{"jobTemplate":{"spec":{"template":{"spec":{"=(ephemeralContainers)":[{"=(securityContext)":{"=(runAsUser)":"\u003e0"}}],"=(initContainers)":[{"=(securityContext)":{"=(runAsUser)":"\u003e0"}}],"=(securityContext)":{"=(runAsUser)":"\u003e0"},"containers":[{"=(securityContext)":{"=(runAsUser)":"\u003e0"}}]}}}}}}}}]},"conditions":[{"lastTransitionTime":"2024-02-23T15:54:13Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":1,"verifyimages":0}}}
      kyverno.io/kubernetes-version: 1.22-1.23
      kyverno.io/kyverno-version: 1.6.0
      policies.kyverno.io/category: Pod Security Standards (Restricted)
      policies.kyverno.io/description: Containers must be required to run as non-root
        users. This policy ensures `runAsUser` is either unset or set to a number
        greater than zero.
      policies.kyverno.io/severity: medium
      policies.kyverno.io/subject: Pod
      policies.kyverno.io/title: Require Run As Non-Root User
    creationTimestamp: "2024-04-16T06:35:32Z"
    generation: 1
    name: require-run-as-non-root-user
    resourceVersion: "28989"
    uid: 23e6e113-175c-48a8-8970-e921443ca731
  spec:
    background: true
    rules:
    - exclude:
        any:
        - resources:
            kinds:
            - Pod
            namespaces:
            - datadog
            - grafana-agent
            - calico-apiserver
            - calico-system
            - gloo-system
            - aws-ebs-csi-driver
            - aws-efs-csi-driver
            - tigera-operator
            - tigera-apiserver
            - tigera-system
            - tigera-fluentd
            - tigera-compliance
      match:
        any:
        - resources:
            kinds:
            - Pod
      name: run-as-non-root-user
      validate:
        message: Running as root is not allowed. The fields spec.securityContext.runAsUser,
          spec.containers[*].securityContext.runAsUser, spec.initContainers[*].securityContext.runAsUser,
          and spec.ephemeralContainers[*].securityContext.runAsUser must be unset
          or set to a number greater than zero.
        pattern:
          spec:
            =(ephemeralContainers):
            - =(securityContext):
                =(runAsUser): '>0'
            =(initContainers):
            - =(securityContext):
                =(runAsUser): '>0'
            =(securityContext):
              =(runAsUser): '>0'
            containers:
            - =(securityContext):
                =(runAsUser): '>0'
    validationFailureAction: audit
  status:
    autogen:
      rules:
      - exclude:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
              namespaces:
              - datadog
              - grafana-agent
              - calico-apiserver
              - calico-system
              - gloo-system
              - aws-ebs-csi-driver
              - aws-efs-csi-driver
              - tigera-operator
              - tigera-apiserver
              - tigera-system
              - tigera-fluentd
              - tigera-compliance
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
          resources: {}
        mutate: {}
        name: autogen-run-as-non-root-user
        validate:
          message: Running as root is not allowed. The fields spec.securityContext.runAsUser,
            spec.containers[*].securityContext.runAsUser, spec.initContainers[*].securityContext.runAsUser,
            and spec.ephemeralContainers[*].securityContext.runAsUser must be unset
            or set to a number greater than zero.
          pattern:
            spec:
              template:
                spec:
                  =(ephemeralContainers):
                  - =(securityContext):
                      =(runAsUser): '>0'
                  =(initContainers):
                  - =(securityContext):
                      =(runAsUser): '>0'
                  =(securityContext):
                    =(runAsUser): '>0'
                  containers:
                  - =(securityContext):
                      =(runAsUser): '>0'
      - exclude:
          any:
          - resources:
              kinds:
              - CronJob
              namespaces:
              - datadog
              - grafana-agent
              - calico-apiserver
              - calico-system
              - gloo-system
              - aws-ebs-csi-driver
              - aws-efs-csi-driver
              - tigera-operator
              - tigera-apiserver
              - tigera-system
              - tigera-fluentd
              - tigera-compliance
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - CronJob
          resources: {}
        mutate: {}
        name: autogen-cronjob-run-as-non-root-user
        validate:
          message: Running as root is not allowed. The fields spec.securityContext.runAsUser,
            spec.containers[*].securityContext.runAsUser, spec.initContainers[*].securityContext.runAsUser,
            and spec.ephemeralContainers[*].securityContext.runAsUser must be unset
            or set to a number greater than zero.
          pattern:
            spec:
              jobTemplate:
                spec:
                  template:
                    spec:
                      =(ephemeralContainers):
                      - =(securityContext):
                          =(runAsUser): '>0'
                      =(initContainers):
                      - =(securityContext):
                          =(runAsUser): '>0'
                      =(securityContext):
                        =(runAsUser): '>0'
                      containers:
                      - =(securityContext):
                          =(runAsUser): '>0'
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:32Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/require-run-as-nonroot
      controls.cfasec.com/id: hp13
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/require-run-as-nonroot","controls.cfasec.com/id":"hp13","kyverno.io/kubernetes-version":"1.22-1.23","kyverno.io/kyverno-version":"1.6.0","policies.kyverno.io/category":"Pod Security Standards (Restricted)","policies.kyverno.io/description":"Containers must be required to run as non-root users. This policy ensures `runAsNonRoot` is set to `true`. A known issue prevents a policy such as this using `anyPattern` from being persisted properly in Kubernetes 1.23.0-1.23.2.","policies.kyverno.io/severity":"medium","policies.kyverno.io/subject":"Pod","policies.kyverno.io/title":"Require runAsNonRoot"},"creationTimestamp":"2024-02-23T16:11:28Z","generation":1,"name":"require-run-as-nonroot","resourceVersion":"727837355","uid":"eaf159e4-7e8a-42eb-9183-cf762606c7a0"},"spec":{"background":true,"rules":[{"exclude":{"any":[{"resources":{"kinds":["Pod"],"namespaces":["akuity","aws-ebs-csi-driver","aws-ebs-csi-driver","aws-efc-csi-driver","aws-efs-csi-driver","brupop-bottlerocket-aws","calico-apiserver","calico-system","cluster-autoscaler","datadog","external-secrets","gloo-system","grafana-agent","karpenter","kube-system","kubecross-system","monitoring","tigera-operator"]}}]},"match":{"any":[{"resources":{"kinds":["Pod"]}}]},"name":"run-as-non-root","validate":{"anyPattern":[{"spec":{"=(ephemeralContainers)":[{"=(securityContext)":{"=(runAsNonRoot)":true}}],"=(initContainers)":[{"=(securityContext)":{"=(runAsNonRoot)":true}}],"containers":[{"=(securityContext)":{"=(runAsNonRoot)":true}}],"securityContext":{"runAsNonRoot":true}}},{"spec":{"=(ephemeralContainers)":[{"securityContext":{"runAsNonRoot":true}}],"=(initContainers)":[{"securityContext":{"runAsNonRoot":true}}],"containers":[{"securityContext":{"runAsNonRoot":true}}]}}],"message":"Running as root is not allowed. Either the field spec.securityContext.runAsNonRoot must be set to `true`, or the fields spec.containers[*].securityContext.runAsNonRoot, spec.initContainers[*].securityContext.runAsNonRoot, and spec.ephemeralContainers[*].securityContext.runAsNonRoot must be set to `true`."}}],"validationFailureAction":"audit"},"status":{"autogen":{"rules":[{"exclude":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"],"namespaces":["akuity","aws-ebs-csi-driver","aws-ebs-csi-driver","aws-efc-csi-driver","aws-efs-csi-driver","brupop-bottlerocket-aws","calico-apiserver","calico-system","cluster-autoscaler","datadog","external-secrets","gloo-system","grafana-agent","karpenter","kube-system","kubecross-system","monitoring","tigera-operator"]}}],"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"]}}],"resources":{}},"mutate":{},"name":"autogen-run-as-non-root","validate":{"anyPattern":[{"spec":{"template":{"spec":{"=(ephemeralContainers)":[{"=(securityContext)":{"=(runAsNonRoot)":true}}],"=(initContainers)":[{"=(securityContext)":{"=(runAsNonRoot)":true}}],"containers":[{"=(securityContext)":{"=(runAsNonRoot)":true}}],"securityContext":{"runAsNonRoot":true}}}}},{"spec":{"template":{"spec":{"=(ephemeralContainers)":[{"securityContext":{"runAsNonRoot":true}}],"=(initContainers)":[{"securityContext":{"runAsNonRoot":true}}],"containers":[{"securityContext":{"runAsNonRoot":true}}]}}}}],"message":"Running as root is not allowed. Either the field spec.securityContext.runAsNonRoot must be set to `true`, or the fields spec.containers[*].securityContext.runAsNonRoot, spec.initContainers[*].securityContext.runAsNonRoot, and spec.ephemeralContainers[*].securityContext.runAsNonRoot must be set to `true`."}},{"exclude":{"any":[{"resources":{"kinds":["CronJob"],"namespaces":["akuity","aws-ebs-csi-driver","aws-ebs-csi-driver","aws-efc-csi-driver","aws-efs-csi-driver","brupop-bottlerocket-aws","calico-apiserver","calico-system","cluster-autoscaler","datadog","external-secrets","gloo-system","grafana-agent","karpenter","kube-system","kubecross-system","monitoring","tigera-operator"]}}],"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["CronJob"]}}],"resources":{}},"mutate":{},"name":"autogen-cronjob-run-as-non-root","validate":{"anyPattern":[{"spec":{"jobTemplate":{"spec":{"template":{"spec":{"=(ephemeralContainers)":[{"=(securityContext)":{"=(runAsNonRoot)":true}}],"=(initContainers)":[{"=(securityContext)":{"=(runAsNonRoot)":true}}],"containers":[{"=(securityContext)":{"=(runAsNonRoot)":true}}],"securityContext":{"runAsNonRoot":true}}}}}}},{"spec":{"jobTemplate":{"spec":{"template":{"spec":{"=(ephemeralContainers)":[{"securityContext":{"runAsNonRoot":true}}],"=(initContainers)":[{"securityContext":{"runAsNonRoot":true}}],"containers":[{"securityContext":{"runAsNonRoot":true}}]}}}}}}],"message":"Running as root is not allowed. Either the field spec.securityContext.runAsNonRoot must be set to `true`, or the fields spec.containers[*].securityContext.runAsNonRoot, spec.initContainers[*].securityContext.runAsNonRoot, and spec.ephemeralContainers[*].securityContext.runAsNonRoot must be set to `true`."}}]},"conditions":[{"lastTransitionTime":"2024-02-23T16:11:32Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":1,"verifyimages":0}}}
      kyverno.io/kubernetes-version: 1.22-1.23
      kyverno.io/kyverno-version: 1.6.0
      policies.kyverno.io/category: Pod Security Standards (Restricted)
      policies.kyverno.io/description: Containers must be required to run as non-root
        users. This policy ensures `runAsNonRoot` is set to `true`. A known issue
        prevents a policy such as this using `anyPattern` from being persisted properly
        in Kubernetes 1.23.0-1.23.2.
      policies.kyverno.io/severity: medium
      policies.kyverno.io/subject: Pod
      policies.kyverno.io/title: Require runAsNonRoot
    creationTimestamp: "2024-04-16T06:35:32Z"
    generation: 1
    name: require-run-as-nonroot
    resourceVersion: "29048"
    uid: 2f1ce7ad-97a7-458c-997c-f859c9da5724
  spec:
    background: true
    rules:
    - exclude:
        any:
        - resources:
            kinds:
            - Pod
            namespaces:
            - akuity
            - aws-ebs-csi-driver
            - aws-ebs-csi-driver
            - aws-efc-csi-driver
            - aws-efs-csi-driver
            - brupop-bottlerocket-aws
            - calico-apiserver
            - calico-system
            - cluster-autoscaler
            - datadog
            - external-secrets
            - gloo-system
            - grafana-agent
            - karpenter
            - kube-system
            - kubecross-system
            - monitoring
            - tigera-operator
      match:
        any:
        - resources:
            kinds:
            - Pod
      name: run-as-non-root
      validate:
        anyPattern:
        - spec:
            =(ephemeralContainers):
            - =(securityContext):
                =(runAsNonRoot): true
            =(initContainers):
            - =(securityContext):
                =(runAsNonRoot): true
            containers:
            - =(securityContext):
                =(runAsNonRoot): true
            securityContext:
              runAsNonRoot: true
        - spec:
            =(ephemeralContainers):
            - securityContext:
                runAsNonRoot: true
            =(initContainers):
            - securityContext:
                runAsNonRoot: true
            containers:
            - securityContext:
                runAsNonRoot: true
        message: Running as root is not allowed. Either the field spec.securityContext.runAsNonRoot
          must be set to `true`, or the fields spec.containers[*].securityContext.runAsNonRoot,
          spec.initContainers[*].securityContext.runAsNonRoot, and spec.ephemeralContainers[*].securityContext.runAsNonRoot
          must be set to `true`.
    validationFailureAction: audit
  status:
    autogen:
      rules:
      - exclude:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
              namespaces:
              - akuity
              - aws-ebs-csi-driver
              - aws-ebs-csi-driver
              - aws-efc-csi-driver
              - aws-efs-csi-driver
              - brupop-bottlerocket-aws
              - calico-apiserver
              - calico-system
              - cluster-autoscaler
              - datadog
              - external-secrets
              - gloo-system
              - grafana-agent
              - karpenter
              - kube-system
              - kubecross-system
              - monitoring
              - tigera-operator
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
          resources: {}
        mutate: {}
        name: autogen-run-as-non-root
        validate:
          anyPattern:
          - spec:
              template:
                spec:
                  =(ephemeralContainers):
                  - =(securityContext):
                      =(runAsNonRoot): true
                  =(initContainers):
                  - =(securityContext):
                      =(runAsNonRoot): true
                  containers:
                  - =(securityContext):
                      =(runAsNonRoot): true
                  securityContext:
                    runAsNonRoot: true
          - spec:
              template:
                spec:
                  =(ephemeralContainers):
                  - securityContext:
                      runAsNonRoot: true
                  =(initContainers):
                  - securityContext:
                      runAsNonRoot: true
                  containers:
                  - securityContext:
                      runAsNonRoot: true
          message: Running as root is not allowed. Either the field spec.securityContext.runAsNonRoot
            must be set to `true`, or the fields spec.containers[*].securityContext.runAsNonRoot,
            spec.initContainers[*].securityContext.runAsNonRoot, and spec.ephemeralContainers[*].securityContext.runAsNonRoot
            must be set to `true`.
      - exclude:
          any:
          - resources:
              kinds:
              - CronJob
              namespaces:
              - akuity
              - aws-ebs-csi-driver
              - aws-ebs-csi-driver
              - aws-efc-csi-driver
              - aws-efs-csi-driver
              - brupop-bottlerocket-aws
              - calico-apiserver
              - calico-system
              - cluster-autoscaler
              - datadog
              - external-secrets
              - gloo-system
              - grafana-agent
              - karpenter
              - kube-system
              - kubecross-system
              - monitoring
              - tigera-operator
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - CronJob
          resources: {}
        mutate: {}
        name: autogen-cronjob-run-as-non-root
        validate:
          anyPattern:
          - spec:
              jobTemplate:
                spec:
                  template:
                    spec:
                      =(ephemeralContainers):
                      - =(securityContext):
                          =(runAsNonRoot): true
                      =(initContainers):
                      - =(securityContext):
                          =(runAsNonRoot): true
                      containers:
                      - =(securityContext):
                          =(runAsNonRoot): true
                      securityContext:
                        runAsNonRoot: true
          - spec:
              jobTemplate:
                spec:
                  template:
                    spec:
                      =(ephemeralContainers):
                      - securityContext:
                          runAsNonRoot: true
                      =(initContainers):
                      - securityContext:
                          runAsNonRoot: true
                      containers:
                      - securityContext:
                          runAsNonRoot: true
          message: Running as root is not allowed. Either the field spec.securityContext.runAsNonRoot
            must be set to `true`, or the fields spec.containers[*].securityContext.runAsNonRoot,
            spec.initContainers[*].securityContext.runAsNonRoot, and spec.ephemeralContainers[*].securityContext.runAsNonRoot
            must be set to `true`.
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:33Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-apparmor-profiles
      controls.cfasec.com/id: gensec1
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-apparmor-profiles","controls.cfasec.com/id":"gensec1","kyverno.io/kubernetes-version":"1.22-1.23","kyverno.io/kyverno-version":"1.6.0","policies.kyverno.io/category":"Pod Security Standards (Baseline)","policies.kyverno.io/description":"On supported hosts, the 'runtime/default' AppArmor profile is applied by default. The default policy should prevent overriding or disabling the policy, or restrict overrides to an allowed set of profiles. This policy ensures Pods do not specify any other AppArmor profiles than `runtime/default` or `localhost/*`.","policies.kyverno.io/minversion":"1.3.0","policies.kyverno.io/severity":"medium","policies.kyverno.io/subject":"Pod, Annotation","policies.kyverno.io/title":"Restrict AppArmor"},"creationTimestamp":"2024-02-23T16:11:51Z","generation":1,"name":"restrict-apparmor-profiles","resourceVersion":"727837782","uid":"4476c95b-f76a-46c1-a0b4-76d1acba7488"},"spec":{"background":true,"rules":[{"match":{"any":[{"resources":{"kinds":["Pod"]}}]},"name":"app-armor","validate":{"message":"Specifying other AppArmor profiles is disallowed. The annotation `container.apparmor.security.beta.kubernetes.io` if defined must not be set to anything other than `runtime/default` or `localhost/*`.","pattern":{"=(metadata)":{"=(annotations)":{"=(container.apparmor.security.beta.kubernetes.io/*)":"runtime/default | localhost/*"}}}}}],"validationFailureAction":"audit"},"status":{"autogen":{"rules":[{"exclude":{"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"]}}],"resources":{}},"mutate":{},"name":"autogen-app-armor","validate":{"message":"Specifying other AppArmor profiles is disallowed. The annotation `container.apparmor.security.beta.kubernetes.io` if defined must not be set to anything other than `runtime/default` or `localhost/*`.","pattern":{"spec":{"template":{"=(metadata)":{"=(annotations)":{"=(container.apparmor.security.beta.kubernetes.io/*)":"runtime/default | localhost/*"}}}}}}},{"exclude":{"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["CronJob"]}}],"resources":{}},"mutate":{},"name":"autogen-cronjob-app-armor","validate":{"message":"Specifying other AppArmor profiles is disallowed. The annotation `container.apparmor.security.beta.kubernetes.io` if defined must not be set to anything other than `runtime/default` or `localhost/*`.","pattern":{"spec":{"jobTemplate":{"spec":{"template":{"=(metadata)":{"=(annotations)":{"=(container.apparmor.security.beta.kubernetes.io/*)":"runtime/default | localhost/*"}}}}}}}}}]},"conditions":[{"lastTransitionTime":"2024-02-23T16:11:53Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":1,"verifyimages":0}}}
      kyverno.io/kubernetes-version: 1.22-1.23
      kyverno.io/kyverno-version: 1.6.0
      policies.kyverno.io/category: Pod Security Standards (Baseline)
      policies.kyverno.io/description: On supported hosts, the 'runtime/default' AppArmor
        profile is applied by default. The default policy should prevent overriding
        or disabling the policy, or restrict overrides to an allowed set of profiles.
        This policy ensures Pods do not specify any other AppArmor profiles than `runtime/default`
        or `localhost/*`.
      policies.kyverno.io/minversion: 1.3.0
      policies.kyverno.io/severity: medium
      policies.kyverno.io/subject: Pod, Annotation
      policies.kyverno.io/title: Restrict AppArmor
    creationTimestamp: "2024-04-16T06:35:33Z"
    generation: 1
    name: restrict-apparmor-profiles
    resourceVersion: "29079"
    uid: 283ae63b-3d98-4ef0-b58c-9cb80b3e15f9
  spec:
    background: true
    rules:
    - match:
        any:
        - resources:
            kinds:
            - Pod
      name: app-armor
      validate:
        message: Specifying other AppArmor profiles is disallowed. The annotation
          `container.apparmor.security.beta.kubernetes.io` if defined must not be
          set to anything other than `runtime/default` or `localhost/*`.
        pattern:
          =(metadata):
            =(annotations):
              =(container.apparmor.security.beta.kubernetes.io/*): runtime/default
                | localhost/*
    validationFailureAction: audit
  status:
    autogen:
      rules:
      - exclude:
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
          resources: {}
        mutate: {}
        name: autogen-app-armor
        validate:
          message: Specifying other AppArmor profiles is disallowed. The annotation
            `container.apparmor.security.beta.kubernetes.io` if defined must not be
            set to anything other than `runtime/default` or `localhost/*`.
          pattern:
            spec:
              template:
                =(metadata):
                  =(annotations):
                    =(container.apparmor.security.beta.kubernetes.io/*): runtime/default
                      | localhost/*
      - exclude:
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - CronJob
          resources: {}
        mutate: {}
        name: autogen-cronjob-app-armor
        validate:
          message: Specifying other AppArmor profiles is disallowed. The annotation
            `container.apparmor.security.beta.kubernetes.io` if defined must not be
            set to anything other than `runtime/default` or `localhost/*`.
          pattern:
            spec:
              jobTemplate:
                spec:
                  template:
                    =(metadata):
                      =(annotations):
                        =(container.apparmor.security.beta.kubernetes.io/*): runtime/default
                          | localhost/*
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:33Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-automount-sa-token
      controls.cfasec.com/id: sm1
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-automount-sa-token","controls.cfasec.com/id":"sm1","policies.kyverno.io/category":"Sample, EKS Best Practices","policies.kyverno.io/description":"Kubernetes automatically mounts ServiceAccount credentials in each Pod. The ServiceAccount may be assigned roles allowing Pods to access API resources. Blocking this ability is an extension of the least privilege best practice and should be followed if Pods do not need to speak to the API server to function. This policy ensures that mounting of these ServiceAccount tokens is blocked.      ","policies.kyverno.io/minversion":"1.6.0","policies.kyverno.io/severity":"medium","policies.kyverno.io/subject":"Pod,ServiceAccount","policies.kyverno.io/title":"Restrict Auto-Mount of Service Account Tokens"},"creationTimestamp":"2024-02-23T16:11:28Z","generation":1,"name":"restrict-automount-sa-token","resourceVersion":"727837330","uid":"98525d5b-8202-4073-847e-ef8505c8cd36"},"spec":{"background":true,"rules":[{"exclude":{"any":[{"resources":{"kinds":["Pod"],"namespaces":["akuity-admin","aws-ebs-csi-driver","aws-efs-csi-driver","calico-apiserver","calico-system","cert-manager","chkk-system","cluster-autoscaler","datadog","enterprise-kyverno-operator","external-dns","external-secrets","fw-argocd","fw-prometheus","fw-telemetry","gloo-system","grafana-agent","insights-agent","karpenter","keda","kube-engineering","kube-self-serve","kube-system","kubecross-system","kubelink-system","kyverno","metrics-server","monitoring","nirmata","rbac-manager","sigsci-agent","tigera-operator"]}}]},"match":{"any":[{"resources":{"kinds":["Pod"]}}]},"name":"validate-automountServiceAccountToken","preconditions":{"all":[{"key":"{{ request.\"object\".metadata.labels.\"app.kubernetes.io/part-of\" || '' }}","operator":"NotEquals","value":"policy-reporter"}]},"validate":{"message":"Auto-mounting of Service Account tokens is not allowed.","pattern":{"spec":{"automountServiceAccountToken":"false"}}}}],"validationFailureAction":"audit"},"status":{"autogen":{"rules":[{"exclude":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"],"namespaces":["akuity-admin","aws-ebs-csi-driver","aws-efs-csi-driver","calico-apiserver","calico-system","cert-manager","chkk-system","cluster-autoscaler","datadog","enterprise-kyverno-operator","external-dns","external-secrets","fw-argocd","fw-prometheus","fw-telemetry","gloo-system","grafana-agent","insights-agent","karpenter","keda","kube-engineering","kube-self-serve","kube-system","kubecross-system","kubelink-system","kyverno","metrics-server","monitoring","nirmata","rbac-manager","sigsci-agent","tigera-operator"]}}],"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"]}}],"resources":{}},"mutate":{},"name":"autogen-validate-automountServiceAccountToken","preconditions":{"all":[{"key":"{{ request.\"object\".metadata.labels.\"app.kubernetes.io/part-of\" || '' }}","operator":"NotEquals","value":"policy-reporter"}]},"validate":{"message":"Auto-mounting of Service Account tokens is not allowed.","pattern":{"spec":{"template":{"spec":{"automountServiceAccountToken":"false"}}}}}},{"exclude":{"any":[{"resources":{"kinds":["CronJob"],"namespaces":["akuity-admin","aws-ebs-csi-driver","aws-efs-csi-driver","calico-apiserver","calico-system","cert-manager","chkk-system","cluster-autoscaler","datadog","enterprise-kyverno-operator","external-dns","external-secrets","fw-argocd","fw-prometheus","fw-telemetry","gloo-system","grafana-agent","insights-agent","karpenter","keda","kube-engineering","kube-self-serve","kube-system","kubecross-system","kubelink-system","kyverno","metrics-server","monitoring","nirmata","rbac-manager","sigsci-agent","tigera-operator"]}}],"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["CronJob"]}}],"resources":{}},"mutate":{},"name":"autogen-cronjob-validate-automountServiceAccountToken","preconditions":{"all":[{"key":"{{ request.\"object\".metadata.labels.\"app.kubernetes.io/part-of\" || '' }}","operator":"NotEquals","value":"policy-reporter"}]},"validate":{"message":"Auto-mounting of Service Account tokens is not allowed.","pattern":{"spec":{"jobTemplate":{"spec":{"template":{"spec":{"automountServiceAccountToken":"false"}}}}}}}}]},"conditions":[{"lastTransitionTime":"2024-02-23T16:11:32Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":1,"verifyimages":0}}}
      policies.kyverno.io/category: Sample, EKS Best Practices
      policies.kyverno.io/description: 'Kubernetes automatically mounts ServiceAccount
        credentials in each Pod. The ServiceAccount may be assigned roles allowing
        Pods to access API resources. Blocking this ability is an extension of the
        least privilege best practice and should be followed if Pods do not need to
        speak to the API server to function. This policy ensures that mounting of
        these ServiceAccount tokens is blocked.      '
      policies.kyverno.io/minversion: 1.6.0
      policies.kyverno.io/severity: medium
      policies.kyverno.io/subject: Pod,ServiceAccount
      policies.kyverno.io/title: Restrict Auto-Mount of Service Account Tokens
    creationTimestamp: "2024-04-16T06:35:33Z"
    generation: 1
    name: restrict-automount-sa-token
    resourceVersion: "29108"
    uid: 199b2aaf-f545-49fa-a69f-871252e80284
  spec:
    background: true
    rules:
    - exclude:
        any:
        - resources:
            kinds:
            - Pod
            namespaces:
            - akuity-admin
            - aws-ebs-csi-driver
            - aws-efs-csi-driver
            - calico-apiserver
            - calico-system
            - cert-manager
            - chkk-system
            - cluster-autoscaler
            - datadog
            - enterprise-kyverno-operator
            - external-dns
            - external-secrets
            - fw-argocd
            - fw-prometheus
            - fw-telemetry
            - gloo-system
            - grafana-agent
            - insights-agent
            - karpenter
            - keda
            - kube-engineering
            - kube-self-serve
            - kube-system
            - kubecross-system
            - kubelink-system
            - kyverno
            - metrics-server
            - monitoring
            - nirmata
            - rbac-manager
            - sigsci-agent
            - tigera-operator
      match:
        any:
        - resources:
            kinds:
            - Pod
      name: validate-automountServiceAccountToken
      preconditions:
        all:
        - key: '{{ request."object".metadata.labels."app.kubernetes.io/part-of" ||
            '''' }}'
          operator: NotEquals
          value: policy-reporter
      validate:
        message: Auto-mounting of Service Account tokens is not allowed.
        pattern:
          spec:
            automountServiceAccountToken: "false"
    validationFailureAction: audit
  status:
    autogen:
      rules:
      - exclude:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
              namespaces:
              - akuity-admin
              - aws-ebs-csi-driver
              - aws-efs-csi-driver
              - calico-apiserver
              - calico-system
              - cert-manager
              - chkk-system
              - cluster-autoscaler
              - datadog
              - enterprise-kyverno-operator
              - external-dns
              - external-secrets
              - fw-argocd
              - fw-prometheus
              - fw-telemetry
              - gloo-system
              - grafana-agent
              - insights-agent
              - karpenter
              - keda
              - kube-engineering
              - kube-self-serve
              - kube-system
              - kubecross-system
              - kubelink-system
              - kyverno
              - metrics-server
              - monitoring
              - nirmata
              - rbac-manager
              - sigsci-agent
              - tigera-operator
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
          resources: {}
        mutate: {}
        name: autogen-validate-automountServiceAccountToken
        preconditions:
          all:
          - key: '{{ request."object".metadata.labels."app.kubernetes.io/part-of"
              || '''' }}'
            operator: NotEquals
            value: policy-reporter
        validate:
          message: Auto-mounting of Service Account tokens is not allowed.
          pattern:
            spec:
              template:
                spec:
                  automountServiceAccountToken: "false"
      - exclude:
          any:
          - resources:
              kinds:
              - CronJob
              namespaces:
              - akuity-admin
              - aws-ebs-csi-driver
              - aws-efs-csi-driver
              - calico-apiserver
              - calico-system
              - cert-manager
              - chkk-system
              - cluster-autoscaler
              - datadog
              - enterprise-kyverno-operator
              - external-dns
              - external-secrets
              - fw-argocd
              - fw-prometheus
              - fw-telemetry
              - gloo-system
              - grafana-agent
              - insights-agent
              - karpenter
              - keda
              - kube-engineering
              - kube-self-serve
              - kube-system
              - kubecross-system
              - kubelink-system
              - kyverno
              - metrics-server
              - monitoring
              - nirmata
              - rbac-manager
              - sigsci-agent
              - tigera-operator
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - CronJob
          resources: {}
        mutate: {}
        name: autogen-cronjob-validate-automountServiceAccountToken
        preconditions:
          all:
          - key: '{{ request."object".metadata.labels."app.kubernetes.io/part-of"
              || '''' }}'
            operator: NotEquals
            value: policy-reporter
        validate:
          message: Auto-mounting of Service Account tokens is not allowed.
          pattern:
            spec:
              jobTemplate:
                spec:
                  template:
                    spec:
                      automountServiceAccountToken: "false"
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:33Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-binding-clusteradmin
      controls.cfasec.com/id: rbac4
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-binding-clusteradmin","controls.cfasec.com/id":"rbac4","kyverno.io/kubernetes-version":"1.23","kyverno.io/kyverno-version":"1.6.2","policies.kyverno.io/category":"Security","policies.kyverno.io/description":"The cluster-admin ClusterRole allows any action to be performed on any resource in the cluster and its granting should be heavily restricted. This policy prevents binding to the cluster-admin ClusterRole in RoleBinding or ClusterRoleBinding resources.","policies.kyverno.io/minversion":"1.6.0","policies.kyverno.io/severity":"medium","policies.kyverno.io/subject":"RoleBinding, ClusterRoleBinding, RBAC","policies.kyverno.io/title":"Restrict Binding to Cluster-Admin"},"creationTimestamp":"2024-02-23T16:11:51Z","generation":1,"name":"restrict-binding-clusteradmin","resourceVersion":"727837813","uid":"390c9e2d-dea8-41ee-9e13-6099ef51d67c"},"spec":{"background":true,"rules":[{"exclude":{"any":[{"resources":{"kinds":["ClusterRoleBinding"],"names":["cluster-admin","oidc-rbac-definition-admins-cluster-admin","calico-cloud-installer-rbac"]}}]},"match":{"any":[{"resources":{"kinds":["RoleBinding","ClusterRoleBinding"]}}]},"name":"clusteradmin-bindings","validate":{"message":"Binding to cluster-admin is not allowed.","pattern":{"roleRef":{"name":"!cluster-admin"}}}}],"validationFailureAction":"audit"},"status":{"autogen":{},"conditions":[{"lastTransitionTime":"2024-02-23T16:11:54Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":1,"verifyimages":0}}}
      kyverno.io/kubernetes-version: "1.23"
      kyverno.io/kyverno-version: 1.6.2
      policies.kyverno.io/category: Security
      policies.kyverno.io/description: The cluster-admin ClusterRole allows any action
        to be performed on any resource in the cluster and its granting should be
        heavily restricted. This policy prevents binding to the cluster-admin ClusterRole
        in RoleBinding or ClusterRoleBinding resources.
      policies.kyverno.io/minversion: 1.6.0
      policies.kyverno.io/severity: medium
      policies.kyverno.io/subject: RoleBinding, ClusterRoleBinding, RBAC
      policies.kyverno.io/title: Restrict Binding to Cluster-Admin
    creationTimestamp: "2024-04-16T06:35:34Z"
    generation: 1
    name: restrict-binding-clusteradmin
    resourceVersion: "29140"
    uid: 4fba3d7c-6acb-4410-99bd-7404cc4b9148
  spec:
    background: true
    rules:
    - exclude:
        any:
        - resources:
            kinds:
            - ClusterRoleBinding
            names:
            - cluster-admin
            - oidc-rbac-definition-admins-cluster-admin
            - calico-cloud-installer-rbac
      match:
        any:
        - resources:
            kinds:
            - RoleBinding
            - ClusterRoleBinding
      name: clusteradmin-bindings
      validate:
        message: Binding to cluster-admin is not allowed.
        pattern:
          roleRef:
            name: '!cluster-admin'
    validationFailureAction: audit
  status:
    autogen: {}
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:34Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-binding-system-groups
      controls.cfasec.com/id: rbac10
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-binding-system-groups","controls.cfasec.com/id":"rbac10","kyverno.io/kubernetes-version":"1.23","kyverno.io/kyverno-version":"1.8.0","policies.kyverno.io/category":"Security, EKS Best Practices","policies.kyverno.io/description":"Certain system groups exist in Kubernetes which grant permissions that are used for certain system-level functions yet typically never appropriate for other users. This policy prevents creating bindings to some of these groups including system:anonymous, system:unauthenticated, and system:masters.","policies.kyverno.io/minversion":"1.6.0","policies.kyverno.io/severity":"medium","policies.kyverno.io/subject":"RoleBinding, ClusterRoleBinding, RBAC","policies.kyverno.io/title":"Restrict Binding System Groups"},"creationTimestamp":"2024-02-23T15:54:02Z","generation":1,"name":"restrict-binding-system-groups","resourceVersion":"727809469","uid":"ab172b69-3430-44ed-bfca-30f03b68f0ae"},"spec":{"background":true,"rules":[{"match":{"any":[{"resources":{"kinds":["RoleBinding","ClusterRoleBinding"]}}]},"name":"restrict-anonymous","validate":{"message":"Binding to system:anonymous is not allowed.","pattern":{"roleRef":{"name":"!system:anonymous"}}}},{"match":{"any":[{"resources":{"kinds":["RoleBinding","ClusterRoleBinding"]}}]},"name":"restrict-unauthenticated","validate":{"message":"Binding to system:unauthenticated is not allowed.","pattern":{"roleRef":{"name":"!system:unauthenticated"}}}},{"match":{"any":[{"resources":{"kinds":["RoleBinding","ClusterRoleBinding"]}}]},"name":"restrict-masters","validate":{"message":"Binding to system:masters is not allowed.","pattern":{"roleRef":{"name":"!system:masters"}}}}],"validationFailureAction":"audit"},"status":{"autogen":{},"conditions":[{"lastTransitionTime":"2024-02-23T15:54:13Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":3,"verifyimages":0}}}
      kyverno.io/kubernetes-version: "1.23"
      kyverno.io/kyverno-version: 1.8.0
      policies.kyverno.io/category: Security, EKS Best Practices
      policies.kyverno.io/description: Certain system groups exist in Kubernetes which
        grant permissions that are used for certain system-level functions yet typically
        never appropriate for other users. This policy prevents creating bindings
        to some of these groups including system:anonymous, system:unauthenticated,
        and system:masters.
      policies.kyverno.io/minversion: 1.6.0
      policies.kyverno.io/severity: medium
      policies.kyverno.io/subject: RoleBinding, ClusterRoleBinding, RBAC
      policies.kyverno.io/title: Restrict Binding System Groups
    creationTimestamp: "2024-04-16T06:35:34Z"
    generation: 1
    name: restrict-binding-system-groups
    resourceVersion: "29166"
    uid: c1f69dba-c949-496f-849c-0e66536ba902
  spec:
    background: true
    rules:
    - match:
        any:
        - resources:
            kinds:
            - RoleBinding
            - ClusterRoleBinding
      name: restrict-anonymous
      validate:
        message: Binding to system:anonymous is not allowed.
        pattern:
          roleRef:
            name: '!system:anonymous'
    - match:
        any:
        - resources:
            kinds:
            - RoleBinding
            - ClusterRoleBinding
      name: restrict-unauthenticated
      validate:
        message: Binding to system:unauthenticated is not allowed.
        pattern:
          roleRef:
            name: '!system:unauthenticated'
    - match:
        any:
        - resources:
            kinds:
            - RoleBinding
            - ClusterRoleBinding
      name: restrict-masters
      validate:
        message: Binding to system:masters is not allowed.
        pattern:
          roleRef:
            name: '!system:masters'
    validationFailureAction: audit
  status:
    autogen: {}
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:34Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 3
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-clusterrole-nodesproxy
      controls.cfasec.com/id: rbac1
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-clusterrole-nodesproxy","controls.cfasec.com/id":"rbac1","kyverno.io/kubernetes-version":"1.23","kyverno.io/kyverno-version":"1.7.0","policies.kyverno.io/category":"Sample","policies.kyverno.io/description":"A ClusterRole with nodes/proxy resource access allows a user to perform anything the kubelet API allows. It also allows users to bypass the API server and talk directly to the kubelet potentially circumventing audits and admission controllers. See https://blog.aquasec.com/privilege-escalation-kubernetes-rbac for more info. This policy prevents the creation of a ClusterRole if it contains the nodes/proxy resource.","policies.kyverno.io/minversion":"1.6.0","policies.kyverno.io/severity":"medium","policies.kyverno.io/subject":"ClusterRole, RBAC","policies.kyverno.io/title":"Restrict ClusterRole with Nodes Proxy"},"creationTimestamp":"2024-02-23T15:54:02Z","generation":1,"name":"restrict-clusterrole-nodesproxy","resourceVersion":"727809471","uid":"f4d7eec0-bb6a-45f4-87d3-0dbfbb91fd9e"},"spec":{"background":false,"rules":[{"exclude":{"any":[{"resources":{"kinds":["ClusterRole"],"selector":{"matchExpressions":[{"key":"app","operator":"In","values":["gloo","grafana","akuity-admin","rbac-manager","datadog","keda"]}]}}},{"resources":{"kinds":["ClusterRole"],"selector":{"matchExpressions":[{"key":"exclude","operator":"In","values":["nodesproxy"]}]}}}]},"match":{"any":[{"resources":{"kinds":["ClusterRole"]}}]},"name":"clusterrole-nodesproxy","validate":{"deny":{"conditions":{"any":[{"key":"nodes/proxy","operator":"AnyIn","value":"{{ request.object.rules[].resources[] }}"}]}},"message":"A ClusterRole containing the nodes/proxy resource is not allowed."}}],"validationFailureAction":"audit"},"status":{"autogen":{},"conditions":[{"lastTransitionTime":"2024-02-23T15:54:13Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":1,"verifyimages":0}}}
      kyverno.io/kubernetes-version: "1.23"
      kyverno.io/kyverno-version: 1.7.0
      policies.kyverno.io/category: Sample
      policies.kyverno.io/description: A ClusterRole with nodes/proxy resource access
        allows a user to perform anything the kubelet API allows. It also allows users
        to bypass the API server and talk directly to the kubelet potentially circumventing
        audits and admission controllers. See https://blog.aquasec.com/privilege-escalation-kubernetes-rbac
        for more info. This policy prevents the creation of a ClusterRole if it contains
        the nodes/proxy resource.
      policies.kyverno.io/minversion: 1.6.0
      policies.kyverno.io/severity: medium
      policies.kyverno.io/subject: ClusterRole, RBAC
      policies.kyverno.io/title: Restrict ClusterRole with Nodes Proxy
    creationTimestamp: "2024-04-16T06:35:34Z"
    generation: 1
    name: restrict-clusterrole-nodesproxy
    resourceVersion: "29226"
    uid: 95d605ab-abe8-4446-be32-3453515845d1
  spec:
    background: false
    rules:
    - exclude:
        any:
        - resources:
            kinds:
            - ClusterRole
            selector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - gloo
                - grafana
                - akuity-admin
                - rbac-manager
                - datadog
                - keda
        - resources:
            kinds:
            - ClusterRole
            selector:
              matchExpressions:
              - key: exclude
                operator: In
                values:
                - nodesproxy
      match:
        any:
        - resources:
            kinds:
            - ClusterRole
      name: clusterrole-nodesproxy
      validate:
        deny:
          conditions:
            any:
            - key: nodes/proxy
              operator: AnyIn
              value: '{{ request.object.rules[].resources[] }}'
        message: A ClusterRole containing the nodes/proxy resource is not allowed.
    validationFailureAction: audit
  status:
    autogen: {}
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:35Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-escalation-verbs-roles
      controls.cfasec.com/id: rbac5
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-escalation-verbs-roles","controls.cfasec.com/id":"rbac5","kyverno.io/kubernetes-version":"1.23","kyverno.io/kyverno-version":"1.6.2","policies.kyverno.io/category":"Security","policies.kyverno.io/description":"The verbs `impersonate`, `bind`, and `escalate` may all potentially lead to privilege escalation and should be tightly controlled. This policy prevents use of these verbs in Role or ClusterRole resources. In order to fully implement this control, it is recommended to pair this policy with another which also prevents use of the wildcard ('*') in the verbs list.","policies.kyverno.io/minversion":"1.6.0","policies.kyverno.io/severity":"medium","policies.kyverno.io/subject":"Role, ClusterRole, RBAC","policies.kyverno.io/title":"Restrict Escalation Verbs in Roles"},"creationTimestamp":"2024-02-23T16:11:27Z","generation":1,"name":"restrict-escalation-verbs-roles","resourceVersion":"727837317","uid":"4b405e00-2d1e-494a-825f-f1575aaf9a77"},"spec":{"background":true,"rules":[{"exclude":{"any":[{"resources":{"kinds":["ClusterRole"],"names":["admin","akuity-admin","cluster-admin","rbac-manager","keda-operator-external-metrics-reader","keda-operator","fw-prometheus-kube-prometh-operator"]}},{"resources":{"kinds":["ClusterRole","Role"],"selector":{"matchExpressions":[{"key":"app","operator":"In","values":["gloo","gloo-fed"]}]}}}]},"match":{"any":[{"resources":{"kinds":["Role","ClusterRole"]}}]},"name":"escalate","validate":{"deny":{"conditions":{"any":[{"key":["escalate","bind","impersonate"],"operator":"AnyIn","value":"{{ request.object.rules[].verbs[] }}"}]}},"message":"Use of verbs `escalate`, `bind`, and `impersonate` are forbidden."}}],"validationFailureAction":"audit"},"status":{"autogen":{},"conditions":[{"lastTransitionTime":"2024-02-23T16:11:32Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":1,"verifyimages":0}}}
      kyverno.io/kubernetes-version: "1.23"
      kyverno.io/kyverno-version: 1.6.2
      policies.kyverno.io/category: Security
      policies.kyverno.io/description: The verbs `impersonate`, `bind`, and `escalate`
        may all potentially lead to privilege escalation and should be tightly controlled.
        This policy prevents use of these verbs in Role or ClusterRole resources.
        In order to fully implement this control, it is recommended to pair this policy
        with another which also prevents use of the wildcard ('*') in the verbs list.
      policies.kyverno.io/minversion: 1.6.0
      policies.kyverno.io/severity: medium
      policies.kyverno.io/subject: Role, ClusterRole, RBAC
      policies.kyverno.io/title: Restrict Escalation Verbs in Roles
    creationTimestamp: "2024-04-16T06:35:35Z"
    generation: 1
    name: restrict-escalation-verbs-roles
    resourceVersion: "29262"
    uid: 439758ee-41b3-4af8-8ca1-7c9bf52aa02b
  spec:
    background: true
    rules:
    - exclude:
        any:
        - resources:
            kinds:
            - ClusterRole
            names:
            - admin
            - akuity-admin
            - cluster-admin
            - rbac-manager
            - keda-operator-external-metrics-reader
            - keda-operator
            - fw-prometheus-kube-prometh-operator
        - resources:
            kinds:
            - ClusterRole
            - Role
            selector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - gloo
                - gloo-fed
      match:
        any:
        - resources:
            kinds:
            - Role
            - ClusterRole
      name: escalate
      validate:
        deny:
          conditions:
            any:
            - key:
              - escalate
              - bind
              - impersonate
              operator: AnyIn
              value: '{{ request.object.rules[].verbs[] }}'
        message: Use of verbs `escalate`, `bind`, and `impersonate` are forbidden.
    validationFailureAction: audit
  status:
    autogen: {}
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:35Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-external-dns
      controls.cfasec.com/id: nw5
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-external-dns","controls.cfasec.com/id":"nw5","pod-policies.kyverno.io/autogen-controllers":"None","policies.kyverno.io/category":"Kuberneering","policies.kyverno.io/description":"External DNS is not approved for usage","policies.kyverno.io/minversion":"1.6.0","policies.kyverno.io/subject":"Pod, Annotation","policies.kyverno.io/title":"Restrict External DNS"},"creationTimestamp":"2024-02-23T16:11:51Z","generation":1,"name":"restrict-external-dns","resourceVersion":"727837827","uid":"4b29b4f4-7565-4c2d-8093-bdd7dbeee03e"},"spec":{"background":true,"rules":[{"exclude":{"any":[{"resources":{"kinds":["Deployment","CronJob","Job","StatefulSet","DaemonSet","Service","Ingress","Pod"],"namespaces":["gloo-system","gloo-blue","gloo-green"]}}]},"match":{"any":[{"resources":{"kinds":["Deployment","CronJob","Job","StatefulSet","DaemonSet","Service","Ingress","Pod"]}}]},"name":"block-external-dns","validate":{"message":"Cannot use external dns annotation.","pattern":{"metadata":{"=(annotations)":{"X(external-dns.alpha.kubernetes.io/*)":"*?"}}}}}],"validationFailureAction":"audit"},"status":{"autogen":{},"conditions":[{"lastTransitionTime":"2024-02-23T16:11:54Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":1,"verifyimages":0}}}
      pod-policies.kyverno.io/autogen-controllers: None
      policies.kyverno.io/category: Kuberneering
      policies.kyverno.io/description: External DNS is not approved for usage
      policies.kyverno.io/minversion: 1.6.0
      policies.kyverno.io/subject: Pod, Annotation
      policies.kyverno.io/title: Restrict External DNS
    creationTimestamp: "2024-04-16T06:35:35Z"
    generation: 1
    name: restrict-external-dns
    resourceVersion: "29306"
    uid: 0d709019-bf9a-475c-874d-c9efc513fb17
  spec:
    background: true
    rules:
    - exclude:
        any:
        - resources:
            kinds:
            - Deployment
            - CronJob
            - Job
            - StatefulSet
            - DaemonSet
            - Service
            - Ingress
            - Pod
            namespaces:
            - gloo-system
            - gloo-blue
            - gloo-green
      match:
        any:
        - resources:
            kinds:
            - Deployment
            - CronJob
            - Job
            - StatefulSet
            - DaemonSet
            - Service
            - Ingress
            - Pod
      name: block-external-dns
      validate:
        message: Cannot use external dns annotation.
        pattern:
          metadata:
            =(annotations):
              X(external-dns.alpha.kubernetes.io/*): '*?'
    validationFailureAction: audit
  status:
    autogen: {}
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:35Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-external-ips
      controls.cfasec.com/id: cc2
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-external-ips","controls.cfasec.com/id":"cc2","policies.kyverno.io/category":"Best Practices","policies.kyverno.io/description":"Service externalIPs can be used for a MITM attack (CVE-2020-8554). Restrict externalIPs or limit to a known set of addresses. See: https://github.com/kyverno/kyverno/issues/1367. This policy validates that the `externalIPs` field is not set on a Service.","policies.kyverno.io/severity":"medium","policies.kyverno.io/subject":"Service","policies.kyverno.io/title":"Restrict External IPs"},"creationTimestamp":"2024-02-23T15:58:33Z","generation":1,"name":"restrict-external-ips","resourceVersion":"727818420","uid":"ec49d742-3c4c-4f0c-942b-bac96932699b"},"spec":{"background":true,"rules":[{"match":{"resources":{"kinds":["Service"]}},"name":"check-ips","validate":{"message":"externalIPs are not allowed.","pattern":{"spec":{"X(externalIPs)":"null"}}}}],"validationFailureAction":"audit"},"status":{"autogen":{},"conditions":[{"lastTransitionTime":"2024-02-23T15:59:30Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":1,"verifyimages":0}}}
      policies.kyverno.io/category: Best Practices
      policies.kyverno.io/description: 'Service externalIPs can be used for a MITM
        attack (CVE-2020-8554). Restrict externalIPs or limit to a known set of addresses.
        See: https://github.com/kyverno/kyverno/issues/1367. This policy validates
        that the `externalIPs` field is not set on a Service.'
      policies.kyverno.io/severity: medium
      policies.kyverno.io/subject: Service
      policies.kyverno.io/title: Restrict External IPs
    creationTimestamp: "2024-04-16T06:35:35Z"
    generation: 1
    name: restrict-external-ips
    resourceVersion: "29331"
    uid: a177f869-f2cb-47cf-bdea-18279c952066
  spec:
    background: true
    rules:
    - match:
        resources:
          kinds:
          - Service
      name: check-ips
      validate:
        message: externalIPs are not allowed.
        pattern:
          spec:
            X(externalIPs): "null"
    validationFailureAction: audit
  status:
    autogen: {}
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:36Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-image-registries
      controls.cfasec.com/id: cc3
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-image-registries","controls.cfasec.com/id":"cc3","policies.kyverno.io/category":"Best Practices, EKS Best Practices","policies.kyverno.io/description":"Images from unknown, public registries can be of dubious quality and may not be scanned and secured, representing a high degree of risk. Requiring use of known, approved registries helps reduce threat exposure by ensuring image pulls only come from them. This policy validates that container images only originate from the registry `eu.foo.io` or `bar.io`. Use of this policy requires customization to define your allowable registries.","policies.kyverno.io/minversion":"1.6.0","policies.kyverno.io/severity":"medium","policies.kyverno.io/subject":"Pod","policies.kyverno.io/title":"Restrict Image Registries"},"creationTimestamp":"2024-02-23T16:11:29Z","generation":1,"name":"restrict-image-registries","resourceVersion":"727837299","uid":"71e63de4-2732-4fdc-9175-601755e100a5"},"spec":{"background":true,"rules":[{"exclude":{"any":[{"resources":{"kinds":["Pod"],"namespaces":["rbac-manager","akuity-admin","obsp"]}}]},"match":{"any":[{"resources":{"kinds":["Pod"]}}]},"name":"validate-registries","validate":{"message":"Unknown image registry.","pattern":{"spec":{"containers":[{"image":"cfa-docker.jfrog.io/* | grafana/* | docker.io/library/redis* | gcr.io/kubebuilder/kube-rbac-proxy* | ghcr.io/external-secrets/external-secret* | nginxinc/nginx-unprivileged* | quay.io/solo-io* | registry.k8s.io/kube-state-metrics/kube-state-metrics* | quay.io/tigera/* | quay.io/calico/* | docker.io/library/calico/* | docker.io/library/busybox* | hashicorp/* | signalsciences/sigsci-agent* | quay.io/akuityio/* | quay.io/argoproj/* | quay.io/akuity/* | quay.io/jetstack/* | docker.io/library/bitnami/* | public.ecr.aws/eks-distro/kubernetes-csi/* | public.ecr.aws/ebs-csi-driver/* | amazon/aws-efs-csi-driver* | quay.io/fairwinds/* | us-docker.pkg.dev/fairwinds-ops/* | ghcr.io/kedacore/* | registry.k8s.io/metrics-server/* | quay.io/reactiveops/* | k8s.gcr.io/ingress-nginx/* |  quay.io/prometheus/* | quay.io/prometheus-operator/* | registry.k8s.io/autoscaling/* | public.ecr.aws/datadog/* | public.ecr.aws/karpenter/* | public.ecr.aws/eks/aws-load-balancer-controller* | registry.k8s.io/external-dns/* | debian:rc-buggy-20221219 | jess/netcat@sha256:569448ec81218010177e6605b5bbc3a9db049fb02cb24ccba585a2816084d870 | timberio/vector* | otel/opentelemetry-collector-contrib*"}]}}}}],"validationFailureAction":"audit"},"status":{"autogen":{"rules":[{"exclude":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"],"namespaces":["rbac-manager","akuity-admin","obsp"]}}],"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"]}}],"resources":{}},"mutate":{},"name":"autogen-validate-registries","validate":{"message":"Unknown image registry.","pattern":{"spec":{"template":{"spec":{"containers":[{"image":"cfa-docker.jfrog.io/* | grafana/* | docker.io/library/redis* | gcr.io/kubebuilder/kube-rbac-proxy* | ghcr.io/external-secrets/external-secret* | nginxinc/nginx-unprivileged* | quay.io/solo-io* | registry.k8s.io/kube-state-metrics/kube-state-metrics* | quay.io/tigera/* | quay.io/calico/* | docker.io/library/calico/* | docker.io/library/busybox* | hashicorp/* | signalsciences/sigsci-agent* | quay.io/akuityio/* | quay.io/argoproj/* | quay.io/akuity/* | quay.io/jetstack/* | docker.io/library/bitnami/* | public.ecr.aws/eks-distro/kubernetes-csi/* | public.ecr.aws/ebs-csi-driver/* | amazon/aws-efs-csi-driver* | quay.io/fairwinds/* | us-docker.pkg.dev/fairwinds-ops/* | ghcr.io/kedacore/* | registry.k8s.io/metrics-server/* | quay.io/reactiveops/* | k8s.gcr.io/ingress-nginx/* |  quay.io/prometheus/* | quay.io/prometheus-operator/* | registry.k8s.io/autoscaling/* | public.ecr.aws/datadog/* | public.ecr.aws/karpenter/* | public.ecr.aws/eks/aws-load-balancer-controller* | registry.k8s.io/external-dns/* | debian:rc-buggy-20221219 | jess/netcat@sha256:569448ec81218010177e6605b5bbc3a9db049fb02cb24ccba585a2816084d870 | timberio/vector* | otel/opentelemetry-collector-contrib*"}]}}}}}},{"exclude":{"any":[{"resources":{"kinds":["CronJob"],"namespaces":["rbac-manager","akuity-admin","obsp"]}}],"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["CronJob"]}}],"resources":{}},"mutate":{},"name":"autogen-cronjob-validate-registries","validate":{"message":"Unknown image registry.","pattern":{"spec":{"jobTemplate":{"spec":{"template":{"spec":{"containers":[{"image":"cfa-docker.jfrog.io/* | grafana/* | docker.io/library/redis* | gcr.io/kubebuilder/kube-rbac-proxy* | ghcr.io/external-secrets/external-secret* | nginxinc/nginx-unprivileged* | quay.io/solo-io* | registry.k8s.io/kube-state-metrics/kube-state-metrics* | quay.io/tigera/* | quay.io/calico/* | docker.io/library/calico/* | docker.io/library/busybox* | hashicorp/* | signalsciences/sigsci-agent* | quay.io/akuityio/* | quay.io/argoproj/* | quay.io/akuity/* | quay.io/jetstack/* | docker.io/library/bitnami/* | public.ecr.aws/eks-distro/kubernetes-csi/* | public.ecr.aws/ebs-csi-driver/* | amazon/aws-efs-csi-driver* | quay.io/fairwinds/* | us-docker.pkg.dev/fairwinds-ops/* | ghcr.io/kedacore/* | registry.k8s.io/metrics-server/* | quay.io/reactiveops/* | k8s.gcr.io/ingress-nginx/* |  quay.io/prometheus/* | quay.io/prometheus-operator/* | registry.k8s.io/autoscaling/* | public.ecr.aws/datadog/* | public.ecr.aws/karpenter/* | public.ecr.aws/eks/aws-load-balancer-controller* | registry.k8s.io/external-dns/* | debian:rc-buggy-20221219 | jess/netcat@sha256:569448ec81218010177e6605b5bbc3a9db049fb02cb24ccba585a2816084d870 | timberio/vector* | otel/opentelemetry-collector-contrib*"}]}}}}}}}}]},"conditions":[{"lastTransitionTime":"2024-02-23T16:11:32Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":1,"verifyimages":0}}}
      policies.kyverno.io/category: Best Practices, EKS Best Practices
      policies.kyverno.io/description: Images from unknown, public registries can
        be of dubious quality and may not be scanned and secured, representing a high
        degree of risk. Requiring use of known, approved registries helps reduce threat
        exposure by ensuring image pulls only come from them. This policy validates
        that container images only originate from the registry `eu.foo.io` or `bar.io`.
        Use of this policy requires customization to define your allowable registries.
      policies.kyverno.io/minversion: 1.6.0
      policies.kyverno.io/severity: medium
      policies.kyverno.io/subject: Pod
      policies.kyverno.io/title: Restrict Image Registries
    creationTimestamp: "2024-04-16T06:35:36Z"
    generation: 1
    name: restrict-image-registries
    resourceVersion: "29420"
    uid: 897a761e-7da7-4ea5-9ddf-21c8b0dfc08b
  spec:
    background: true
    rules:
    - exclude:
        any:
        - resources:
            kinds:
            - Pod
            namespaces:
            - rbac-manager
            - akuity-admin
            - obsp
      match:
        any:
        - resources:
            kinds:
            - Pod
      name: validate-registries
      validate:
        message: Unknown image registry.
        pattern:
          spec:
            containers:
            - image: cfa-docker.jfrog.io/* | grafana/* | docker.io/library/redis*
                | gcr.io/kubebuilder/kube-rbac-proxy* | ghcr.io/external-secrets/external-secret*
                | nginxinc/nginx-unprivileged* | quay.io/solo-io* | registry.k8s.io/kube-state-metrics/kube-state-metrics*
                | quay.io/tigera/* | quay.io/calico/* | docker.io/library/calico/*
                | docker.io/library/busybox* | hashicorp/* | signalsciences/sigsci-agent*
                | quay.io/akuityio/* | quay.io/argoproj/* | quay.io/akuity/* | quay.io/jetstack/*
                | docker.io/library/bitnami/* | public.ecr.aws/eks-distro/kubernetes-csi/*
                | public.ecr.aws/ebs-csi-driver/* | amazon/aws-efs-csi-driver* | quay.io/fairwinds/*
                | us-docker.pkg.dev/fairwinds-ops/* | ghcr.io/kedacore/* | registry.k8s.io/metrics-server/*
                | quay.io/reactiveops/* | k8s.gcr.io/ingress-nginx/* |  quay.io/prometheus/*
                | quay.io/prometheus-operator/* | registry.k8s.io/autoscaling/* |
                public.ecr.aws/datadog/* | public.ecr.aws/karpenter/* | public.ecr.aws/eks/aws-load-balancer-controller*
                | registry.k8s.io/external-dns/* | debian:rc-buggy-20221219 | jess/netcat@sha256:569448ec81218010177e6605b5bbc3a9db049fb02cb24ccba585a2816084d870
                | timberio/vector* | otel/opentelemetry-collector-contrib*
    validationFailureAction: audit
  status:
    autogen:
      rules:
      - exclude:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
              namespaces:
              - rbac-manager
              - akuity-admin
              - obsp
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
          resources: {}
        mutate: {}
        name: autogen-validate-registries
        validate:
          message: Unknown image registry.
          pattern:
            spec:
              template:
                spec:
                  containers:
                  - image: cfa-docker.jfrog.io/* | grafana/* | docker.io/library/redis*
                      | gcr.io/kubebuilder/kube-rbac-proxy* | ghcr.io/external-secrets/external-secret*
                      | nginxinc/nginx-unprivileged* | quay.io/solo-io* | registry.k8s.io/kube-state-metrics/kube-state-metrics*
                      | quay.io/tigera/* | quay.io/calico/* | docker.io/library/calico/*
                      | docker.io/library/busybox* | hashicorp/* | signalsciences/sigsci-agent*
                      | quay.io/akuityio/* | quay.io/argoproj/* | quay.io/akuity/*
                      | quay.io/jetstack/* | docker.io/library/bitnami/* | public.ecr.aws/eks-distro/kubernetes-csi/*
                      | public.ecr.aws/ebs-csi-driver/* | amazon/aws-efs-csi-driver*
                      | quay.io/fairwinds/* | us-docker.pkg.dev/fairwinds-ops/* |
                      ghcr.io/kedacore/* | registry.k8s.io/metrics-server/* | quay.io/reactiveops/*
                      | k8s.gcr.io/ingress-nginx/* |  quay.io/prometheus/* | quay.io/prometheus-operator/*
                      | registry.k8s.io/autoscaling/* | public.ecr.aws/datadog/* |
                      public.ecr.aws/karpenter/* | public.ecr.aws/eks/aws-load-balancer-controller*
                      | registry.k8s.io/external-dns/* | debian:rc-buggy-20221219
                      | jess/netcat@sha256:569448ec81218010177e6605b5bbc3a9db049fb02cb24ccba585a2816084d870
                      | timberio/vector* | otel/opentelemetry-collector-contrib*
      - exclude:
          any:
          - resources:
              kinds:
              - CronJob
              namespaces:
              - rbac-manager
              - akuity-admin
              - obsp
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - CronJob
          resources: {}
        mutate: {}
        name: autogen-cronjob-validate-registries
        validate:
          message: Unknown image registry.
          pattern:
            spec:
              jobTemplate:
                spec:
                  template:
                    spec:
                      containers:
                      - image: cfa-docker.jfrog.io/* | grafana/* | docker.io/library/redis*
                          | gcr.io/kubebuilder/kube-rbac-proxy* | ghcr.io/external-secrets/external-secret*
                          | nginxinc/nginx-unprivileged* | quay.io/solo-io* | registry.k8s.io/kube-state-metrics/kube-state-metrics*
                          | quay.io/tigera/* | quay.io/calico/* | docker.io/library/calico/*
                          | docker.io/library/busybox* | hashicorp/* | signalsciences/sigsci-agent*
                          | quay.io/akuityio/* | quay.io/argoproj/* | quay.io/akuity/*
                          | quay.io/jetstack/* | docker.io/library/bitnami/* | public.ecr.aws/eks-distro/kubernetes-csi/*
                          | public.ecr.aws/ebs-csi-driver/* | amazon/aws-efs-csi-driver*
                          | quay.io/fairwinds/* | us-docker.pkg.dev/fairwinds-ops/*
                          | ghcr.io/kedacore/* | registry.k8s.io/metrics-server/*
                          | quay.io/reactiveops/* | k8s.gcr.io/ingress-nginx/* |  quay.io/prometheus/*
                          | quay.io/prometheus-operator/* | registry.k8s.io/autoscaling/*
                          | public.ecr.aws/datadog/* | public.ecr.aws/karpenter/*
                          | public.ecr.aws/eks/aws-load-balancer-controller* | registry.k8s.io/external-dns/*
                          | debian:rc-buggy-20221219 | jess/netcat@sha256:569448ec81218010177e6605b5bbc3a9db049fb02cb24ccba585a2816084d870
                          | timberio/vector* | otel/opentelemetry-collector-contrib*
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:36Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-ingress-defaultbackend
      controls.cfasec.com/id: cc4
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-ingress-defaultbackend","controls.cfasec.com/id":"cc4","kyverno.io/kubernetes-version":"1.23","kyverno.io/kyverno-version":"1.6.2","policies.kyverno.io/category":"Best Practices","policies.kyverno.io/description":"An Ingress with no rules sends all traffic to a single default backend. The defaultBackend is conventionally a configuration option of the Ingress controller and is not specified in your Ingress resources. If none of the hosts or paths match the HTTP request in the Ingress objects, the traffic is routed to your default backend. In a multi-tenant environment, you want users to use explicit hosts, they should not be able to overwrite the global default backend service. This policy prohibits the use of the defaultBackend field.","policies.kyverno.io/minversion":"1.6.0","policies.kyverno.io/severity":"high","policies.kyverno.io/subject":"Ingress","policies.kyverno.io/title":"Restrict Ingress defaultBackend"},"creationTimestamp":"2024-02-23T15:54:14Z","generation":1,"name":"restrict-ingress-defaultbackend","resourceVersion":"727809666","uid":"a5f0fd84-d9c1-4ec5-8639-da5e89f7a77f"},"spec":{"background":true,"rules":[{"match":{"any":[{"resources":{"kinds":["Ingress"]}}]},"name":"restrict-ingress-defaultbackend","validate":{"message":"Setting the defaultBackend field is prohibited.","pattern":{"spec":{"X(defaultBackend)":"null"}}}}],"validationFailureAction":"audit"},"status":{"autogen":{},"conditions":[{"lastTransitionTime":"2024-02-23T15:54:19Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":1,"verifyimages":0}}}
      kyverno.io/kubernetes-version: "1.23"
      kyverno.io/kyverno-version: 1.6.2
      policies.kyverno.io/category: Best Practices
      policies.kyverno.io/description: An Ingress with no rules sends all traffic
        to a single default backend. The defaultBackend is conventionally a configuration
        option of the Ingress controller and is not specified in your Ingress resources.
        If none of the hosts or paths match the HTTP request in the Ingress objects,
        the traffic is routed to your default backend. In a multi-tenant environment,
        you want users to use explicit hosts, they should not be able to overwrite
        the global default backend service. This policy prohibits the use of the defaultBackend
        field.
      policies.kyverno.io/minversion: 1.6.0
      policies.kyverno.io/severity: high
      policies.kyverno.io/subject: Ingress
      policies.kyverno.io/title: Restrict Ingress defaultBackend
    creationTimestamp: "2024-04-16T06:35:36Z"
    generation: 1
    name: restrict-ingress-defaultbackend
    resourceVersion: "29447"
    uid: d8dc9c0e-0138-4c10-ac6c-97ad9224ab0c
  spec:
    background: true
    rules:
    - match:
        any:
        - resources:
            kinds:
            - Ingress
      name: restrict-ingress-defaultbackend
      validate:
        message: Setting the defaultBackend field is prohibited.
        pattern:
          spec:
            X(defaultBackend): "null"
    validationFailureAction: audit
  status:
    autogen: {}
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:37Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-ingress-wildcard
      controls.cfasec.com/id: na
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-ingress-wildcard","controls.cfasec.com/id":"na","kyverno.io/kubernetes-version":"1.23","kyverno.io/kyverno-version":"1.6.2","policies.kyverno.io/category":"Other","policies.kyverno.io/description":"Ingress hosts optionally accept a wildcard as an alternative to precise matching. In some cases, this may be too permissive as it would direct unintended traffic to the given Ingress resource. This policy enforces that any Ingress host does not contain a wildcard character.","policies.kyverno.io/minversion":"1.6.0","policies.kyverno.io/severity":"medium","policies.kyverno.io/subject":"Ingress","policies.kyverno.io/title":"Restrict Ingress Host with Wildcards"},"creationTimestamp":"2024-02-23T15:54:14Z","generation":1,"name":"restrict-ingress-wildcard","resourceVersion":"727809562","uid":"45b9dc5a-87d3-47e0-a315-7e6866f8e537"},"spec":{"background":true,"rules":[{"match":{"any":[{"resources":{"kinds":["Ingress"]}}]},"name":"block-ingress-wildcard","preconditions":{"all":[{"key":"{{ request.operation }}","operator":"AnyIn","value":["CREATE","UPDATE"]}]},"validate":{"foreach":[{"deny":{"conditions":{"any":[{"key":"{{ contains(element.host, '*') }}","operator":"Equals","value":true}]}},"list":"request.object.spec.rules"}],"message":"Wildcards are not permitted as hosts."}}],"validationFailureAction":"audit"},"status":{"autogen":{},"conditions":[{"lastTransitionTime":"2024-02-23T15:54:16Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":1,"verifyimages":0}}}
      kyverno.io/kubernetes-version: "1.23"
      kyverno.io/kyverno-version: 1.6.2
      policies.kyverno.io/category: Other
      policies.kyverno.io/description: Ingress hosts optionally accept a wildcard
        as an alternative to precise matching. In some cases, this may be too permissive
        as it would direct unintended traffic to the given Ingress resource. This
        policy enforces that any Ingress host does not contain a wildcard character.
      policies.kyverno.io/minversion: 1.6.0
      policies.kyverno.io/severity: medium
      policies.kyverno.io/subject: Ingress
      policies.kyverno.io/title: Restrict Ingress Host with Wildcards
    creationTimestamp: "2024-04-16T06:35:37Z"
    generation: 1
    name: restrict-ingress-wildcard
    resourceVersion: "29474"
    uid: d48b2657-cb8d-43f5-af6a-7901b1c48497
  spec:
    background: true
    rules:
    - match:
        any:
        - resources:
            kinds:
            - Ingress
      name: block-ingress-wildcard
      preconditions:
        all:
        - key: '{{ request.operation }}'
          operator: AnyIn
          value:
          - CREATE
          - UPDATE
      validate:
        foreach:
        - deny:
            conditions:
              any:
              - key: '{{ contains(element.host, ''*'') }}'
                operator: Equals
                value: true
          list: request.object.spec.rules
        message: Wildcards are not permitted as hosts.
    validationFailureAction: audit
  status:
    autogen: {}
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:37Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-node-label-creation
      controls.cfasec.com/id: node1
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-node-label-creation","controls.cfasec.com/id":"node1","policies.kyverno.io/category":"Sample","policies.kyverno.io/description":"Node labels are critical pieces of metadata upon which many other applications and logic may depend and should not be altered or removed by regular users. Many cloud providers also use Node labels to signal specific functions to applications. This policy prevents setting of a new label called `foo` on cluster Nodes. Use of this policy requires removal of the Node resource filter in the Kyverno ConfigMap ([Node,*,*]). Due to Kubernetes CVE-2021-25735, this policy requires, at minimum, one of the following versions of Kubernetes: v1.18.18, v1.19.10, v1.20.6, or v1.21.0.","policies.kyverno.io/subject":"Node, Label","policies.kyverno.io/title":"Restrict node label creation"},"creationTimestamp":"2024-02-23T15:54:14Z","generation":1,"name":"restrict-node-label-creation","resourceVersion":"727809653","uid":"8a05c5dd-769c-44da-b503-c11ac5547a6a"},"spec":{"background":false,"rules":[{"match":{"resources":{"kinds":["Node"]}},"name":"prevent-label-set","preconditions":{"all":[{"key":"{{request.operation}}","operator":"Equals","value":"UPDATE"},{"key":"{{request.object.metadata.labels.foo || '' }}","operator":"Equals","value":"?*"}]},"validate":{"deny":{},"message":"Setting the `foo` label on a Node is not allowed."}}],"validationFailureAction":"audit"},"status":{"autogen":{},"conditions":[{"lastTransitionTime":"2024-02-23T15:54:19Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":1,"verifyimages":0}}}
      policies.kyverno.io/category: Sample
      policies.kyverno.io/description: 'Node labels are critical pieces of metadata
        upon which many other applications and logic may depend and should not be
        altered or removed by regular users. Many cloud providers also use Node labels
        to signal specific functions to applications. This policy prevents setting
        of a new label called `foo` on cluster Nodes. Use of this policy requires
        removal of the Node resource filter in the Kyverno ConfigMap ([Node,*,*]).
        Due to Kubernetes CVE-2021-25735, this policy requires, at minimum, one of
        the following versions of Kubernetes: v1.18.18, v1.19.10, v1.20.6, or v1.21.0.'
      policies.kyverno.io/subject: Node, Label
      policies.kyverno.io/title: Restrict node label creation
    creationTimestamp: "2024-04-16T06:35:37Z"
    generation: 1
    name: restrict-node-label-creation
    resourceVersion: "29505"
    uid: 442d132b-1f4c-47be-938c-2411444b3ca4
  spec:
    background: false
    rules:
    - match:
        resources:
          kinds:
          - Node
      name: prevent-label-set
      preconditions:
        all:
        - key: '{{request.operation}}'
          operator: Equals
          value: UPDATE
        - key: '{{request.object.metadata.labels.foo || '''' }}'
          operator: Equals
          value: ?*
      validate:
        deny: {}
        message: Setting the `foo` label on a Node is not allowed.
    validationFailureAction: audit
  status:
    autogen: {}
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:37Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-nodeport
      controls.cfasec.com/id: node4
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-nodeport","controls.cfasec.com/id":"node4","policies.kyverno.io/category":"Best Practices","policies.kyverno.io/description":"A Kubernetes Service of type NodePort uses a host port to receive traffic from any source. A NetworkPolicy cannot be used to control traffic to host ports. Although NodePort Services can be useful, their use must be limited to Services with additional upstream security checks. This policy validates that any new Services do not use the `NodePort` type.","policies.kyverno.io/severity":"medium","policies.kyverno.io/subject":"Service","policies.kyverno.io/title":"Disallow NodePort"},"creationTimestamp":"2024-02-23T15:54:14Z","generation":1,"name":"restrict-nodeport","resourceVersion":"727809631","uid":"bcf19db3-7012-486c-9001-c33710f710e6"},"spec":{"background":true,"rules":[{"match":{"resources":{"kinds":["Service"]}},"name":"validate-nodeport","validate":{"message":"Services of type NodePort are not allowed.","pattern":{"spec":{"type":"!NodePort"}}}}],"validationFailureAction":"audit"},"status":{"autogen":{},"conditions":[{"lastTransitionTime":"2024-02-23T15:54:18Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":1,"verifyimages":0}}}
      policies.kyverno.io/category: Best Practices
      policies.kyverno.io/description: A Kubernetes Service of type NodePort uses
        a host port to receive traffic from any source. A NetworkPolicy cannot be
        used to control traffic to host ports. Although NodePort Services can be useful,
        their use must be limited to Services with additional upstream security checks.
        This policy validates that any new Services do not use the `NodePort` type.
      policies.kyverno.io/severity: medium
      policies.kyverno.io/subject: Service
      policies.kyverno.io/title: Disallow NodePort
    creationTimestamp: "2024-04-16T06:35:37Z"
    generation: 1
    name: restrict-nodeport
    resourceVersion: "29528"
    uid: e27134cd-4786-4ce2-9d69-05e1d95866ff
  spec:
    background: true
    rules:
    - match:
        resources:
          kinds:
          - Service
      name: validate-nodeport
      validate:
        message: Services of type NodePort are not allowed.
        pattern:
          spec:
            type: '!NodePort'
    validationFailureAction: audit
  status:
    autogen: {}
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:37Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-non-memory-medium-emptydir
      controls.cfasec.com/id: na
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-non-memory-medium-emptydir","controls.cfasec.com/id":"na","kyverno.io/kubernetes-version":"1.24","kyverno.io/kyverno-version":"1.7.3,1.8.0-rc2","policies.kyverno.io/category":"Other","policies.kyverno.io/description":"Limits usage of non-memory medium emptyDir volume type. This policy blocks any other medium type.","policies.kyverno.io/minversion":"1.6.0","policies.kyverno.io/subject":"Pod,Volume","policies.kyverno.io/title":"Restrict Non-Memory Medium emptyDir"},"creationTimestamp":"2024-02-23T15:54:14Z","generation":1,"name":"restrict-non-memory-medium-emptydir","resourceVersion":"727809636","uid":"6b063752-7c7f-45a0-a4fc-1d8f52d50101"},"spec":{"background":true,"rules":[{"match":{"any":[{"resources":{"kinds":["Pod"]}}]},"name":"restricted-medium","validate":{"foreach":[{"deny":{"conditions":{"all":[{"key":"{{element.emptyDir.medium || ''}}","operator":"AnyNotIn","value":["Memory",""]}]}},"list":"request.object.spec.volumes[]"}],"message":"Only memory mediums may be used for emptyDir volume types."}}],"validationFailureAction":"audit"},"status":{"autogen":{"rules":[{"exclude":{"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"]}}],"resources":{}},"mutate":{},"name":"autogen-restricted-medium","validate":{"foreach":[{"deny":{"conditions":{"all":[{"key":"{{element.emptyDir.medium || ''}}","operator":"AnyNotIn","value":["Memory",""]}]}},"list":"request.object.spec.template.spec.volumes[]"}],"message":"Only memory mediums may be used for emptyDir volume types."}},{"exclude":{"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["CronJob"]}}],"resources":{}},"mutate":{},"name":"autogen-cronjob-restricted-medium","validate":{"foreach":[{"deny":{"conditions":{"all":[{"key":"{{element.emptyDir.medium || ''}}","operator":"AnyNotIn","value":["Memory",""]}]}},"list":"request.object.spec.jobTemplate.spec.template.spec.volumes[]"}],"message":"Only memory mediums may be used for emptyDir volume types."}}]},"conditions":[{"lastTransitionTime":"2024-02-23T15:54:18Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":1,"verifyimages":0}}}
      kyverno.io/kubernetes-version: "1.24"
      kyverno.io/kyverno-version: 1.7.3,1.8.0-rc2
      policies.kyverno.io/category: Other
      policies.kyverno.io/description: Limits usage of non-memory medium emptyDir
        volume type. This policy blocks any other medium type.
      policies.kyverno.io/minversion: 1.6.0
      policies.kyverno.io/subject: Pod,Volume
      policies.kyverno.io/title: Restrict Non-Memory Medium emptyDir
    creationTimestamp: "2024-04-16T06:35:38Z"
    generation: 1
    name: restrict-non-memory-medium-emptydir
    resourceVersion: "29586"
    uid: cbf05cec-7164-43f1-95ee-28fb5f7de6eb
  spec:
    background: true
    rules:
    - match:
        any:
        - resources:
            kinds:
            - Pod
      name: restricted-medium
      validate:
        foreach:
        - deny:
            conditions:
              all:
              - key: '{{element.emptyDir.medium || ''''}}'
                operator: AnyNotIn
                value:
                - Memory
                - ""
          list: request.object.spec.volumes[]
        message: Only memory mediums may be used for emptyDir volume types.
    validationFailureAction: audit
  status:
    autogen:
      rules:
      - exclude:
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
          resources: {}
        mutate: {}
        name: autogen-restricted-medium
        validate:
          foreach:
          - deny:
              conditions:
                all:
                - key: '{{element.emptyDir.medium || ''''}}'
                  operator: AnyNotIn
                  value:
                  - Memory
                  - ""
            list: request.object.spec.template.spec.volumes[]
          message: Only memory mediums may be used for emptyDir volume types.
      - exclude:
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - CronJob
          resources: {}
        mutate: {}
        name: autogen-cronjob-restricted-medium
        validate:
          foreach:
          - deny:
              conditions:
                all:
                - key: '{{element.emptyDir.medium || ''''}}'
                  operator: AnyNotIn
                  value:
                  - Memory
                  - ""
            list: request.object.spec.jobTemplate.spec.template.spec.volumes[]
          message: Only memory mediums may be used for emptyDir volume types.
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:38Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-persistent-volumes
      controls.cfasec.com/id: hp2
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-persistent-volumes","controls.cfasec.com/id":"hp2","policies.kyverno.io/category":"Sample","policies.kyverno.io/description":"Persistent volumes are not allowed","policies.kyverno.io/severity":"medium","policies.kyverno.io/subject":"PersistentVolume","policies.kyverno.io/title":"Restrict persistent volumes"},"creationTimestamp":"2024-02-23T16:11:29Z","generation":1,"name":"restrict-persistent-volumes","resourceVersion":"727837345","uid":"ec9dcf62-7b19-412e-a134-2c0e2b546207"},"spec":{"background":true,"rules":[{"exclude":{"any":[{"resources":{"names":["spine-as2-server-efs-pv","tester-app-efs-pv","pvc-33184360-4211-4999-9c63-210bc42ed6cd","grafana-pv"]}}]},"match":{"any":[{"resources":{"kinds":["PersistentVolume"]}}]},"name":"restrictPersistentVolumes","validate":{"message":"PersistentVolumes that are not class 'efs-crossaccount' are not allowed.","pattern":{"spec":{"storageClassName":"efs-crossaccount"}}}}],"validationFailureAction":"Audit"},"status":{"autogen":{},"conditions":[{"lastTransitionTime":"2024-02-23T16:11:32Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":1,"verifyimages":0}}}
      policies.kyverno.io/category: Sample
      policies.kyverno.io/description: Persistent volumes are not allowed
      policies.kyverno.io/severity: medium
      policies.kyverno.io/subject: PersistentVolume
      policies.kyverno.io/title: Restrict persistent volumes
    creationTimestamp: "2024-04-16T06:35:38Z"
    generation: 1
    name: restrict-persistent-volumes
    resourceVersion: "29621"
    uid: 3fd3ee9f-7656-4b07-a179-e98613caada9
  spec:
    background: true
    rules:
    - exclude:
        any:
        - resources:
            names:
            - spine-as2-server-efs-pv
            - tester-app-efs-pv
            - pvc-33184360-4211-4999-9c63-210bc42ed6cd
            - grafana-pv
      match:
        any:
        - resources:
            kinds:
            - PersistentVolume
      name: restrictPersistentVolumes
      validate:
        message: PersistentVolumes that are not class 'efs-crossaccount' are not allowed.
        pattern:
          spec:
            storageClassName: efs-crossaccount
    validationFailureAction: Audit
  status:
    autogen: {}
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:38Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-seccomp
      controls.cfasec.com/id: na
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-seccomp","controls.cfasec.com/id":"na","kyverno.io/kubernetes-version":"1.22-1.23","kyverno.io/kyverno-version":"1.6.0","policies.kyverno.io/category":"Pod Security Standards (Baseline)","policies.kyverno.io/description":"The seccomp profile must not be explicitly set to Unconfined. This policy,  requiring Kubernetes v1.19 or later, ensures that seccomp is unset or  set to `RuntimeDefault` or `Localhost`.","policies.kyverno.io/severity":"medium","policies.kyverno.io/subject":"Pod","policies.kyverno.io/title":"Restrict Seccomp"},"creationTimestamp":"2024-02-23T15:54:16Z","generation":1,"name":"restrict-seccomp","resourceVersion":"727810048","uid":"30e8d452-d8b3-4002-9895-6b0172041487"},"spec":{"background":true,"rules":[{"match":{"any":[{"resources":{"kinds":["Pod"]}}]},"name":"check-seccomp","validate":{"message":"Use of custom Seccomp profiles is disallowed. The fields spec.securityContext.seccompProfile.type, spec.containers[*].securityContext.seccompProfile.type, spec.initContainers[*].securityContext.seccompProfile.type, and spec.ephemeralContainers[*].securityContext.seccompProfile.type must be unset or set to `RuntimeDefault` or `Localhost`.","pattern":{"spec":{"=(ephemeralContainers)":[{"=(securityContext)":{"=(seccompProfile)":{"=(type)":"RuntimeDefault | Localhost"}}}],"=(initContainers)":[{"=(securityContext)":{"=(seccompProfile)":{"=(type)":"RuntimeDefault | Localhost"}}}],"=(securityContext)":{"=(seccompProfile)":{"=(type)":"RuntimeDefault | Localhost"}},"containers":[{"=(securityContext)":{"=(seccompProfile)":{"=(type)":"RuntimeDefault | Localhost"}}}]}}}}],"validationFailureAction":"audit"},"status":{"autogen":{"rules":[{"exclude":{"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"]}}],"resources":{}},"mutate":{},"name":"autogen-check-seccomp","validate":{"message":"Use of custom Seccomp profiles is disallowed. The fields spec.securityContext.seccompProfile.type, spec.containers[*].securityContext.seccompProfile.type, spec.initContainers[*].securityContext.seccompProfile.type, and spec.ephemeralContainers[*].securityContext.seccompProfile.type must be unset or set to `RuntimeDefault` or `Localhost`.","pattern":{"spec":{"template":{"spec":{"=(ephemeralContainers)":[{"=(securityContext)":{"=(seccompProfile)":{"=(type)":"RuntimeDefault | Localhost"}}}],"=(initContainers)":[{"=(securityContext)":{"=(seccompProfile)":{"=(type)":"RuntimeDefault | Localhost"}}}],"=(securityContext)":{"=(seccompProfile)":{"=(type)":"RuntimeDefault | Localhost"}},"containers":[{"=(securityContext)":{"=(seccompProfile)":{"=(type)":"RuntimeDefault | Localhost"}}}]}}}}}},{"exclude":{"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["CronJob"]}}],"resources":{}},"mutate":{},"name":"autogen-cronjob-check-seccomp","validate":{"message":"Use of custom Seccomp profiles is disallowed. The fields spec.securityContext.seccompProfile.type, spec.containers[*].securityContext.seccompProfile.type, spec.initContainers[*].securityContext.seccompProfile.type, and spec.ephemeralContainers[*].securityContext.seccompProfile.type must be unset or set to `RuntimeDefault` or `Localhost`.","pattern":{"spec":{"jobTemplate":{"spec":{"template":{"spec":{"=(ephemeralContainers)":[{"=(securityContext)":{"=(seccompProfile)":{"=(type)":"RuntimeDefault | Localhost"}}}],"=(initContainers)":[{"=(securityContext)":{"=(seccompProfile)":{"=(type)":"RuntimeDefault | Localhost"}}}],"=(securityContext)":{"=(seccompProfile)":{"=(type)":"RuntimeDefault | Localhost"}},"containers":[{"=(securityContext)":{"=(seccompProfile)":{"=(type)":"RuntimeDefault | Localhost"}}}]}}}}}}}}]},"conditions":[{"lastTransitionTime":"2024-02-23T15:54:36Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":1,"verifyimages":0}}}
      kyverno.io/kubernetes-version: 1.22-1.23
      kyverno.io/kyverno-version: 1.6.0
      policies.kyverno.io/category: Pod Security Standards (Baseline)
      policies.kyverno.io/description: The seccomp profile must not be explicitly
        set to Unconfined. This policy,  requiring Kubernetes v1.19 or later, ensures
        that seccomp is unset or  set to `RuntimeDefault` or `Localhost`.
      policies.kyverno.io/severity: medium
      policies.kyverno.io/subject: Pod
      policies.kyverno.io/title: Restrict Seccomp
    creationTimestamp: "2024-04-16T06:35:38Z"
    generation: 1
    name: restrict-seccomp
    resourceVersion: "29654"
    uid: ec5c86dd-8dd5-48cc-a4d3-2a81ecb6cd1d
  spec:
    background: true
    rules:
    - match:
        any:
        - resources:
            kinds:
            - Pod
      name: check-seccomp
      validate:
        message: Use of custom Seccomp profiles is disallowed. The fields spec.securityContext.seccompProfile.type,
          spec.containers[*].securityContext.seccompProfile.type, spec.initContainers[*].securityContext.seccompProfile.type,
          and spec.ephemeralContainers[*].securityContext.seccompProfile.type must
          be unset or set to `RuntimeDefault` or `Localhost`.
        pattern:
          spec:
            =(ephemeralContainers):
            - =(securityContext):
                =(seccompProfile):
                  =(type): RuntimeDefault | Localhost
            =(initContainers):
            - =(securityContext):
                =(seccompProfile):
                  =(type): RuntimeDefault | Localhost
            =(securityContext):
              =(seccompProfile):
                =(type): RuntimeDefault | Localhost
            containers:
            - =(securityContext):
                =(seccompProfile):
                  =(type): RuntimeDefault | Localhost
    validationFailureAction: audit
  status:
    autogen:
      rules:
      - exclude:
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
          resources: {}
        mutate: {}
        name: autogen-check-seccomp
        validate:
          message: Use of custom Seccomp profiles is disallowed. The fields spec.securityContext.seccompProfile.type,
            spec.containers[*].securityContext.seccompProfile.type, spec.initContainers[*].securityContext.seccompProfile.type,
            and spec.ephemeralContainers[*].securityContext.seccompProfile.type must
            be unset or set to `RuntimeDefault` or `Localhost`.
          pattern:
            spec:
              template:
                spec:
                  =(ephemeralContainers):
                  - =(securityContext):
                      =(seccompProfile):
                        =(type): RuntimeDefault | Localhost
                  =(initContainers):
                  - =(securityContext):
                      =(seccompProfile):
                        =(type): RuntimeDefault | Localhost
                  =(securityContext):
                    =(seccompProfile):
                      =(type): RuntimeDefault | Localhost
                  containers:
                  - =(securityContext):
                      =(seccompProfile):
                        =(type): RuntimeDefault | Localhost
      - exclude:
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - CronJob
          resources: {}
        mutate: {}
        name: autogen-cronjob-check-seccomp
        validate:
          message: Use of custom Seccomp profiles is disallowed. The fields spec.securityContext.seccompProfile.type,
            spec.containers[*].securityContext.seccompProfile.type, spec.initContainers[*].securityContext.seccompProfile.type,
            and spec.ephemeralContainers[*].securityContext.seccompProfile.type must
            be unset or set to `RuntimeDefault` or `Localhost`.
          pattern:
            spec:
              jobTemplate:
                spec:
                  template:
                    spec:
                      =(ephemeralContainers):
                      - =(securityContext):
                          =(seccompProfile):
                            =(type): RuntimeDefault | Localhost
                      =(initContainers):
                      - =(securityContext):
                          =(seccompProfile):
                            =(type): RuntimeDefault | Localhost
                      =(securityContext):
                        =(seccompProfile):
                          =(type): RuntimeDefault | Localhost
                      containers:
                      - =(securityContext):
                          =(seccompProfile):
                            =(type): RuntimeDefault | Localhost
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:39Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-service-account
      controls.cfasec.com/id: sa3
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-service-account","controls.cfasec.com/id":"sa3","kyverno.io/kubernetes-version":"1.23","kyverno.io/kyverno-version":"1.6.2","policies.kyverno.io/category":"","policies.kyverno.io/description":"'This policy blocks usage of the default ServiceAccount.'","policies.kyverno.io/minversion":"1.3.5","policies.kyverno.io/severity":"medium","policies.kyverno.io/subject":"Pod,ServiceAccount","policies.kyverno.io/title":"Restrict Service Account"},"creationTimestamp":"2024-02-23T16:11:29Z","generation":1,"name":"restrict-service-account","resourceVersion":"727837328","uid":"c84afd56-aa62-4087-b4b2-96d378571699"},"spec":{"background":false,"rules":[{"match":{"resources":{"kinds":["Pod"]}},"name":"validate-service-account","validate":{"message":"Invalid service account. Use of the default ServiceAccount is not allowed.","pattern":{"spec":{"serviceAccountName":"!default"}}}}],"validationFailureAction":"audit"},"status":{"autogen":{"rules":[{"exclude":{"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"]}},"mutate":{},"name":"autogen-validate-service-account","validate":{"message":"Invalid service account. Use of the default ServiceAccount is not allowed.","pattern":{"spec":{"template":{"spec":{"serviceAccountName":"!default"}}}}}},{"exclude":{"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"resources":{"kinds":["CronJob"]}},"mutate":{},"name":"autogen-cronjob-validate-service-account","validate":{"message":"Invalid service account. Use of the default ServiceAccount is not allowed.","pattern":{"spec":{"jobTemplate":{"spec":{"template":{"spec":{"serviceAccountName":"!default"}}}}}}}}]},"conditions":[{"lastTransitionTime":"2024-02-23T16:11:32Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":1,"verifyimages":0}}}
      kyverno.io/kubernetes-version: "1.23"
      kyverno.io/kyverno-version: 1.6.2
      policies.kyverno.io/category: ""
      policies.kyverno.io/description: '''This policy blocks usage of the default
        ServiceAccount.'''
      policies.kyverno.io/minversion: 1.3.5
      policies.kyverno.io/severity: medium
      policies.kyverno.io/subject: Pod,ServiceAccount
      policies.kyverno.io/title: Restrict Service Account
    creationTimestamp: "2024-04-16T06:35:39Z"
    generation: 1
    name: restrict-service-account
    resourceVersion: "29671"
    uid: 8123f01d-671e-4455-8f02-facb61159916
  spec:
    background: false
    rules:
    - match:
        resources:
          kinds:
          - Pod
      name: validate-service-account
      validate:
        message: Invalid service account. Use of the default ServiceAccount is not
          allowed.
        pattern:
          spec:
            serviceAccountName: '!default'
    validationFailureAction: audit
  status:
    autogen:
      rules:
      - exclude:
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          resources:
            kinds:
            - DaemonSet
            - Deployment
            - Job
            - StatefulSet
            - ReplicaSet
            - ReplicationController
        mutate: {}
        name: autogen-validate-service-account
        validate:
          message: Invalid service account. Use of the default ServiceAccount is not
            allowed.
          pattern:
            spec:
              template:
                spec:
                  serviceAccountName: '!default'
      - exclude:
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          resources:
            kinds:
            - CronJob
        mutate: {}
        name: autogen-cronjob-validate-service-account
        validate:
          message: Invalid service account. Use of the default ServiceAccount is not
            allowed.
          pattern:
            spec:
              jobTemplate:
                spec:
                  template:
                    spec:
                      serviceAccountName: '!default'
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:39Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-sysctls
      controls.cfasec.com/id: hp12
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-sysctls","controls.cfasec.com/id":"hp12","kyverno.io/kubernetes-version":"1.22-1.23","kyverno.io/kyverno-version":"1.6.0","policies.kyverno.io/category":"Pod Security Standards (Baseline)","policies.kyverno.io/description":"Sysctls can disable security mechanisms or affect all containers on a host, and should be disallowed except for an allowed \"safe\" subset. A sysctl is considered safe if it is namespaced in the container or the Pod, and it is isolated from other Pods or processes on the same Node. This policy ensures that only those \"safe\" subsets can be specified in a Pod.","policies.kyverno.io/severity":"medium","policies.kyverno.io/subject":"Pod","policies.kyverno.io/title":"Restrict sysctls"},"creationTimestamp":"2024-02-23T16:11:29Z","generation":1,"name":"restrict-sysctls","resourceVersion":"727837342","uid":"5228e5aa-b38f-47ea-b4cb-e0f5e0ec5ab3"},"spec":{"background":true,"rules":[{"match":{"any":[{"resources":{"kinds":["Pod"]}}]},"name":"check-sysctls","validate":{"message":"Setting additional sysctls above the allowed type is disallowed. The field spec.securityContext.sysctls must be unset or not use any other names than kernel.shm_rmid_forced, net.ipv4.ip_local_port_range, net.ipv4.ip_unprivileged_port_start, net.ipv4.tcp_syncookies and net.ipv4.ping_group_range.","pattern":{"spec":{"=(securityContext)":{"=(sysctls)":[{"=(name)":"kernel.shm_rmid_forced | net.ipv4.ip_local_port_range | net.ipv4.ip_unprivileged_port_start | net.ipv4.tcp_syncookies | net.ipv4.ping_group_range"}]}}}}}],"validationFailureAction":"audit"},"status":{"autogen":{"rules":[{"exclude":{"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"]}}],"resources":{}},"mutate":{},"name":"autogen-check-sysctls","validate":{"message":"Setting additional sysctls above the allowed type is disallowed. The field spec.securityContext.sysctls must be unset or not use any other names than kernel.shm_rmid_forced, net.ipv4.ip_local_port_range, net.ipv4.ip_unprivileged_port_start, net.ipv4.tcp_syncookies and net.ipv4.ping_group_range.","pattern":{"spec":{"template":{"spec":{"=(securityContext)":{"=(sysctls)":[{"=(name)":"kernel.shm_rmid_forced | net.ipv4.ip_local_port_range | net.ipv4.ip_unprivileged_port_start | net.ipv4.tcp_syncookies | net.ipv4.ping_group_range"}]}}}}}}},{"exclude":{"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["CronJob"]}}],"resources":{}},"mutate":{},"name":"autogen-cronjob-check-sysctls","validate":{"message":"Setting additional sysctls above the allowed type is disallowed. The field spec.securityContext.sysctls must be unset or not use any other names than kernel.shm_rmid_forced, net.ipv4.ip_local_port_range, net.ipv4.ip_unprivileged_port_start, net.ipv4.tcp_syncookies and net.ipv4.ping_group_range.","pattern":{"spec":{"jobTemplate":{"spec":{"template":{"spec":{"=(securityContext)":{"=(sysctls)":[{"=(name)":"kernel.shm_rmid_forced | net.ipv4.ip_local_port_range | net.ipv4.ip_unprivileged_port_start | net.ipv4.tcp_syncookies | net.ipv4.ping_group_range"}]}}}}}}}}}]},"conditions":[{"lastTransitionTime":"2024-02-23T16:11:32Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":1,"verifyimages":0}}}
      kyverno.io/kubernetes-version: 1.22-1.23
      kyverno.io/kyverno-version: 1.6.0
      policies.kyverno.io/category: Pod Security Standards (Baseline)
      policies.kyverno.io/description: Sysctls can disable security mechanisms or
        affect all containers on a host, and should be disallowed except for an allowed
        "safe" subset. A sysctl is considered safe if it is namespaced in the container
        or the Pod, and it is isolated from other Pods or processes on the same Node.
        This policy ensures that only those "safe" subsets can be specified in a Pod.
      policies.kyverno.io/severity: medium
      policies.kyverno.io/subject: Pod
      policies.kyverno.io/title: Restrict sysctls
    creationTimestamp: "2024-04-16T06:35:39Z"
    generation: 1
    name: restrict-sysctls
    resourceVersion: "29698"
    uid: 4931bc9f-1069-4945-8321-33e04e86221e
  spec:
    background: true
    rules:
    - match:
        any:
        - resources:
            kinds:
            - Pod
      name: check-sysctls
      validate:
        message: Setting additional sysctls above the allowed type is disallowed.
          The field spec.securityContext.sysctls must be unset or not use any other
          names than kernel.shm_rmid_forced, net.ipv4.ip_local_port_range, net.ipv4.ip_unprivileged_port_start,
          net.ipv4.tcp_syncookies and net.ipv4.ping_group_range.
        pattern:
          spec:
            =(securityContext):
              =(sysctls):
              - =(name): kernel.shm_rmid_forced | net.ipv4.ip_local_port_range | net.ipv4.ip_unprivileged_port_start
                  | net.ipv4.tcp_syncookies | net.ipv4.ping_group_range
    validationFailureAction: audit
  status:
    autogen:
      rules:
      - exclude:
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
          resources: {}
        mutate: {}
        name: autogen-check-sysctls
        validate:
          message: Setting additional sysctls above the allowed type is disallowed.
            The field spec.securityContext.sysctls must be unset or not use any other
            names than kernel.shm_rmid_forced, net.ipv4.ip_local_port_range, net.ipv4.ip_unprivileged_port_start,
            net.ipv4.tcp_syncookies and net.ipv4.ping_group_range.
          pattern:
            spec:
              template:
                spec:
                  =(securityContext):
                    =(sysctls):
                    - =(name): kernel.shm_rmid_forced | net.ipv4.ip_local_port_range
                        | net.ipv4.ip_unprivileged_port_start | net.ipv4.tcp_syncookies
                        | net.ipv4.ping_group_range
      - exclude:
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - CronJob
          resources: {}
        mutate: {}
        name: autogen-cronjob-check-sysctls
        validate:
          message: Setting additional sysctls above the allowed type is disallowed.
            The field spec.securityContext.sysctls must be unset or not use any other
            names than kernel.shm_rmid_forced, net.ipv4.ip_local_port_range, net.ipv4.ip_unprivileged_port_start,
            net.ipv4.tcp_syncookies and net.ipv4.ping_group_range.
          pattern:
            spec:
              jobTemplate:
                spec:
                  template:
                    spec:
                      =(securityContext):
                        =(sysctls):
                        - =(name): kernel.shm_rmid_forced | net.ipv4.ip_local_port_range
                            | net.ipv4.ip_unprivileged_port_start | net.ipv4.tcp_syncookies
                            | net.ipv4.ping_group_range
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:39Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-volume-types
      controls.cfasec.com/id: stor1
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-volume-types","controls.cfasec.com/id":"stor1","kyverno.io/kubernetes-version":"1.22-1.23","kyverno.io/kyverno-version":"1.6.0","policies.kyverno.io/category":"Pod Security Standards (Restricted)","policies.kyverno.io/description":"In addition to restricting HostPath volumes, the restricted pod security profile limits usage of non-core volume types to those defined through PersistentVolumes. This policy blocks any other type of volume other than those in the allow list.","policies.kyverno.io/minversion":"1.6.0","policies.kyverno.io/severity":"medium","policies.kyverno.io/subject":"Pod,Volume","policies.kyverno.io/title":"Restrict Volume Types"},"creationTimestamp":"2024-02-23T16:11:51Z","generation":1,"name":"restrict-volume-types","resourceVersion":"727837834","uid":"4ac28d26-ec40-442d-b370-9a26ba96ed5f"},"spec":{"background":true,"rules":[{"exclude":{"any":[{"resources":{"kinds":["Pod"],"namespaces":["aws-ebs-csi-driver","aws-efs-csi-driver","calico-system","datadog","fw-prometheus","grafana-agent","monitoring","tigera-operator"]}}]},"match":{"any":[{"resources":{"kinds":["Pod"]}}]},"name":"restricted-volumes","validate":{"deny":{"conditions":{"all":[{"key":"{{ request.object.spec.volumes[].keys(@)[] || '' }}","operator":"AnyNotIn","value":["name","configMap","downwardAPI","emptyDir","ephemeral","persistentVolumeClaim","projected","secret",""]}]}},"message":"Only the following types of volumes may be used: configMap, csi, downwardAPI, emptyDir, ephemeral, persistentVolumeClaim, projected, and secret."}}],"validationFailureAction":"audit"},"status":{"autogen":{"rules":[{"exclude":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"],"namespaces":["aws-ebs-csi-driver","aws-efs-csi-driver","calico-system","datadog","fw-prometheus","grafana-agent","monitoring","tigera-operator"]}}],"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["DaemonSet","Deployment","Job","StatefulSet","ReplicaSet","ReplicationController"]}}],"resources":{}},"mutate":{},"name":"autogen-restricted-volumes","validate":{"deny":{"conditions":{"all":[{"key":"{{ request.object.spec.template.spec.volumes[].keys(@)[] || '' }}","operator":"AnyNotIn","value":["name","configMap","downwardAPI","emptyDir","ephemeral","persistentVolumeClaim","projected","secret",""]}]}},"message":"Only the following types of volumes may be used: configMap, csi, downwardAPI, emptyDir, ephemeral, persistentVolumeClaim, projected, and secret."}},{"exclude":{"any":[{"resources":{"kinds":["CronJob"],"namespaces":["aws-ebs-csi-driver","aws-efs-csi-driver","calico-system","datadog","fw-prometheus","grafana-agent","monitoring","tigera-operator"]}}],"resources":{}},"generate":{"clone":{},"cloneList":{}},"match":{"any":[{"resources":{"kinds":["CronJob"]}}],"resources":{}},"mutate":{},"name":"autogen-cronjob-restricted-volumes","validate":{"deny":{"conditions":{"all":[{"key":"{{ request.object.spec.jobTemplate.spec.template.spec.volumes[].keys(@)[] || '' }}","operator":"AnyNotIn","value":["name","configMap","downwardAPI","emptyDir","ephemeral","persistentVolumeClaim","projected","secret",""]}]}},"message":"Only the following types of volumes may be used: configMap, csi, downwardAPI, emptyDir, ephemeral, persistentVolumeClaim, projected, and secret."}}]},"conditions":[{"lastTransitionTime":"2024-02-23T16:11:54Z","message":"","reason":"Succeeded","status":"True","type":"Ready"}],"ready":true,"rulecount":{"generate":0,"mutate":0,"validate":1,"verifyimages":0}}}
      kyverno.io/kubernetes-version: 1.22-1.23
      kyverno.io/kyverno-version: 1.6.0
      policies.kyverno.io/category: Pod Security Standards (Restricted)
      policies.kyverno.io/description: In addition to restricting HostPath volumes,
        the restricted pod security profile limits usage of non-core volume types
        to those defined through PersistentVolumes. This policy blocks any other type
        of volume other than those in the allow list.
      policies.kyverno.io/minversion: 1.6.0
      policies.kyverno.io/severity: medium
      policies.kyverno.io/subject: Pod,Volume
      policies.kyverno.io/title: Restrict Volume Types
    creationTimestamp: "2024-04-16T06:35:39Z"
    generation: 1
    name: restrict-volume-types
    resourceVersion: "29751"
    uid: e39f9d8d-cfeb-4798-82f4-fe5f3196cf20
  spec:
    background: true
    rules:
    - exclude:
        any:
        - resources:
            kinds:
            - Pod
            namespaces:
            - aws-ebs-csi-driver
            - aws-efs-csi-driver
            - calico-system
            - datadog
            - fw-prometheus
            - grafana-agent
            - monitoring
            - tigera-operator
      match:
        any:
        - resources:
            kinds:
            - Pod
      name: restricted-volumes
      validate:
        deny:
          conditions:
            all:
            - key: '{{ request.object.spec.volumes[].keys(@)[] || '''' }}'
              operator: AnyNotIn
              value:
              - name
              - configMap
              - downwardAPI
              - emptyDir
              - ephemeral
              - persistentVolumeClaim
              - projected
              - secret
              - ""
        message: 'Only the following types of volumes may be used: configMap, csi,
          downwardAPI, emptyDir, ephemeral, persistentVolumeClaim, projected, and
          secret.'
    validationFailureAction: audit
  status:
    autogen:
      rules:
      - exclude:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
              namespaces:
              - aws-ebs-csi-driver
              - aws-efs-csi-driver
              - calico-system
              - datadog
              - fw-prometheus
              - grafana-agent
              - monitoring
              - tigera-operator
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - DaemonSet
              - Deployment
              - Job
              - StatefulSet
              - ReplicaSet
              - ReplicationController
          resources: {}
        mutate: {}
        name: autogen-restricted-volumes
        validate:
          deny:
            conditions:
              all:
              - key: '{{ request.object.spec.template.spec.volumes[].keys(@)[] ||
                  '''' }}'
                operator: AnyNotIn
                value:
                - name
                - configMap
                - downwardAPI
                - emptyDir
                - ephemeral
                - persistentVolumeClaim
                - projected
                - secret
                - ""
          message: 'Only the following types of volumes may be used: configMap, csi,
            downwardAPI, emptyDir, ephemeral, persistentVolumeClaim, projected, and
            secret.'
      - exclude:
          any:
          - resources:
              kinds:
              - CronJob
              namespaces:
              - aws-ebs-csi-driver
              - aws-efs-csi-driver
              - calico-system
              - datadog
              - fw-prometheus
              - grafana-agent
              - monitoring
              - tigera-operator
          resources: {}
        generate:
          clone: {}
          cloneList: {}
        match:
          any:
          - resources:
              kinds:
              - CronJob
          resources: {}
        mutate: {}
        name: autogen-cronjob-restricted-volumes
        validate:
          deny:
            conditions:
              all:
              - key: '{{ request.object.spec.jobTemplate.spec.template.spec.volumes[].keys(@)[]
                  || '''' }}'
                operator: AnyNotIn
                value:
                - name
                - configMap
                - downwardAPI
                - emptyDir
                - ephemeral
                - persistentVolumeClaim
                - projected
                - secret
                - ""
          message: 'Only the following types of volumes may be used: configMap, csi,
            downwardAPI, emptyDir, ephemeral, persistentVolumeClaim, projected, and
            secret.'
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:40Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-wide-secret-access-cluster-role
      controls.cfasec.com/id: rbac8
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-wide-secret-access-cluster-role","controls.cfasec.com/id":"rbac8","policies.kyverno.io/category":"Namespace Isolation","policies.kyverno.io/description":"Prevent ClusterRoles from being created with blanket secret access","policies.kyverno.io/subject":"ClusterRoles, RBAC","policies.kyverno.io/title":"Disallow Wide Secret Access RBAC"},"creationTimestamp":"2024-02-23T16:11:29Z","generation":1,"name":"restrict-wide-secret-access-cluster-role","resourceVersion":"727837307","uid":"3aa82059-011f-46f8-a0d0-95bca64f2bae"},"spec":{"background":false,"rules":[{"exclude":{"any":[{"clusterRoles":["cluster-admin"]}]},"match":{"any":[{"resources":{"kinds":["ClusterRole"]}}]},"name":"restrict-secret-access-cluster-role","preconditions":{"all":[{"key":"{{ request.operation || 'BACKGROUND' }}","operator":"AnyIn","value":["CREATE","UPDATE"]}]},"validate":{"foreach":[{"deny":{"conditions":{"all":[{"key":" {{ element.verbs || '' }}","operator":"AnyIn","value":["get","list","\\\"*\""]},{"key":" {{ element.apiGroups || '' }}","operator":"AnyIn","value":["","\\\"*\""]}],"any":[{"key":" {{ element.resources || '' }}","operator":"AnyIn","value":["\\\"*\"","secrets"]},{"key":" {{ element.nonResourceURLs || '' }}","operator":"AnyIn","value":["/api*"]}]}},"list":"request.object.rules"}],"message":"ClustRoles with unrestricted secret access are not allowed."}}],"validationFailureAction":"audit"}}
      policies.kyverno.io/category: Namespace Isolation
      policies.kyverno.io/description: Prevent ClusterRoles from being created with
        blanket secret access
      policies.kyverno.io/subject: ClusterRoles, RBAC
      policies.kyverno.io/title: Disallow Wide Secret Access RBAC
    creationTimestamp: "2024-04-16T06:35:39Z"
    generation: 1
    name: restrict-wide-secret-access-cluster-role
    resourceVersion: "29825"
    uid: aff99607-c03a-450a-b9e6-854c54e7189a
  spec:
    background: false
    rules:
    - exclude:
        any:
        - clusterRoles:
          - cluster-admin
      match:
        any:
        - resources:
            kinds:
            - ClusterRole
      name: restrict-secret-access-cluster-role
      preconditions:
        all:
        - key: '{{ request.operation || ''BACKGROUND'' }}'
          operator: AnyIn
          value:
          - CREATE
          - UPDATE
      validate:
        foreach:
        - deny:
            conditions:
              all:
              - key: ' {{ element.verbs || '''' }}'
                operator: AnyIn
                value:
                - get
                - list
                - \"*"
              - key: ' {{ element.apiGroups || '''' }}'
                operator: AnyIn
                value:
                - ""
                - \"*"
              any:
              - key: ' {{ element.resources || '''' }}'
                operator: AnyIn
                value:
                - \"*"
                - secrets
              - key: ' {{ element.nonResourceURLs || '''' }}'
                operator: AnyIn
                value:
                - /api*
          list: request.object.rules
        message: ClustRoles with unrestricted secret access are not allowed.
    validationFailureAction: audit
  status:
    autogen: {}
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:40Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-wide-secret-access-role
      controls.cfasec.com/id: rbac8
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-wide-secret-access-role","controls.cfasec.com/id":"rbac8","policies.kyverno.io/category":"Namespace Isolation","policies.kyverno.io/description":"Prevent Roles from being created with blanket secret access","policies.kyverno.io/subject":"Roles, RBAC","policies.kyverno.io/title":"Disallow Wide Secret Access RBAC"},"creationTimestamp":"2024-02-23T16:11:51Z","generation":1,"name":"restrict-wide-secret-access-role","resourceVersion":"727837821","uid":"356cc5c9-2348-4b31-8aa7-4be1353a2340"},"spec":{"background":false,"rules":[{"exclude":{"any":[{"clusterRoles":["cluster-admin"]}]},"match":{"any":[{"resources":{"kinds":["Role"]}}]},"name":"restrict-secret-access-role","preconditions":{"all":[{"key":"{{ request.operation || 'BACKGROUND' }}","operator":"AnyIn","value":["CREATE","UPDATE"]}]},"validate":{"foreach":[{"deny":{"conditions":{"all":[{"key":"{{ element.verbs }}","operator":"AnyIn","value":["get","list","\\\"*\""]},{"key":"{{ element.apiGroups }}","operator":"AnyIn","value":["","\\\"*\""]},{"key":"{{ element.resources }}","operator":"AnyIn","value":["\\\"*\"","secrets"]}]}},"list":"request.object.rules"}],"message":"Roles with unrestricted secret access are not allowed."}}],"validationFailureAction":"audit"}}
      policies.kyverno.io/category: Namespace Isolation
      policies.kyverno.io/description: Prevent Roles from being created with blanket
        secret access
      policies.kyverno.io/subject: Roles, RBAC
      policies.kyverno.io/title: Disallow Wide Secret Access RBAC
    creationTimestamp: "2024-04-16T06:35:40Z"
    generation: 1
    name: restrict-wide-secret-access-role
    resourceVersion: "29874"
    uid: f938c1bf-b078-4ba7-a72a-7e52432403e6
  spec:
    background: false
    rules:
    - exclude:
        any:
        - clusterRoles:
          - cluster-admin
      match:
        any:
        - resources:
            kinds:
            - Role
      name: restrict-secret-access-role
      preconditions:
        all:
        - key: '{{ request.operation || ''BACKGROUND'' }}'
          operator: AnyIn
          value:
          - CREATE
          - UPDATE
      validate:
        foreach:
        - deny:
            conditions:
              all:
              - key: '{{ element.verbs }}'
                operator: AnyIn
                value:
                - get
                - list
                - \"*"
              - key: '{{ element.apiGroups }}'
                operator: AnyIn
                value:
                - ""
                - \"*"
              - key: '{{ element.resources }}'
                operator: AnyIn
                value:
                - \"*"
                - secrets
          list: request.object.rules
        message: Roles with unrestricted secret access are not allowed.
    validationFailureAction: audit
  status:
    autogen: {}
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:40Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-wildcard-verbs
      controls.cfasec.com/id: rbac6
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/restrict-wildcard-verbs","controls.cfasec.com/id":"rbac6","kyverno.io/kubernetes-version":"1.23","kyverno.io/kyverno-version":"1.6.2","policies.kyverno.io/category":"Security","policies.kyverno.io/description":"Wildcards ('*') in verbs grants all access to the resources referenced by it and does not follow the principal of least privilege. As much as possible, avoid such open verbs unless scoped to perhaps a custom API group. This policy blocks any Role or ClusterRole that contains a wildcard entry in the verbs list found in any rule.","policies.kyverno.io/minversion":"1.6.0","policies.kyverno.io/severity":"medium","policies.kyverno.io/subject":"Role, ClusterRole, RBAC","policies.kyverno.io/title":"Restrict Wildcard in Verbs"},"creationTimestamp":"2024-02-23T16:11:29Z","generation":1,"name":"restrict-wildcard-verbs","resourceVersion":"727837314","uid":"642cde13-7377-4e2f-9e73-df500018ce31"},"spec":{"background":true,"rules":[{"exclude":{"any":[{"resources":{"kinds":["ClusterRole"],"names":["admin","akuity-admin","cluster-admin","rbac-manager","keda-operator-external-metrics-reader","keda-operator"]}},{"resources":{"kinds":["ClusterRole","Role"],"selector":{"matchExpressions":[{"key":"app","operator":"In","values":["gloo","gloo-fed"]}]}}}]},"match":{"any":[{"resources":{"kinds":["Role","ClusterRole"]}}]},"name":"wildcard-verbs","preconditions":{"all":[{"key":"{{request.operation || 'BACKGROUND'}}","operator":"NotEquals","value":"DELETE"}]},"validate":{"deny":{"conditions":{"any":[{"key":"{{ contains(request.object.rules[].verbs[] ||  '', '*') }}","operator":"Equals","value":true}]}},"message":"Use of a wildcard ('*') in any verbs is forbidden."}}],"validationFailureAction":"audit"}}
      kyverno.io/kubernetes-version: "1.23"
      kyverno.io/kyverno-version: 1.6.2
      policies.kyverno.io/category: Security
      policies.kyverno.io/description: Wildcards ('*') in verbs grants all access
        to the resources referenced by it and does not follow the principal of least
        privilege. As much as possible, avoid such open verbs unless scoped to perhaps
        a custom API group. This policy blocks any Role or ClusterRole that contains
        a wildcard entry in the verbs list found in any rule.
      policies.kyverno.io/minversion: 1.6.0
      policies.kyverno.io/severity: medium
      policies.kyverno.io/subject: Role, ClusterRole, RBAC
      policies.kyverno.io/title: Restrict Wildcard in Verbs
    creationTimestamp: "2024-04-16T06:35:40Z"
    generation: 1
    name: restrict-wildcard-verbs
    resourceVersion: "29916"
    uid: 74a78fdf-e978-4e2a-8a1d-382815162eca
  spec:
    background: true
    rules:
    - exclude:
        any:
        - resources:
            kinds:
            - ClusterRole
            names:
            - admin
            - akuity-admin
            - cluster-admin
            - rbac-manager
            - keda-operator-external-metrics-reader
            - keda-operator
        - resources:
            kinds:
            - ClusterRole
            - Role
            selector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - gloo
                - gloo-fed
      match:
        any:
        - resources:
            kinds:
            - Role
            - ClusterRole
      name: wildcard-verbs
      preconditions:
        all:
        - key: '{{request.operation || ''BACKGROUND''}}'
          operator: NotEquals
          value: DELETE
      validate:
        deny:
          conditions:
            any:
            - key: '{{ contains(request.object.rules[].verbs[] ||  '''', ''*'') }}'
              operator: Equals
              value: true
        message: Use of a wildcard ('*') in any verbs is forbidden.
    validationFailureAction: audit
  status:
    autogen: {}
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:41Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
- apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    annotations:
      argocd.argoproj.io/tracking-id: sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/validate-disallow-token-requests-rbac
      controls.cfasec.com/id: rbac9
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"kyverno.io/v1","kind":"ClusterPolicy","metadata":{"annotations":{"argocd.argoproj.io/tracking-id":"sb-use1-01-kyverno-policies:kyverno.io/ClusterPolicy:kyverno/validate-disallow-token-requests-rbac","controls.cfasec.com/id":"rbac9","policies.kyverno.io/category":"Sample","policies.kyverno.io/description":"TokenRequests are not allowed.","policies.kyverno.io/severity":"medium","policies.kyverno.io/subject":"TokenRequests","policies.kyverno.io/title":"Disallow TokenRequests"},"creationTimestamp":"2024-02-23T16:11:51Z","generation":1,"name":"validate-disallow-token-requests-rbac","resourceVersion":"727837792","uid":"3bf7a29c-39ac-4416-b990-60e254509b32"},"spec":{"background":false,"rules":[{"match":{"any":[{"resources":{"kinds":["Role","ClusterRole"]}}]},"name":"disallowTokenRequestsRbac","validate":{"message":"Roles or ClusterRoles are not allowed to have permissions on tokenreviews or tokenrequests.","pattern":{"rules":{"resources":["tokenreviews","tokenrequests"],"verbs":["*"]}}}}],"validationFailureAction":"Audit"}}
      policies.kyverno.io/category: Sample
      policies.kyverno.io/description: TokenRequests are not allowed.
      policies.kyverno.io/severity: medium
      policies.kyverno.io/subject: TokenRequests
      policies.kyverno.io/title: Disallow TokenRequests
    creationTimestamp: "2024-04-16T06:35:41Z"
    generation: 1
    name: validate-disallow-token-requests-rbac
    resourceVersion: "29938"
    uid: cb11d502-256c-46fe-93a5-b27f15309747
  spec:
    background: false
    rules:
    - match:
        any:
        - resources:
            kinds:
            - Role
            - ClusterRole
      name: disallowTokenRequestsRbac
      validate:
        message: Roles or ClusterRoles are not allowed to have permissions on tokenreviews
          or tokenrequests.
        pattern:
          rules:
            resources:
            - tokenreviews
            - tokenrequests
            verbs:
            - '*'
    validationFailureAction: Audit
  status:
    autogen: {}
    conditions:
    - lastTransitionTime: "2024-04-16T06:35:41Z"
      message: ""
      reason: Succeeded
      status: "True"
      type: Ready
    ready: true
    rulecount:
      generate: 0
      mutate: 0
      validate: 1
      verifyimages: 0
kind: List
metadata:
  resourceVersion: ""
